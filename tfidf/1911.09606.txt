An Introduction to Symbolic Artiﬁcial Intelligence
Applied to Multimedia

Guilherme Lima, Rodrigo Costa, Marcio Ferreira Moreno

Guilherme.Lima@ibm.com, Rodrigo.Costa@ibm.com, mmoreno@br.ibm.com

IBM Research, Brazil

2019-11-08

9
1
0
2

v
o

N

1
2

]
I

A

.

s

c

[

1
v
6
0
6
9
0

.

1
1
9
1

:

v

i

X

r

a

 
 
 
 
 
 
Abstract

In this chapter, we give an introduction to symbolic artiﬁcial intelligence (AI) and
discuss its relation and application to multimedia. We begin by deﬁning what
symbolic AI is, what distinguishes it from non-symbolic approaches, such as ma-
chine learning, and how it can used in the construction of advanced multimedia
applications. We then introduce description logic (DL) and use it to discuss sym-
bolic representation and reasoning. DL is the logical underpinning of OWL, the
most successful family of ontology languages. After discussing DL, we present
OWL and related Semantic Web technologies, such as RDF and SPARQL. We
conclude the chapter by discussing a hybrid model for multimedia representation,
called Hyperknowledge. Throughout the text, we make references to technologies
and extensions speciﬁcally designed to solve the kinds of problems that arise in
multimedia representation.

2

4

5
11
18
20
20

22

23
26
29

36

37
38
43

45

Contents

1

Introduction

2 Description Logic(s)

2.1 Syntax .
.
.
.
.
.
2.2 Semantics .
.
.
.
2.3 Reasoning tasks .
2.4 Rules
.
.
.
.
.
.
2.5 Other DLs .
.
.
.

.
.
.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .

3 Semantic Web Technologies

3.1 RDF .
.
.
.
3.2 SPARQL .
3.3 OWL .
.
.

.
.
.

.
.
.

.
.
.

.
.
.

. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . .

4 A Hybrid Approach: Hyperknowledge

4.1 Hyperknowledge in a nutshell . . . . . . . . . . . . . . . . . . . .
4.2 HSL and HyQL .
.
. . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Hyperknowledge tools
. . . . . . . . . . . . . . . . . . . . . . .

5 Further Reading

1

1

Introduction

A classic problem in multimedia representation and understanding is the semantic
gap problem. It states that there is a big representational gap between the audiovisual
signals that compose multimedia objects and the concepts represented by these
signals. For instance, the dominant color and movement trajectory of a given set of
pixels in a video clip, which are low-level characteristics of the clip, do not provide
much information about the meaning of the set of pixels—at least not to computers.
But recent developments in artiﬁcial intelligence (AI) are changing that.
Backed by large training datasets, current machine learning methods are able to
extrapolate complex patterns from low-level multimedia data. These patterns are
embodied in trained models which can be used to classify or identify persons and
objects with reasonable speed and accuracy in images, audio clips, and video clips.
But being able to identify persons and objects in multimedia data only solves half
of the problem. To emulate human cognition and truly understand a scene—for
instance, to determine who is doing what and the consequences of these actions—
computers need additional information: they need common sense knowledge and
domain knowledge, and also the capacity to infer new knowledge from preexisting
knowledge. This is where symbolic AI comes in.
The basic idea of symbolic AI is to describe the world, its entities, and their
relationships using a formal language—a language that can be conveniently manipu-
lated by computers—and to develop eﬃcient algorithms to query and deduce things
from these formal descriptions. To illustrate the kind of applications enabled by the
combination of symbolic AI and multimedia consider Figure 1.

Jean-Paul Marat

Wound

Letter from
Charlotte Corday

Knife

Figure 1: The Death of Marat (detail), by Jacques-Louis David, 1793. (WikiMedia)

2

Suppose we are given this picture and suppose the only thing we know about it is
what we can infer from the image. We can see it depicts Jean-Paul Marat (assuming
we can identify him), a stab wound, a blood-tainted knife, and a letter addressed
to him and signed by Charlotte Corday (assuming we can read the contents of the
letter). The analogy here is that we have extracted these information—or facts—
using pattern matching. Although such basic facts allow us to perform simple
computational tasks, such as keyword-based image classiﬁcation and search, they
are not enough to understand the image.
To truly understand what is being depicted in Figure 1 we need more than basic
facts. We need (1) general knowledge about the world, (2) speciﬁc knowledge about
the persons named, and (3) the capacity to combine general and speciﬁc knowledge
with the facts extracted from the image in order to infer new facts.
Now suppose we are given (1), (2), and (3). From our general knowledge of
the world, and possibly by further analyzing the image, we can assert with high
conﬁdence that Marat is holding the letter and that he has a stab wound on the
chest. From this and from the blood-tainted knife depicted below him, we might
infer that the depicted knife is the object that caused the wound. Since knifes are
not autonomous beings, we might also conclude that someone (possibly himself )
stabbed Marat in the chest. But who and why?
To answer these questions we will need more information. Suppose we are told
that Marat was a journalist and political agitator, and one of the leaders of a radical
political faction in the Reign of Terror period of the French Revolution (c. 1793).
Suppose we are also told that Charlotte Corday, who signed the letter, was a declared
political enemy of Marat—she blamed him for a number of killings in Paris and
other cities and believed that he was a grave threat to the French Republic. Under
the light of these new facts, we can conclude that Figure 1 looks like the scene of a
political murder.
By combining this conclusion with the additional fact that Charlotte Corday
is known to have murdered Jean-Paul Marat with a knife while he was in his
bathtub, holding a letter from her, we can infer that Figure 1 must be a graphical
representation of this incident, that is, of the politically motivated assassination of
Jean-Paul Marat by Charlotte Corday.
The derivation of this last fact from the visual patterns of Figure 1 has only
been possible because we have had access not only to basic facts extracted from the
image, but also to facts about the world (common sense knowledge) and about the
depicted objects and persons (domain knowledge), and because we could combine
all of these facts and make inferences.
One of the main goals of symbolic AI is to enable the representation and manip-
ulation of pieces of knowledge by computers in ways that resemble or emulate the
kind of manipulations performed by humans—manipulations similar to the consider-
ations that enabled us to determine the true meaning of Figure 1. The combination
of this capacity with multimedia opens up many possibilities. For instance, the
Marat’s murder example is an application of automated image understanding. Two
related applications are video understanding and audio understanding, which are

3

often more complex as they involve the extraction of temporal information.
Other applications of symbolic AI to multimedia include the semantic retrieval,
classiﬁcation, recommendation, and inspection of multimedia data—for example,
to automatically identify suspicious activity in surveillance videos, generate age
ratings for music and movies, and identify risk factors for diseases in medical images
and videos. Although we could list many other interesting applications, and we
will discuss some of these as we go along, here our focus is not on the applications
themselves. Our focus is on the principles and technologies that enabled their
conception in the ﬁrst place.
In this chapter, we give an introduction to symbolic AI from the perspective of
multimedia. We begin, in Section 2, with description logic (DL). One reason for
doing so is that DL allows us to introduce symbolic representation in an abstract
setting, without the complications and biases of a particular technology. Another
reason is that DL is itself a practical technology: it is the logical underpinning of
the most expressive family of ontology languages, the OWL family.
After introducing DL, in the next section (Section 3) we discuss the incarnation
of symbolic AI on the Web, the so-called Semantic Web. We lay out the Semantic
Web vision, its main enabling technologies (RDF, OWL, SPARQL, SWRL, etc.),
and the relation of these technologies with the notions discussed in Section 2.
Throughout both sections, whenever possible we motivate the discussion with
examples from the multimedia domain. We also strive to present or mention
methodologies and extensions speciﬁcally designed to solve the kinds of problems
that arise in multimedia representation.
We conclude the chapter with the discussion of a hybrid model for multimedia
representation (Section 4). This model, called Hyperknowledge (HK), generalizes a
classic hypermedia model with the notions of concept nodes and semantic links. By
doing so, the Hyperknowledge model allows for the integrated representation and
processing of multimedia content together with their semantic description.
Suggestions for further reading are listed at the end of the chapter (Section 5).

2 Description Logic(s)

The word logic has many meanings and no completely satisfying deﬁnition. We can
understand logic as a system for deducing new statements from previously asserted
statements. There are many kinds of logics. One of the simplest is propositional
logic, which deals with statements constructed by means of the propositional con-
nectives ¬ (not), ∧ (and), ∨ (or), → (if-then), and ↔ (if and only if ). First-order
logic (FOL), often used to formalize mathematical statements, extends propositional
logic with the notions of variables, constants, functions, predicates, and quantiﬁers.
There are still further extensions, such as second order logic, and logics which adopt
slightly diﬀerent approaches, such as modal and fuzzy logics.
The term “description logic” (DL) refers not to a single logic but to a family of
logics. That is why we sometimes write description logics (plural). The logics in

4

this family come in many ﬂavors, but most of them share the same core modeling
features—they speak of individuals, concepts, and roles. Here we will focus on the
description logic SR OI Q [16]. Most of today’s mainstream DLs are sublanguages
of SR OI Q , which is also the basis of the ontology language OWL 2 DL [35]. We
will follow the usual approach for presenting a formal language. We begin by giving
the form (syntax) of SR OI Q statements together with their intuitive meaning. We
will deﬁne their exact meaning (semantics) later.

2.1 Syntax

We assume we are given three sets of names, NI , NC , and NR , containing names
for individuals, concepts, and roles, respectively. The idea is that individuals will
represent real-world entities, concepts will represent characteristics of these entities,
and roles will represent relations between (two) entities. 1 We assume further that the
sets NI , NC , and NR are pairwise disjoint, that is, that no name occurs at the same
time in more than one of the sets. The three sets of names constitute the vocabulary
of SR OI Q—the basic building blocks which we will use to construct statements
of the language.
We distinguish three kinds of statements, which in DL are also called axioms.
These are grouped into boxes: ABox, TBox, and RBox. The latter, RBox, is
available only in very expressive description logics, such as SR OI Q , but all DL-
based ontologies have a TBox and most of them an ABox. Together the three boxes
comprise a knowledge base.
The ABox contains the assertional knowledge: statements that assert facts about
speciﬁc individuals. For example, the concept assertion

Director(kubrick)

states that the individual named kubrick is a director. Similarly, the role assertion

directs(kubrick, space-odyssey)

states that the individual named kubrick directs the individual (that is, the movie)

named space-odyssey.

The TBox and RBox contain the terminological knowledge: statements that
assert facts concerning all individuals. The TBox contains statements about concepts
and the RBox contains statements about roles. For example, the TBox axiom

Director (cid:118) Person

states that the concept named Director is subsumed by the concept named Person,
that is, that every individual who is a director is also a person. And the RBox axiom

directs (cid:118) likes

1For those versed in ﬁrst-order logic, names of individuals are constants, names of concepts are
unary predicates, and names of roles are binary predicates.

5

states that the role named directs is subsumed by the role named likes, that is,
that directing a movie implies liking it. 2
This last statement is, of course, questionable. Maybe some director out there in
the world does not like some movie which he or she directed. But the point here
is that the statements in a knowledge base, especially those in the TBox and RBox,
formalize a particular conceptualization of a domain. The conceptualization reﬂects
the world-view of its designer and may contain simpliﬁcations which make sense in
its context of use.
Another property of a conceptualization is that it is language-independent—it is
just a conceptual model which can be created in a modeling language such as UML.
The term ontology is sometimes used to mean the instantiation of a conceptualization
in a speciﬁc knowledge representation language. For our purposes, the term ontology
will mean the same as knowledge base, that is, a set of axioms partitioned into ABox,
TBox, and RBox.
Back to SR OI Q , we will now deﬁne the precise syntax of the statements in
each of the boxes.

RBox The SR OI Q RBox contains statements that describe characteristics of
roles and interdependencies between roles. A role is one of the following expres-
sions:
1. A role name r, for some r in NR .
2. An inverted role name r− , for some r in NR .
3. The universal role u.
A role inclusion axiom (RIA) is a statement of the form

r1 ◦ · · · ◦ rn (cid:118) r,

where r1 , . . . , rn , and r are roles.
Here is an example RIA:

fatherOf (cid:118) childOf−

.

This RIA states that the role named fatherOf is subsumed by the inverse of the
role named childOf, that is, that if a is a father of b then b is a child of a, for any
individuals a and b. Similarly, the RIAs
and

owns ◦ partOf (cid:118) owns

owns (cid:118) caresFor

2We can rewrite the last two statements in ﬁrst-order logic as

∀ x (Director( x ) → Person( x ))

and ∀ x∀ y (directs( x, y ) → likes( x, y )).

The notation of DL is inspired by set theory and does not use variables.

6

state, respectively, that if a owns b then a cares for b (ownership implies care)
and that if a owns b and b is part of c then a owns c (ownership of a part implies
ownership of the whole). 3 A ﬁnite set of RIAs is called a role hierarchy.
A role characteristic is a statement of one of the forms:

Sym(r ), Asy(r ),

Tra(r ), Ref(r ),

Irr(r ), Dis(r, s),

where r and s are any roles diﬀerent from the universal role u. As we will see in
Section 2.2, we interpret roles as binary relations and we use role characteristic
statements to assert properties of these relations—namely, symmetry, asymmetry,
transitivity, ref lexivity, irreﬂexivity, and disjointness. We will give the precise
meaning of these terms later.
A SR OI Q RBox consists of a role hierarchy together with a ﬁnite set of role
characteristics. The RBox is said to be regular if its role hierarchy is regular.
Regularity is desirable property because it guarantees the decidability of the
resulting logic. In practice, this means that any reasoning task will terminate in a
ﬁnite time (not loop indeﬁnitely). We will not deﬁne what a regular RBox is, as
that would take us a little too far aﬁeld, but we remark that regularity is a purely
syntactical property: it can be obtained by restricting the form of the RIAs that
occur in a given role hierarchy. See [16] for details.

TBox The SR OI Q TBox contains statements relating concepts, or more pre-
cisely, concept expressions. A concept (expression) is one of the following:
1. A concept name C, for some C in NC .
2. The top concept (cid:62).
3. The bottom concept ⊥.
4. The nominal concept {a1, . . . , an } where a1 , . . . , an are names in NI .
5. The negation ¬C where C is a concept expression.
6. The intersection C (cid:117) D where C and D are concept expressions.
7. The union C (cid:116) D where C and D are concept expressions.
8. The existential ∃r .C where r is a role and C is a concept expression.
9. The universal ∀r .C where r is a role and C is a concept expression.

3These three RIAs can be formalized in ﬁrst-order logic as

∀ x∀ y (fatherOf( x, y ) → childOf( y, x ))
∀ x∀ y (owns( x, y ) → caresFor( x, y ))
∀ x∀ y∀z(owns( x, y ) ∧ partOf( y, z) → owns( x, z)).

7

10. The self-restriction ∃r .Self where r is a (simple) role.
11. The at-least restriction ≥nr .C where n is a nonnegative integer, r is a (simple)
role, and C is a concept expression.
12. The at-most restriction ≤nr .C where n is a nonnegative integer, r is a (simple)
role, and C is a concept expression.
Note that a concept expression, as deﬁned above, is not a statement—it does
not assert something which is either true or false. Instead, a concept expression
constructs a new concept from the given expressions, which may be other concept
expressions, individual names, or roles. This construction starts with the atomic
concepts, that is, the concept names and the top (cid:62) and bottom ⊥ concepts (rules 1,
2, and 3 above).
Recall that a concept stands for a given characteristic of certain individuals. We
can understand a concept C as the collection (or set) of all individuals possessing
that given characteristic. So, the concept name Actor can be understood as the set
of all individuals who are actors. Similarly, the top concept (cid:62) can be understood as
the set of all individuals whatsoever and the bottom concept ⊥ as the empty set—the
set containing no individuals at all.
A nominal concept {a1, . . . , an } (rule 4) stands for the set containing precisely
the individuals named by a1 , . . . , an . For instance, {kubrick, scorsese} stands
for the set whose only members are the individuals named kubrick and scorsese.
The negation, intersection, and union operations (rules 5, 6, and 7) allows us
to construct new concepts from other concepts. For instance, the concept ¬Actor
stands for the set of all individuals who are not actors. Similarly, the concepts

Actor (cid:117) Female and Actor (cid:116) Director

stand, respectively, for the set of individuals who are female actors and the set of
individuals who are actors or directors (or both). Note that these operations apply
to any concept expressions, not just names. So, for example, the complex concept

Director (cid:117) ¬(Female (cid:116) {kubrick, scorsese})

stands for directors who are neither female nor the individuals named kubrick or

scorsese.

The existential and universal quantiﬁers (rules 8 and 9) take a role and a concept
and construct a new concept. For instance, the concepts

∃knows.Actor and ∀directs. {a-bronx-tale, good-shepherd}

stand, respectively, for the set individuals who know some actor, and for the set
individuals who either haven’t directed any ﬁlm or directed exactly the ﬁlms named
a-bronx-tale and good-shepherd. As we will see in the next section, by the way

8

the ∀ operator is deﬁned, if we want to exclude the “haven’t directed any ﬁlm part”
we must write

(∃directs.(cid:62)) (cid:117) (∀directs. {a-bronx-tale, good-shepherd}),

which incidentally speciﬁes the set {de-niro} .
The self-restriction operator (rule 10) takes a (simple) role r and constructs
example, the concept ∃loves.Self stands for the set of all individuals who love
the concept containing all individuals which are related to themselves via r . For
themselves. Clearly, this operator only makes sense when applied to roles which
connect the same kind of entity, for example, persons to persons, movies to movies,
etc.

The requirement of r being simple in the deﬁnition of the self-restriction operator
is related to the problem of regularity mentioned earlier. The roles that appear in an
SR OI Q RBox are classiﬁed into simple and non-simple depending on the form
of the RIAs in which they occur. Informally, the non-simple roles are those which
are “created” by role chains of length greater than one; the remaining roles are
considered simple. We assume that the r and s occurring in role characteristics of
the form Irr(r ), Asy(r ), and Dis(r, s) are always simple roles. See [16] for details.
The two remaining concept constructors of SR OI Q are the cardinality restric-
tion operators ≥ and ≤ (rules 11 and 12). Both take a nonnegative integer n, a
simple role r , and concept C , and construct a new concept containing all individuals
which are r -connected to at-least or at-most n individuals in C . For example, the
concepts

≥2knows.Actor and ≤5directs.(cid:62)

stand, respectively, for the set of individuals who know two or more actors, and the
set of individuals who directed ﬁve or less movies.
We are ﬁnally in a position to deﬁne what a SR OI Q TBox is. The SR OI Q
TBox is a ﬁnite set of general concept inclusion axioms (GCIs) where each GCI is a
statement of the form

C (cid:118) D,

for arbitrary concepts C and D. As in RIAs, the symbol (cid:118) in GCIs stands for
subsumption. So, for instance,

Actor (cid:118) Person and ∃directs.(cid:62) (cid:118) ∃knows.Actor

state, respectively, that the every individual who is an actor is also a person, and that
every individual who directs some ﬁlm knows some actor. 4

4To translate a GCI to ﬁrst-order logic we ﬁrst translate the concepts on each side of the (cid:118) as
formulas with a single free variable, say x . The (cid:118) becomes an implication and the whole formula is
then enclosed in a ∀ x . For example, the last two GCIs are translated as:

∀ x (Actor( x ) → Person( x ))

and ∀ x (∃ y (directs( x, y ) ∧(cid:62)( y )) → ∃z(knows( x, z) ∧ Actor(z))).

9

ABox The SR OI Q ABox contains the assertional statements: statements that
assert facts about speciﬁc individuals. These statements have one of the forms:

C (a),

r (a, b), ¬r (a, b),

a ≈ b,

a (cid:48) b,

where C is a concept, r is a role, and a and b are names of individuals.
The concept assertion Actor (cid:117) Director(de-niro) states that the individual
named de-niro is an instance of the concept named Actor (cid:117) Director, that is,
that this individual is both an actor and a director.
The role assertion directs(kubrick, dr-strangelove) states that the indi-
vidual named kubrick is directs-connected to the individual dr-strangelove.
Similarly, the negated role assertion ¬ directs(kubrick, taxi-driver) states
The equality assertion kubrick ≈ stanley and the inequality assertion

that kubrick is not directs-connected to taxi-driver.

kubrick (cid:48) taxi-driver state, respectively, that kubrick and stanley name

the same individual, and that kubrick and taxi-driver do not name the same
individual.

Knowledge base (KB) A SR OI Q knowledge base is the union of the three boxes:
RBox, TBox, and ABox. A knowledge base is said to be regular if its RBox is
regular.

The movie facts KB We conclude this section on the syntax of SR OI Q with
an example. The knowledge base below collects some of the movie facts we
have been discussing. Note that the usual interpretation of these statements—the
interpretation in which kubrick names the famous director—is just one of many
possible interpretations. We will have more to say about interpretations next.

ABox

Director(kubrick)
Actor (cid:117) Director(de-niro)
≥2knows.Actor(stanley)
directs(kubrick, space-odyssey)
¬ directs(kubrick, taxi-driver)
kubrick ≈ stanley
kubrick (cid:48) de-niro

“kubrick is a director”
“de-niro is an actor and a director”
“stanley knows at least two actors”

“kubrick directed space-odyssey”
“kubrick did not direct taxi-driver”

“kubrick and stanley are the same individual”
“kubrick and de-niro are not the same individual”

TBox

Director (cid:118) ∃directs.(cid:62)
∃directs.(cid:62) (cid:118) Director
Director (cid:118) Person
Director (cid:118) ≥1knows.Actor
(∃directs.(cid:62)) (cid:117) (∀directs. {a-bronx-tale, good-shepherd}) (cid:118) {de-niro}

“a director directs something”
“anything which directs is a director”
“a director is a person”
“a director knows at least one actor”

“anything which directs exactly {a-bronx-tale, good-shepherd} must be a {de-niro}”

10

RBox

directs (cid:118) likes
directs ◦ actsIn− (cid:118) knows

2.2 Semantics

“directing implies liking”
“if x directs y in which z acts, then x knows z”

A knowledge base, as deﬁned previously, is basically a set well-formed strings, called
statements or axioms. The meaning of each of these strings depends ultimately on
the meaning of the names which occur in them. To see this, consider the axiom
Director(kubrick). This axiom will be true if we interpret the names Director
and kubrick as “the property of being a movie director” and “Stanley Kubrick”,
respectively. If however we interpret Director as “the property of being an even
number” and kubrick as “the number 37”, then the assertion Director(kubrick)
ceases to be true. This example is artiﬁcial but serves to illustrate our point that the
meaning is derived from the interpretation of the names. We will now deﬁne this
notion of interpretation precisely.

Interpretation An interpretation I consists of two things:
1. A nonempty set ∆I called the domain or universe of discourse.
2. A function I from the vocabulary sets NI , NC , and NR such that: 5
(a) If a ∈ NI then aI ∈ ∆I .
(b) If C ∈ NC then CI ⊆ ∆I .
(c) If r ∈ NR then rI ⊆ ∆I × ∆I .
In other words, an interpretation I ﬁxes a domain of discourse ∆I , which can be
any nonempty set, and maps the names of individuals into elements of the domain,
the names of concepts into subsets of the domain, and the names of roles into binary
relations on the domain.
We reserve the term individual to refer to the semantic counterpart of an indi-
vidual name, that is, to an element of the domain. And we reserve the terms concept
extension and role extension to refer, respectively, to the semantic counterparts of
concepts and roles, that is, to unary and binary relations on the domain.
We now lift the interpretation function I so that it can be applied to arbitrary
roles and concepts:

u I = ∆I × ∆I
(r − )I = { (cid:104)δ
(cid:48)
(cid:62)I = ∆I

, δ(cid:105) | (cid:104)δ, δ

(cid:48)(cid:105) ∈ r I }

(1)
(2)
(3)

5Note that x I is just a more compact way to write I ( x ) which is the usual syntax for function
application.

11

{a1, . . . , an } I = {aI
1 , . . . , aI

n }

⊥I = 

(¬C )I = ∆I \ C I
(C (cid:117) D)I = C I

(4)
(5)
(6)

12. The at-least restriction ≥n.rC denotes the set of all individuals which are
connected via relation r I to at least n individuals in C I .
13. The at-most restriction ≤n.rC denotes the set of all individuals which are
connected via relation r I to at most n individuals in C I .
We now turn to the problem of deﬁning the truth-value (truth or falsity) of an
axiom under a given interpretation.

Satisﬁability An interpretation I satisﬁes (or is a model of ) an axiom α, in
symbols I (cid:15) α, under the following conditions:
1. (RIA) I (cid:15) r1 ◦ · · · ◦ rn (cid:118) r iﬀ 7 for every sequence δ0 , δ1 , . . . , δn in ∆I :
implies

1 , (cid:104)δ1, δ2 (cid:105) ∈ r I
2 , . . . , and (cid:104)δn−1, δn (cid:105) ∈ r I

(cid:104)δ0, δ1 (cid:105) ∈ r I

(cid:104)δ0, δn (cid:105) ∈ r I

n

,

n

1 , . . . , r I

(in this order) has a

that is, iﬀ every path in ∆I that traverses r I
direct r I -shortcut.
2. (Role symmetry) I (cid:15) Sym(r ) iﬀ r I is a symmetric relation, that is, iﬀ
(cid:104)δ1, δ2 (cid:105) ∈ r I implies (cid:104)δ2, δ1 (cid:105) ∈ r I and vice versa, for any δ1, δ2 in ∆I .
3. (Role asymmetry) I (cid:15) Asy(r ) iﬀ r I is an asymmetric relation, that is, iﬀ
(cid:104)δ1, δ2 (cid:105) ∈ r I implies (cid:104)δ2, δ1 (cid:105) (cid:60) r I , for any δ1, δ2 in ∆I .
4. (Role transitivity) I (cid:15) Tra(r ) iﬀ r I is a transitive relation, that is, iﬀ (cid:104)δ1, δ2 (cid:105) ∈
r I and (cid:104)δ2, δ3 (cid:105) ∈ r I implies (cid:104)δ1, δ3 (cid:105) ∈ r I , for any δ1, δ2, δ3 in ∆I .
5. (Role reﬂexivity) I (cid:15) Ref(r ) iﬀ r I is a reﬂexive relation, that is, iﬀ (cid:104)δ, δ(cid:105) ∈ r I ,
for any δ in ∆I .
6. (Role irreﬂexivity) I (cid:15) Irr(r ) iﬀ r I is an irreﬂexive relation, that is, iﬀ
(cid:104)δ, δ(cid:105) (cid:60) r I , for any δ in ∆I .
7. (Role disjointness) I (cid:15) Dis(r, s) iﬀ r I

10. (Role assertion) I (cid:15) r (a, b) iﬀ (cid:104)aI , bI (cid:105) ∈ r I , that is, iﬀ aI is r I -connected
to bI .
11. (Negated role assertion) I (cid:15) ¬r (a, b) iﬀ (cid:104)aI , bI (cid:105) (cid:60) r I .
12. (Equality assertion) I (cid:15) a ≈ b iﬀ aI = bI , that is, iﬀ aI and bI are the same
element of ∆I .
13. (Inequality assertion) I (cid:15) a (cid:48) b iﬀ aI (cid:44) bI .
Now that we have deﬁned when an interpretation satisﬁes an axiom, we can
extend this notion to apply to a knowledge base (set of axioms). An interpretation I
satisﬁes (or is a model of ) of a knowledge base K B , in symbols I (cid:15) K B , iﬀ I (cid:15) α,
for every axiom α in K B . A knowledge base is said to be satisﬁable or consistent if
it has a model, that is, if there is some interpretation I which satisﬁes it; otherwise,
the knowledge base is said to be insatisﬁable or inconsistent.
To make the discussion of interpretations more concrete, consider the following
interpretation I for the movie facts KB presented at the end of the last section:

∆I = {i1, i2, i3, i4, i5, i6, i7 }
kubrickI = i1
de-niroI = i2
stanleyI = i1
space-odysseyI = i3
taxi-driverI = i4
a-bronx-taleI = i5
good-shepherdI = i6
DirectorI = {i1, i2 }
ActorI = {i2, i7 }
PersonI = {i1, i2 }
knowsI = { (cid:104)i1, i2 (cid:105), (cid:104)i1, i7 (cid:105), (cid:104)i2, i7 (cid:105) }
directsI = { (cid:104)i1, i3 (cid:105), (cid:104)i2, i5 (cid:105), (cid:104)i2, i6 (cid:105) }
likesI = { (cid:104)i1, i3 (cid:105), (cid:104)i1, i4 (cid:105), (cid:104)i2, i5 (cid:105), (cid:104)i2, i6 (cid:105) }
actsInI = { (cid:104)i7, i5 (cid:105) }

knowsI

i1

i2

i7

directsI

i1

likesI

i1

i4

actsInI

i2

i3

i2

i3

i5

i6

i5

i6

i7

i5

The domain ∆I in this case consists of seven distinct individuals, i1 , . . . , i7 , and the
names that occur in the movie facts KB are mapped as shown above. The following
remarks are in order:
• Some individuals in the domain ∆I might not have corresponding names: i7
is not named by any name in the movie facts KB.

14

• Two distinct names might denote the same thing: kubrick and stanley
denote the individual i1 .
• Concept names are mapped into subsets of the domain ∆I : Director, Actor,
and Person denote sets of individuals.
• Role names are mapped into binary relations on the domain ∆I : knows,
directs, likes, and actsIn denote sets of ordered pairs of individuals.
The individuals i2 and i5 stand in relation directsI to each other (in this
other) because the pair (cid:104)i2, i5 (cid:105) is in directsI . Binary relations can be
conveniently depicted as directed graphs. The graphs corresponding to the
relations knowsI , directsI , likesI , and actsInI are shown in the boxes
above.
Let K B stands for the movie facts KB and let I stands for the previous interpre-
tation. The natural question to ask is whether I (cid:15) K B , that is, whether the previous
interpretation satisﬁes the movie facts KB. This will be the case only if I (cid:15) α for
every axiom α in the movie facts KB. Let us check that.
We begin by checking the movie facts ABox. Clearly,

I (cid:15) Director(kubrick)

because kubrickI ∈ DirectorI , that is, because i1 ∈ {i1, i2 }, as required by the
deﬁnition of satisﬁability of concept assertions. Similarly,

I (cid:15) ¬directs(kubrick, taxi-driver)

because (cid:104)kubrickI
, taxi-driverI (cid:105) (cid:60) directsI . The remaining axioms in the
ABox are also satisﬁed by I , as the reader can easily check.
We will now check the movie facts TBox. We have that

I (cid:15) Director (cid:118) Person

since every individual in the set DirectorI is also in the set PersonI . It is also
the case that

I (cid:15) (∃directs.(cid:62))(cid:117)(∀directs. {a-bronx-tale, good-shepherd}) (cid:118) {de-niro}

because:
1. de-niroI is connected via relation directsI to some member of (cid:62)I (that
is, the whole domain).
2. Everything to which de-niroI is directsI -connected is an element of the

set {a-bronx-taleI

, good-shepherdI }.

3. The previous assertions (1) and (2) hold for no other individual besides

de-niroI .

15

The rest of the axioms in the movie facts TBox are also satisﬁed by I . (Again, we
leave these checks to the reader.)
The last thing to check are the axioms in the movie facts RBox. We have that

I (cid:15) directs (cid:118) likes

holds because every pair in relation directsI is also in relation likesI . One way
to determine whether or not

I (cid:15) directs ◦ actsIn− (cid:118) knows

holds is to search for three (not necessarily distinct) individuals x , y , z such that

(cid:104) x, y (cid:105) ∈ directsI and (cid:104)z, y (cid:105) ∈ actsInI but (cid:104) x, z(cid:105) (cid:60) knowsI . If we can ﬁnd such

three individuals then the assertion is false (as we just found a counterexample).
Otherwise, if we cannot ﬁnd such three individuals, the assertion is true. In the
case of the interpretation I , there is only one possible choice of individuals that
satisﬁes the ﬁrst two requirements, namely, x = i2 , y = i5 , and z = i7 . Under this
choice the third requirement is also satisﬁed since (cid:104)i2, i7 (cid:105) ∈ knowsI . Hence the
assertion is true, that is, the axiom directs ◦ actsIn− (cid:118) knows is satisﬁed by the
interpretation I .
Since I satisﬁes all axioms in each of the boxes of the movie facts KB, we
conclude that answer to our original question (namely, whether or not I (cid:15) K B ) is
positive. That is, it is indeed the case that the interpretation I satisﬁes the movie
facts KB, and consequently, the movie facts KB is consistent (satisﬁable).
Two related questions concerning the movie facts KB are the following: Can we
ﬁnd an interpretation J that does not satisﬁes the movie facts KB? And how can
we modify the movie facts KB so that it becomes inconsistent (insatisﬁable)?
A simple answer to the ﬁrst question is to take an interpretation J which is
identical to the previous interpretation I but in which we map kubrick J and
stanley J to distinct individuals in the domain ∆J . Clearly, under such interpreta-
tion the ABox axiom kubrick ≈ stanley does not hold, and so J (cid:50) K B .
Concerning the second question, in order to make the movie facts KB inconsis-
tent we need to modify it in a way that prevents the construction of any satisfying
interpretation. A trivial way to accomplish this is to add the inequality assertion
kubrick (cid:48) kubrick to the KB. This axiom will be false under any interpreta-
tion I because whatever the choice of denotation for kubrick we will always
have kubrickI = kubrickI . Of course, there are less trivial ways to obtain an
inconsistent KB. (Can the reader ﬁnd one involving a TBox axiom?)
This concludes our discussion of satisﬁability. The whole point of a formal
semantics is to deﬁne a consequence relation which allows us to determine when a
knowledge base entails a given axiom. We will now deﬁne this consequence relation
in terms of the satisﬁability relation.

Logical consequence An axiom α is a logical consequence of (or is entailed by)
a knowledge base K B , in symbols K B (cid:15) α, iﬀ I (cid:15) K B implies I (cid:15) α, for every

16

interpretation I . That is, iﬀ every interpretation which is a model of the knowledge
base K B is also a model of the axiom α. 8
Using this deﬁnition of logical consequence we can determine precisely when an
axiom α follows from a given set of axioms. As we discussed previously, some KBs
are inconsistent in the sense that there is no interpretation satisfying all their axioms.
The problem with having an inconsistent knowledge base is that, by deﬁnition,
it entails any axiom. That is, if K B is inconsistent then the assertion “I (cid:15) K B
implies I (cid:15) α for any I ” is vacuously true because the antecedent of the implication,
namely, I (cid:15) K B , is false. This amounts to the saying that states that anything
follows from a contradiction. In practice, inconsistency is an indicator of modeling
errors.
An important task in DL theory is thus to determine whether or not a given KB
is consistent. We will discuss this and other so-called reasoning tasks in detail in
the next section. Before that, however, let us end this section with an example of
logical consequence.
Consider the following assertion about the movie facts K B :

K B (cid:15) Actor (cid:118) Person .

This assertion states that the axiom Actor (cid:118) Person is logical consequence of the
set of axioms which comprise the K B . Is this assertion true? How can we prove it
or disprove it?
Let us try to disprove it. What we need to do in this case is ﬁnd an interpretation
I which satisﬁes all axioms in K B but which fails to satisfy Actor (cid:118) Person.
For instance, take the previously discussed interpretation I for K B whose domain
consists of the individuals i1 , . . . , i7 . As we have checked a few paragraphs ago,
I (cid:15) K B . But it is not the case that every actor is a person under I . For instance,
facts K B does not entail the axiom Actor (cid:118) Person.
It is usually harder to prove the opposite, that is, that a knowledge base entails a
given axiom α. This amounts to showing that any attempt to ﬁnd an interpretation
which satisﬁes the knowledge base but falsiﬁes α is doomed to failure. For instance,
let us prove that the movie facts K B entails the axiom

i7 ∈ ActorI but i7 (cid:60) PersonI . Hence K B (cid:50) Actor (cid:118) Person, that is, the movie

∃likes.(cid:62)(de-niro).

In other words, let us prove that that once we assume the axioms in the movie facts
K B are true we must conclude, necessarily, that de-niro likes something.
Suppose there is an interpretation J which satisﬁes the movie facts K B but
which does not satisfy the above axiom. From the assumption that J (cid:15) K B , we

8Note that the symbol (cid:15) has diﬀerent meanings depending on the kind of the object that occurs
on its left-hand side. When this object is interpretation, like in I (cid:15) α, the symbol (cid:15) stands for the
satisﬁability relation. When this object is a set of axioms, like in K B (cid:15) α, the symbol (cid:15) denotes the
logical consequence relation.

17

can infer that

J (cid:15) Actor (cid:117) Director(de-niro)
J (cid:15) Director (cid:118) ∃directs.(cid:62)
J (cid:15) directs (cid:118) likes

(14)
(15)
(16)

By (14), we know that the individual denoted by de-niro must be in the set
Director J . And so, by (15), we know that this individual must be directs J -
connected to someone, that is, (cid:104)de-niro J , a(cid:105) ∈ directs J , for some individual a.
Finally, by (16), it must be the case that (cid:104)de-niro, a(cid:105) ∈ likes J , which contradicts
our original assumption that J (cid:50) ∃likes.(cid:62)(de-niro). Hence, we must conclude
that no such J can exist. That is, any interpretation which satisﬁes the movie facts
K B will also satisfy ∃likes.(cid:62)(de-niro), and so K B (cid:15) ∃likes.(cid:62)(de-niro).

2.3 Reasoning tasks

One of the advantages of formalizing a body of knowledge in logic is the possibility
of treating it as a tangible object to which certain operations can be applied. In DL,
the object is the KB (set of axioms) and the operations are reasoning tasks which
attempt to extract new knowledge from it.
An important characteristic of the reasoning tasks of DL, which make them at
same time powerful and complex, is that they follow the open-world assumption
(OWA). Under this assumption, facts which cannot be deduced from a KB are
assumed to be unknown but not necessarily false. This contrasts with the closed-
world assumption (CWA) often adopted in database systems where facts that are not
in the database are assumed to be false. That said, when needed the CWA can be
emulated to some extent in DL via nominals, and there specialized (autoepistemic,
circumscriptive) DLs with support for the CWA.
We will now describe brieﬂy the principal kinds of reasoning tasks for DL. For
a more detailed description (with references) see [30, 2]. A thorough discussion of
the computational complexities associated with these tasks for speciﬁcs DLs can be
found in [40], and a list of software implementing some of the tasks can be found
in [26].

Knowledge base satisﬁability The most fundamental of the DL reasoning tasks
is knowledge base satisﬁability. The goal of this task is to decide whether or not a
given KB is satisﬁable, that is, whether there is an interpretation that satisﬁes all of
its axioms. Some important reasoning tasks, such as axiom entailment, which we
discuss next, can be reduced to KB satisﬁability.
There are basically two kinds of approaches for checking KB satisﬁability. The
model-theoretic approaches try to construct a model for the KB or to show that such
construction must necessarily fail. The proof-theoretic approaches manipulate the
KB syntactically until a contradiction is derived or until a point is reached where
it is guaranteed that no contradiction can be derived. Examples of methods of the

18

ﬁrst kind are the (tree) automata-based methods and the method of the tableaux.
As examples of methods of the second kind we can cite the consequence-driven
methods and those based on resolution.

Axiom entailment The goal of axiom entailment is to decide whether a given
axiom α is a logical consequence of a given KB. This problem can be reduced to
the KB satisﬁability problem in DLs which support negation (such as SR OI Q ). In
DLs without such support this reduction is still possible but requires the emulation
of negation through some notion of opposition between axioms.

Concept satisﬁability and classiﬁcation The goal of the concept satisﬁability

(consistency) is to decide whether a concept C is satisﬁable with respect to a
knowledge base K B . That is, whether there is an interpretation I which satisﬁes
K B and in which C I is populated (not empty). Note that some concepts, such as
C (cid:117) ¬C , by deﬁnition cannot satisﬁed.
A related task is concept classiﬁcation. Its goal to decide whether the concept
names occurring in a KB can be put into a hierarchy according to their subsumption
((cid:118)) relationships. This hierarchical ordering is often a preliminary step executed
before other reasoning tasks and also helps in the visualization of KBs with a large
number of GCIs.

Named instance retrieval The named instance retrieval task takes a knowledge
base K B and a concept C and returns all individual names a such that K B (cid:15) C (a).
That is, it determines all names of individuals which are instances of the concept C
in every model of K B . This task can be extended to roles in which case we search
for pairs of individual names (cid:104)a, b(cid:105) such that K B (cid:15) r (a, b).

Query answering The goal of query answering is to ﬁnd an answer to a query
q in a given knowledge base K B . The query q is speciﬁed as a partial statement
whose missing parts (or blanks—actually, free variables) must ﬁlled with individual
names. An answer to q is a particular ﬁlling which makes K B entail q, that is,
a sequence of individual names which when replaced for the blanks in q makes
K B (cid:15) q. A natural extension of the problem of ﬁnding an answer to a query is the
problem of ﬁnding all possible answers to a query.

Induction and abduction The goal of induction is to analyze the assertional
axioms (those in the ABox) and generalize them by generating corresponding
terminological axioms (GCIs and RIAs). The goal of abduction, on the other hand,
is to determine, given a knowledge base K B and an axiom α not entailed by K B ,
which axioms (satisfying some basic requirements) need to be added into K B so
that K B (cid:15) α. Diﬀerently from the previous tasks, both induction and abduction are
non-truth preserving tasks: the axioms they generate may be falsiﬁed.

19

2.4 Rules

Sometimes the reasoning tasks discussed above are not powerful enough. Some
applications might need to represent relations and allow derivations which go
beyond what can be expressed and achieved with pure DL. For instance, relations
and derivations involving arbitrary computations, such as those involving arithmetic,
or the derivation of facts exactly when some other facts cannot be derived (non-
monotonic inferences).
A common approach to improve the expressivity of a DL is to combine the
axioms in the KB with rules expressed in some rule language. A popular choice of
rule language are Horn clauses—a fragment of ﬁrst-order logic which is also the
basis of the Prolog and Datalog programming languages. For example, the Semantic
Web Rule Language (SWRL), pronounced “swirl”, is essentially a combination of
Datalog and the ontology language OWL. Other combinations of DL with rules
which improve the expressivity of the language (but in this case preserve decidabil-
ity) are the Description Logic Programs (DLP) [11] and Description Logic Rules
(DLR) [18]. For more details on rules, we refer the reader to [15].

2.5 Other DLs

The DL family follows a convention which allows us to determine the features of a
speciﬁc DL from its name. This convention is given by the scheme

((A L C | S ) [H ] | SR ) [O ] [I ] [F | N | Q ],

where parentheses denote grouping, the vertical bar stands for choice, and the square
brackets delimit optional components. The meaning of the letters in the above
scheme is summarized in Table 2 (adapted from [32]).
Besides SR OI Q other popular description logics are the logics A L C and
SH OI Q . A L C [31] is the smallest DL which is boolean-closed, that is, in which
boolean operators can be applied to concepts without restrictions. SH OI Q [2] is
closely related to the ontology language OWL DL (version 1). Note that both A L C
and SH OI Q are sublanguages of SR OI Q .

Spatial and temporal extensions of DL In multimedia representation, we often
need to describe spatial and temporal relations between objects. For instance, when
annotating a particular scene of a ﬁlm we may need to specify the relative position
of the characters in the scene or the temporal sequence of their actions and dialogs.
A simple but expressive formalism for the speciﬁcation of 2D spatial relations
is the region connection calculus (RCC8). The RCC8 [28] describes eight basic
relations which can take place between two regions: disconnected (DC), externally
connected (EC), equal (EQ), partially overlapping (PO), tangential proper part
(TPP), tangential proper part inverse (TPPi), nontangential proper part (NTPP), and
nontangential proper part inverse (NTPPi). These eight relations are depicted in
Figure 2. The A L CI RCC [38] is a family of spatial description logics speciﬁcally

20

Table 2: Features corresponding to the letters in a DL name.

S

H

SR

A L C

Symbol Available/missing features
Missing: RBox axioms, univer-
sal role, role inverses, cardinal-
ity constraints, nominal concepts,
and self concepts.
A L C plus role chain axioms of
the form r ◦ r (cid:118) r for r in NR .
A L C plus role chain axioms of
the form r (cid:118) s .
A L C plus self concepts and all
kinds of RBox axioms.
Available: nominal concepts.
Available: role inverses.
Available: role functionality state-
ments
(expressible as (cid:62) (cid:118)
≤1r .(cid:62)).
Available: cardinality constraints
of the form ≥nr .(cid:62) and ≤nr .(cid:62).
Available: all kinds of cardinality
constraints.

O
I
F

N

Q

Example

¬(LiveAction (cid:116) Animation)

partOf ◦ partOf (cid:118) partOf

remakeOf (cid:118) basedOn

hasParent ◦ hasBrother (cid:118) hasUncle

{universal, disney} (cid:118) Studio
childOf (cid:118) parentOf−
(cid:62) (cid:118) ≤1officialWebsite.(cid:62)

Series (cid:118) ≥2.hasEpisode.(cid:62)

Series (cid:118) ≥2.hasEpisode.Episode

designed to implement the RCC8 relations. Other DLs which can be used for spatial
reasoning are the logics A L C (F) [17] and A L C (CDC) [7]. These two are more
recent proposals which are not based on the RCC.
To describe facts in time we can use one of the temporal DLs. Most of these are
DL extensions with support for the usual operators of temporal logic, such as the
operators ♦ (possibly in the future) and (cid:3) (always in the future). The description
logic A L C -LTL [3] combines A L C and Linear Temporal Logic (LTL), which
adopts a linear (non-branching) notion of time and is usually employed in the
speciﬁcation of dynamic systems. Another temporal DL is DL-CTL [37]; this
combines DL with Computational Tree Logic (CTL) which supports branching time.
There is also an extension of the description logic SH IN that when implemented
in OWL is called tOWL [19]. tOWL supports the representation of time points and
relations between time points and intervals.

Fuzzy extensions of DL Information extracted from multimedia data is often
ambiguous and imprecise. But traditional DLs, which are fragments of classic
ﬁrst-order logic, have no room for ambiguity or imprecision—the logic is boolean:
either some fact is true or it is false. This means that when we use traditional
DLs to represent multimedia data we may lose some important information about

21

Figure 2: The RCC8 relations [32].

uncertainty. Or worse, we may create some misleading sense of certainty where
no such certainty really exists. One way to tackle this problem is to represent
uncertainty in the logic.
The fuzzy logics are particular kind of many-valued (non-boolean) logics whose
semantics involve a notion of truth degrees. These degrees function as additional
shades of gray between the boolean true and false, which can be used to formalize
vagueness and imprecision. There are many fuzzy extensions of DL. We will not
describe the here but we refer the reader to [5].

3 Semantic Web Technologies

The term Semantic Web refers to an eﬀort initiated in the early 2000s to extend the
traditional Web, then a global library of interlinked HTML documents, to enable
the semantic description and processing of these documents. Two decades later, the
Web has become a much more diverse and complex environment, and the success
and feasibility of the Semantic Web vision is somewhat debatable. What is not
debatable, though, is the success of the standards and technologies developed in this
period. Nowadays, it has become common to associate the term Semantic Web with
these standards and technologies.
In this section, we will describe the core technologies of the Semantic Web.
These can be organized as a stack, as depicted in Figure 3, where the technologies
appearing on the top layers build on those which appear on the bottom layers.
Although we will touch upon most of these technologies, we will focus on the ones
depicted in bold font in the ﬁgure, namely, RDF, SPARQL, and OWL, with a special
emphasis on the latter.

22

SWRL

OWL

SPARQL

RDF, RDFS

XML, Turtle, . . .

URI, IRI, Unicode

Figure 3: The Semantic Web stack.

3.1 RDF

One of the principal standards of the Semantic Web is the Resource Description
Framework (RDF) [39]. RDF is a graph-based representation language. It provides
a vocabulary and constructors for describing sets of triples denoting directed graphs.
These triples are called s-p-o triples and have the form
(cid:104)subject, predicate, object(cid:105) .
Here are three s-p-o triples describing, respectively, the type, size in bytes, and
title associated with an audio ﬁle:
(cid:104)song.mp3, type, Music(cid:105), (cid:104)song.mp3, size, 10240(cid:105), (cid:104)song.mp3, title, “9th Symphony”(cid:105) .
And here is the graph corresponding to these three s-p-o triples:

type

Music

song.mp3

size

10240

title

“9th Symphony”

Each triple stands for a directed edge in the graph. The subject of the triple becomes
the source of the edge, the object becomes its target, and the predicate becomes the
edge label.
Of course, this is just an abstract example. In an actual RDF graph the compo-
nents of the triples, that is, the labels of nodes and edges in the graph, must obey
a speciﬁc format (or syntax). A popular textual syntax for RDF is Turtle (Terse
RDF Triple Language) [6]. Turtle is an alternative to the widely supported but
cumbersome RDF/XML syntax. All of our RDF examples will be written in Turtle.
There are three kinds of nodes in an RDF graph: IRI nodes, literal nodes, and
blank nodes. An IRI node is a node labeled by an IRI (Internationalized Resource
Identiﬁer); an IRI is a generalization of URI to support Unicode characters. Here is
an example IRI:

https://pt.wiktionary.org/wiki/maçã

23

Note the non-ASCII characters “ç” and “ã” above. In an RDF graph, IRIs are used
to denote arbitrary resources, such as physical objects, documents, images, abstract
concepts, numbers, strings, etc.
The second kind of node which can appear in an RDF graph is the literal node.
A literal node is any node labeled by a literal, that is, a quoted string denoting a
value in-place. In the Turtle syntax, literals are written enclosed in double quotes
optionally accompanied with language tags and type tags. Here are three RDF
literals (written in Turtle):

"Rock", "maçã"@pt, "10240"^^xsd:integer.

The ﬁrst is a plain literal, the second is a literal with a language tag (Portuguese
in this case), and the third is a literal with a type tag, also called typed literal. The
preﬁx xsd:, which occurs in the third literal above, stands for the namespace where
the type tag integer is deﬁned. We will have more to say about namespaces in a
moment.
The third kind of node that can occur in an RDF graph is the blank node. A
blank node has no speciﬁc denotation; it is an unlabeled node which is neither an IRI
nor literal node. Blank nodes are often used as dummy nodes whose only purpose
is to ease the encoding of complex structures in graphs.
In an RDF triple (cid:104)s, p, o(cid:105) the subject s must be an IRI or blank node, the predicate
p must be an IRI, and the object o must be an IRI, literal, or blank node. When we
assert an RDF triple we are saying informally that “the relationship indicated by
the predicate holds between the resource denoted by the subject and the resource or
value denoted by the object”.
Figure 4 presents a possible Turtle encoding for the graph describing the audio
ﬁle “song.mp3” depicted a few paragraphs ago. 9 Each edge in the graph (that is,
triple in the set) becomes a corresponding triple in the Turtle document (lines 5–7).
The subject, predicate, and object parts are separated by spaces and each triple is
terminated with a dot (.). Note that IRIs are written between angle brackets <...>.

1

2

3

4

5

6

@base <http://example.org/data/> .
@prefix ex: <http://example.org/#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

<song.mp3> ex:type ex:Music .

<song.mp3> ex:size "10240"^^xsd:integer .
<song.mp3> ex:title "9th Symphony" .

Figure 4: Turtle encoding of the RDF triples describing “song.mp3”.

The directives in lines 1–3 of Figure 4 deﬁne the namespaces of the document.
That is, they specify how relative and preﬁxed IRIs are to be interpreted. The

9Sometimes literals are represented as rectangles when depicting an RDF graph. Incidentally, we
did not follow this convention when depicting the graph describing “song.mp3”.

24

directive @base deﬁnes the base IRI of the whole Turtle document. Any relative
IRI occurring in the document is to be interpreted as relative to this base IRI. So,
for instance, the occurrences of <song.mp3> in lines 4–6 of Figure 4 are to be
interpreted as the absolute IRI:

http://example.org/data/song.mp3

The directive @prefix introduces preﬁx labels which can be used to abbreviate
IRIs. So, in Figure 4, the labels ex: and xsd: stand for the following IRI preﬁxes:

http://example.org/#
http://www.w3.org/2001/XMLSchema#

Note that preﬁxed IRIs are not written between angle brackets.
Turtle has a number of other features. Some of these are useful for avoiding te-
dious repetitions within the document. For instance, Figure 5 uses some of these fea-
tures to deﬁne in fewer lines the same graph as Figure 4. Note the semicolons “;” in
lines 3 and 4 of Figure 5. These are used to separate predicate-object pairs referring
to the same subject; in this case, the IRI http://example.org/data/song.mp3.
This type of construction is called a predicate list. Note also the typed literal
10240 in line 4. Some common types of literals, such as integers and ﬂoating-point
numbers, can be written in Turtle in their usual syntaxes.

1

2

3

4

5

@prefix ex: <http://example.org/#> .
<http://example.org/data/song.mp3>

ex:type ex:Music ;
ex:size 10240 ;

ex:title "9th Symphony" .

Figure 5: Example of Figure 4 rewritten using predicate lists.

It is important to realize that an RDF graph is just a data structure, and that
Turtle, RDF/XML, and the other syntaxes for RDF are just ways to encode this data
structure in a string. More importantly, the meanings of the labels which occur in
an RDF graph are not deﬁned in the RDF standard. These labels might indicate
something to the person reading them, but to a computer that understands only RDF
these labels are meaningless strings—they serve only to identify and distinguish
speciﬁc components of the graph.
There is another standard, called RDF Schema (RDFS) [13], deﬁned on top
of RDF, which speciﬁes a basic vocabulary (set predeﬁned terms) and associated
meanings. This vocabulary can be found in the namespace:

http://www.w3.org/2000/01/rdf-schema#

It provides a set of basic terms which can be used to deﬁne more specialized terms
whose meaning is given by describing their interrelations with other terms. (Note

25

that we used a similar approach in Section 2 when we introduced strings representing
concepts and roles, such as Director and directs, and then deﬁned their meaning
via GCIs and RIAs relating them with other terms.)
RDFS is sometimes called a lightweight ontology language because it allows
us to specify ontologies (machine-processable speciﬁcations of conceptualizations
with a formally deﬁned meaning) using a relatively small vocabulary with a simple
semantics. This might be suﬃcient for certain applications but, in general, sophisti-
cated applications require more powerful ontology languages. The natural choice
in this case is OWL, also a Semantic Web technology. We will describe OWL in
Section 3.3. Before that, however, let us present SPARQL, a language for querying
RDF graphs.

3.2 SPARQL

In the previous section, we showed an RDF graph consisting of four nodes and
three edges. When working with such small graphs one hardly needs to worry
about eﬃciency. But, in practice, RDF graphs are rarely small. It is not uncommon
to ﬁnd applications that deal with graphs containing millions of nodes and edges.
For such applications simple tools will not do. They need specialized tools, in
particular, specialized databases, called graph databases and triple stores, designed
to eﬃciently keep and process large amounts of RDF data.
SPARQL (SPARQL Protocol and RDF Query Language) is to graph databases
and triple stores what SQL is to relational databases. It is a declarative interface for
querying and manipulating the contents of the database/graph [12]. There are two
main kinds of SPARQL queries: graph pattern matching and graph navigation. We
will discuss each of these next.

Graph pattern matching A graph pattern matching query is a query that searches
for a given (bounded) structural pattern in the graph. In SPARQL, these structural
patterns are expressed as triple patterns, which are RDF triples in which the subject,
predicate, or object may be a variable (name starting with “?”). A basic graph
pattern (BGP) is the combination of one or more triple patterns.
Consider the RDF graph depicted in Figure 6, which describes the ﬁlm Taxi
Driver. Suppose we want to list all pairs of distinct persons who acted in this ﬁlm.
We can specify this query in SPARQL as follows:

1

2

3

4

5

6

7

8

PREFIX: <http://example.org/#>
SELECT ?x1 ?x2
WHERE {
?x1 :actsIn ?x3 . ?x1 :type :Person .
?x2 :actsIn ?x3 . ?x1 :type :Person .
?x3 :title "Taxi Driver" . ?x3 :type :Movie .
FILTER (?x1 != ?x2)

}

26

:Movie

“Taxi Driver”

:actsIn

:type

:title

:scorsese

:taxi-driver

:actsIn

:de-niro

:directs

:type

:Person

:type

Figure 6: RDF graph describing Taxi Driver.

This query expresses a BGP consisting of six triple patterns. It select all pairs of
labels x1 and x2 (line 2) with x1 (cid:44) x2 (line 7) such that, for some label x3 , each of
the following triples occur in the graph:

(cid:104) x1, :actsIn, x3 (cid:105)
(cid:104) x2, :actsIn, x3 (cid:105)
(cid:104) x3, :title, "Taxi Driver"(cid:105)

and
and
and

(cid:104) x1, :type, :Person(cid:105)
(cid:104) x2, :type, :Person(cid:105)
(cid:104) x3, :type, :Movie(cid:105)

(line 4)
(line 5)
(line 6)

If we apply this query to the graph of Figure 6 we get the following result:

1

2

3

4

?x1
?x2
---------------------
:scorsese
:de-niro
:de-niro
:scorsese

That is, our answer set consists exactly of two pairs of labels: one where x1 is
:scorsese and x2 is :de-niro (line 3 in the result), and another where x1 is
:de-niro and x2 is :scorsese (line 4 in the result).

Graph navigation The other common kind of query supported by SPARQL are
graph navigation queries. These are queries that navigate the topology of the graph
through paths of potentially arbitrary lengths. A path query is a basic navigation
query of the form x α−→ y that retrieves all pairs (cid:104) x, y (cid:105) such that there is a path in
the graph from x to y which satisﬁes a given condition α.
For instance, the path queries

:actsIn ◦ :type

−−−−−−−−−−−→ y

x

:directs

−−−−−−−→ y

x

and
search, respectively, for all nodes x and y such that there is an edge labeled
:directs from x to y , and for all nodes x and y such that there is path of size two
from x to y where the ﬁrst edge in the path is labeled :actsIn and the second edge
is labeled :type. (Recall that a path in a graph is a sequence of edges joining a
sequence of nodes.).
We can specify the latter query in SPARQL as follows:

27

SELECT ?x ?y
WHERE ?x (:actsIn/:type) ?y

Here the symbol “/” stands for chaining and corresponds to the “◦” we used in the
abstract notation. If we apply this SPARQL query to the graph of Figure 6 we get
answer:

?x
?y
------------------
:scorsese :Movie
:de-niro
:Movie

For a more interesting example, consider the path query

(:actsIn ◦ :actsIn− )+

−−−−−−−−−−−−−−−−→ y .

x

This query searches for all actors who have a ﬁnite collaboration distance 10 , that
is, actors x and y such that x and y are co-stars in the same movie (distance 0), or
x and y are co-stars of the same z in some movie (distance 1), or x is co-star of
some z1 in some movie and y is co-star of some z2 in some movie and z1 and z2 are
co-stars in the same movie (distance 2), and so on. The following SPARQL code
implements this query:

SELECT ?x ?y
WHERE ?x (:actsIn/^:actsIn)+ ?y

Here the symbol “^” denotes the inverse of an edge label (the symbol “−” we used
in the abstract notation) and “+” stands for one or more repetitions of the pattern
immediately preceding it.
Suppose we add the following triples to the graph of Figure 6:

(cid:104):de-niro, :actsIn, :cassino(cid:105)

and

(cid:104):sheron-stone, :actsIn, :cassino(cid:105) .

If we run the above SPARQL query over this updated graph we get the answer:

?x
?y
-----------------------------
:scorsese
:de-niro
:de-niro
:scorsese
:de-niro
:sharon-stone
:sharon-stone
:de-niro
:scorsese
:sharon-stone
:sharon-stone
:scorsese

10When x is the actor Kevin Bacon this distance is known as the Bacon distance or Bacon degree.

See: https://en.wikipedia.org/wiki/Six_Degrees_of_Kevin_Bacon

28

SPARQL has many more features, such as groups, options, alternatives, ﬁlters,
etc., which can be combined with basic graph patterns and navigation operators in
order to build complex queries. Our goal here was to provide a glimpse of SPARQL
queries. For a detailed introduction to SPARQL, see [15]. Besides SPARQL, there
are many other languages for querying graphs. See [1] for a general discussion
of these. For a practical introduction to graph databases and triple stores, we
recommend [29].

3.3 OWL

Web Ontology Language (OWL) is a family of ontology languages whose syntax
and (formal) semantics is standardized [35]. Recall that an ontology is a set of
precise descriptive statements about some part of the world—statements like those
of description logic. OWL is based on description logic but also has many features
which go beyond pure DL, such as datatypes and features for versioning and anno-
tating ontologies. Here we will focus on version 2 of OWL (called OWL 2). This is
the most recent version and it is fully compatible with the previous version.
There are three sublanguages of OWL, also called species: OWL Full, OWL DL,
and OWL Lite. OWL Full contains both OWL DL and OWL Lite, and OWL DL
contains OWL Lite. What distinguishes these three sublanguages is their degree of
expressivity and, consequently, the computational cost of their associated reasoning
tasks.
As with any language, in order to present OWL we will need to pick a particular
syntax. Here we will use the RDF/Turtle syntax. Any OWL document written in
this syntax is also a valid RDF document. Besides RDF, other common syntaxes
for OWL are the functional-style syntax and the Manchester syntax. However, the
only syntax that is mandatory to be supported by all OWL 2 tools is the RDF/XML
syntax [14].
Next, we will present the speciﬁc terms and semantics of OWL via translations
from DL. (An OWL 2 DL ontology is essentially an SR OI Q knowledge base.)
Before doing that, however, we must clear up some terminological conﬂicts. For
historical reasons, OWL and DL sometimes use diﬀerent terms to refer to the same
objects. These terminological diﬀerences are summarized in Table 3.

From SR OI Q to OWL 2 DL The translation of an SR OI Q knowledge base
into an OWL document consists of three steps. 11 First, we need to preﬁx to the
document the following namespace declarations:

@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .

The preﬁxes rdfs:, rdf:, and xsd: are necessary because OWL reuses terms from

29

Table 3: Terminological diﬀerences between OWL and DL.
OWL
DL
class name
concept name
class
concept
object property name
role name
object property
role
ontology
knowledge base
axiom
axiom
vocabulary
vocabulary/signature

these namespaces.
The second thing we need to do is add to the OWL document typing statements
for the concept names and role names that occur in the KB. That is, for each concept
name C occurring in the KB, we add to the document the triple:

C rdf:type owl:Class .

And for each role name r occurring in the KB, we add the triple:

r rdf:type owl:ObjectProperty .

the IRI http://example.org/movie-facts#.

Figure 7 shows the OWL document corresponding to the SR OI Q movie facts
KB presented at the end of Section 2.1. The typing statements in lines 7–13 were
generated by the above translations. Note that due to the @prefix directive in line 5,
IRIs with an empty preﬁx label such as :Actor are to be interpreted as preﬁxed by
The third step to translate an SR OI Q knowledge base to OWL is the most
complicated of the three: we need to translate the axioms that occur in each of the
boxes. The complexity in this case stems from the rich syntactical structure of GCIs
and RIAs, which cannot be directly encoded in RDF. To rewrite GCIs and RIAs in
RDF we will need to use blank nodes and techniques for encoding lists in graphs.
The precise translation of arbitrary SR OI Q axioms into OWL is given by
function (cid:110) (cid:111) below:

(cid:110)r1 ◦ · · · ◦ rn (cid:118) r (cid:111) = (cid:110)r (cid:111)R owl:propertyChainAxiom ( (cid:110)r1(cid:111)R . . . (cid:110)rn (cid:111)R ) .

(cid:110)Sym(r )(cid:111) = (cid:110)r (cid:111)R owl:type owl:SymmetricProperty .
(cid:110)Asy(r )(cid:111) = (cid:110)r (cid:111)R owl:type owl:AsymmetricProperty .
(cid:110)Tra(r )(cid:111) = (cid:110)r (cid:111)R owl:type owl:TransitiveProperty .
(cid:110)Ref(r )(cid:111) = (cid:110)r (cid:111)R owl:type owl:ReflexiveProperty .
(cid:110)Irr(r )(cid:111) = (cid:110)r (cid:111)R owl:type owl:IrreflexiveProperty .
(cid:110)Dis(r, s)(cid:111) = (cid:110)r (cid:111)R owl:propertyDisjointWith (cid:110)s(cid:111)R .

11The translations we present here were adapted from Sebastian Rudolph’s excellent text [30].

30

(cid:110)C (cid:118) D(cid:111) = (cid:110)C (cid:111)C rdfs:subClassOf (cid:110)D(cid:111)C .

(cid:110)C (a)(cid:111) = a rdf:type (cid:110)C (cid:111)C .
(cid:110)r(a, b(cid:111) = a r b .
(cid:110)r− (a, b)(cid:111) = b r a .
(cid:110)¬r (a, b)(cid:111) = [] rdf:type owl:NegativePropertyAssertion ;
owl:assertionProperty (cid:110)r (cid:111)R ;
owl:sourceIndividual a ;

owl:targetIndividual b .

(cid:110)a ≈ b(cid:111) = a owl:sameAs b .
(cid:110)a (cid:48) b(cid:111) = a owl:differentFrom b .

where the auxiliary functions (cid:110) (cid:111)R and (cid:110) (cid:111)C are used to translate SR OI Q roles
and concept expression. These auxiliary functions are deﬁned as follows:

(cid:110)u(cid:111)R = owl:topObjectProperty
(cid:110)r−(cid:111)R = [ owl:inverseOf :r ]

(cid:110)r(cid:111)R = r

(cid:110)C(cid:111)C = C

(cid:110)(cid:62)(cid:111)C = owl:Thing
(cid:110)⊥(cid:111)C = owl:Nothing
(cid:110){a1, . . . , an }(cid:111)C = [ rdf:type owl:Class ; owl:oneOf( :a1 . . . :an )]
(cid:110)¬C (cid:111)C = [ rdf:type owl:Class ; owl:complementnOf (cid:110)C (cid:111)C ]
(cid:110)C1 (cid:117) · · · (cid:117) Cn (cid:111)C = [ rdf:type owl:Class ; owl:intersectionOf ( (cid:110)C1(cid:111)C . . . (cid:110)Cn (cid:111)C )]
(cid:110)C1 (cid:116) · · · (cid:116) Cn (cid:111)C = [ rdf:type owl:Class ; owl:unionOf ( (cid:110)C1(cid:111)C . . . (cid:110)Cn (cid:111)C )]
(cid:110)∃r .C (cid:111)C = [ rdf:type owl:Restriction ;
owl:onProperty (cid:110)r (cid:111)R ; owl:someValuesFrom (cid:110)C (cid:111)C ]
(cid:110)∀r .C (cid:111)C = [ rdf:type owl:Restriction ;
owl:onProperty (cid:110)r (cid:111)R ; owl:allValuesFrom (cid:110)C (cid:111)C ]
(cid:110)∃r .Self(cid:111)C = [ rdf:type owl:Restriction ;
owl:onProperty (cid:110)r (cid:111)R ; owl:hasSelf true ]
(cid:110)≥nr .C (cid:111)C = [ rdf:type owl:Restriction ;
owl:minQualifiedCardinality n ;
owl:onProperty (cid:110)r (cid:111)R ; owl:onClass (cid:110)C (cid:111)C ]
(cid:110)≤nr .C (cid:111)C = [ rdf:type owl:Restriction ;
owl:maxQualifiedCardinality n ;
owl:onProperty (cid:110)r (cid:111)R ; owl:onClass (cid:110)C (cid:111)C ]

31

Two remarks on the above translation are in order. First, note that individual
names, concept names, and role names are kept as is by (cid:110) (cid:111), (cid:110) (cid:111)R , and (cid:110) (cid:111)C . For
simplicity, we assume that these names are deﬁned in the namespace of the empty
preﬁx.
Second, note that complex role and concept expressions are translated by (cid:110) (cid:111)R
and (cid:110) (cid:111)C as subgraphs identiﬁed by a blank node. In Turtle, these blank nodes
are introduced by the square brackets. So, for instance, the role r− becomes the
subgraph

owl:inverseOf

r

in which the blank node on the left-hand side stands for the inverse of r. Similarly,
the complex concept ≥2knows.Actor is translated as the subgraph

rdf:type

owl:min
Qualified
Cardinality

owl:onClass

owl:on
Property

owl:Restriction

2

knows

Actor

Again, the blank node above stands for the complex concept as a whole.
The result of using function (cid:110) (cid:111) to translate the axioms in the movie facts KB
is depicted in Figure 7. The translated ABox axioms are listed in lines 16–28, the
TBox axioms in lines 31–53, and the RBox axioms in lines 55–56.

Emulating the additional axiom types of OWL in SR OI Q The features of

OWL used by the previous translation algorithm are suﬃcient for representing any
SR OI Q axiom in OWL. But OWL has many more features, including further types
of logical axioms which have no direct counterpart in SR OI Q . The extra types of
logical axioms of OWL are useful in practice, but they do not add new capabilities
from the point of view of the logic. That is, they are just a syntactic sugar that can
always be rewritten in terms of the types of axioms available in SR OI Q . See [30]
for details.

Tools for manipulating ontologies

If we load the Turtle ﬁle of Figure 7 on
Protégé 12 and ask for a graph of the ontology, we get the following:

32

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56

@prefix owl:
@prefix rdfs:
@prefix rdf:
@prefix xsd:
@prefix :

<http://www.w3.org/2002/07/owl#> .
<http://www.w3.org/2000/01/rdf-schema#> .
<http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
<http://www.w3.org/2001/XMLSchema#> .
<http://example.org/movie-facts#> .

rdf:type
rdf:type
rdf:type
rdf:type
rdf:type
rdf:type
rdf:type

owl:Class .
owl:Class .
owl:Class .
owl:ObjectProperty .
owl:ObjectProperty .
owl:ObjectProperty .
owl:ObjectProperty .

rdf:type
rdf:type

rdf:type

:Director .
[rdf:type owl:Class ;
owl:intersectionOf (:Actor :Director)] .
[rdf:type owl:Restriction ;
owl:minQualifiedCardinality 2 ;
owl:onProperty :knows ; owl:onClass :Actor ] .
:space-odyssey .
owl:NegativePropertyAssertion ;
owl:assertionProperty :directs ;
owl:sourceIndividual :kubrick ;
owl:targetIndividual :taxi-driver .
owl:sameAs
:stanely .
owl:differentFrom
:de-niro .

:directs
rdf:type

:Actor
:Director
:Person
:actsIn
:directs
:knows
:likes

# Abox

:kubrick
:de-niro

:stanley

:kubrick

[]

:kubrick
:kubrick

# TBox

:Director

rdfs:subClassOf

[rdf:type owl:Restriction ;
owl:onProperty :directs ;
owl:someValuesFrom owl:Thing]
rdfs:subClassOf
rdfs:subClassOf
rdfs:subClassOf

:Director
:Director

[rdf:type owl:Restriction ;
owl:onProperty :directs ;
owl:someValuesFrom owl:Thing] .

:Director .
:Person .
[rdf:type owl:Restriction ;
owl:minQualifiedCardinality 1 ;
owl:onProperty :knows ;
owl:onClass :Actor] .

[rdf:type owl:Class ;
owl:intersectionOf

([rdf:type owl:Restriction ;
owl:onProperty :directs ;
owl:someValuesFrom owl:Thing]
[rdf:type owl:Restriction ;
owl:onProperty :directs ;
owl:allValuesFrom [rdf:type owl:Class ;
owl:oneOf (:a-bronx-tale
:good-shepherd)]])]

rdfs:subClassOf

[rdf:type owl:Class ;
owl:oneOf (:de-niro)] .

# RBox

:likes
:knows

owl:propertyChainAxiom
owl:propertyChainAxiom

(:directs) .
(:directs [owl:inverseOf :actsIn]) .

Figure 7: OWL corresponding to the movie facts KB of Section 2.1.

33

Here the nodes with a yellow circle stand for the concepts (classes), the nodes
with purple diamonds stand for individuals, and the colored arrows denote speciﬁc
relationships between them. For instance, the blue arrow from Person to Director
represents the “has subclass” relationship. The yellow box above, with additional
information about kubrick, is the tool-tip displayed by Protégé when we hover the
mouse cursor over a particular node or edge of the graph.
Protégé is the most widely used ontology editor. It supports many plugins for
ontology visualization, debugging, and reasoning. Besides Protégé, there are many
other tools for designing and implementing ontologies. For a comprehensive list,
see [15] and [36].

Linked data and knowledge graphs Over the years the Semantic Web vision
has changed its focus from the description of linked documents to the description
of linked data in general. The term linked open data (LOD) has been used to
refer to open datasets of linked data, such as DBpedia 13 (derived from Wikipedia),
Wikidata 14 (curated by the Wikimedia Foundation), etc. Most of these datasets
adopt the technologies we have been discussing, but they are usually not ontologies
in the strict sense.
Another term often associated with linked data is knowledge graph. This is a
general term which alludes to the fact that the system or database to which the term
is applied uses a graph to represent knowledge. In this sense, an OWL document
encoded in RDF is a knowledge graph. Being a knowledge graph does not imply
being an ontology. For instance, the graph depicted in Figure 6 is a knowledge
graph, but it is certainly not an ontology.

12https://protege.stanford.edu/
13https://wiki.dbpedia.org/
14https://www.wikidata.org/

34

General purpose

Vocabulary/Ontology
Language
Descriptor-derived Content Ontology for the TV-Anytime Content OWL
Content Ontology for the TV-Anytime Format
OWL
Core Ontology for Multimedia (COMM)
OWL
Visual Descriptor Ontology (VDO)
OWL
Dublin Core
RDFS
FOAF
OWL
Schema.org
OWL
SUMO
SUO-KIF
WordNet 3.x
OWL
3D Modeling Language (3DMO)
OWL 2
Audio Eﬀects Ontology (AUFX-O)
OWL
Linked Movie Database (LMD)
RDFS
Multimedia Metadata Ontology (M3O)
OWL
Ontology for Media Resources
OWL
Video Ontology (VidOnt)
OWL

Specialized

Table 4: Some vocabularies and ontologies for multimedia.

Ontologies for multimedia There are numerous ontologies for describing multi-
media. We can classify these broadly into three groups: descriptor-derived, general
purpose, and specialized ontologies. The ontologies in the ﬁrst group are those de-
rived from classic metadata descriptors standards, such as MPEG-7, MPEG-21, and
TV-Anytime. These ontologies are complex, limited in terms of expressivity, and
have design issues (they often do not follow good practices of ontology engineering).
The ontologies on the second group tend to be more mature and well-deﬁned. On
the other hand, as those in the ﬁrst group, the ontologies in the third group are also
problematic. They often have conceptualization problems, for instance, their is
scope is unclear, and usually do not reuse terms from more general (upper-level)
ontologies, which is considered bad practice.
Table 4 lists some of the ontologies in the three groups. For more details on
these, such as references, a discussion of their pros and cons, etc., see [32].
The point of using one of these open ontologies is, of course, to reuse their
terms and deﬁnitions instead constructing everything from scratch. For instance,
using Schema.org and Dublin Core we can rewrite the RDF describing the audio
ﬁle “song.mp3” (Figure 5) as follows:

@prefix dc: <http://purl.org/dc/elements/1.1/> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix schema: <http://schema.org/> .
<http://example.org/data/song.mp3> rdf:type schema:AudioObject ;
schema:contentSize "10240" ;
dc:title "9th Symphony" .

Note that we can use URI fragments [27] to refer to speciﬁc parts of the resource

35

being described. For instance, if we want to indicate that the key of some particular
segment, say from 10s to 20s, of “song.mp3” is C Major, we can write:

@prefix keys: <http://purl.org/NET/c4dm/keys.owl#>
@prefix mo:
<http://purl.org/ontology/mo/>
<http://example.org/data/song.mp3#t=10,20> mo:key keys:CMajor .

where mo:key and keys:CMajor are terms from the Music Ontology 15 . Similarly,
we can refer to spatial fragments of resources using URI fragments of the form
#xywh=x,y,w ,h . We will have more to say about the description of media objects
and their parts in next section.

4 A Hybrid Approach: Hyperknowledge

IBM Hyperlinked Knowledge Graph [25], or Hyperknowledge for short, is a hybrid
model for knowledge representation that permits the speciﬁcation and interlinking
of data objects and concepts. It extends the Nested Context Model (NCM) [33], a
classic hypermedia model, with constructs that combine features from the domains
of hypermedia and knowledge representation. To better understand why the Hyper-
knowledge model was proposed, let us brieﬂy discuss the main concerns of these
two communities.
The hypermedia community has been concerned with the deﬁnition of models
and languages for expressing relationships among media objects (texts, images,
videos, etc.). In languages such as HTML, NCL, SMIL, and SVG we can specify
how diﬀerent objects interact with each other and with users but we cannot link
these objects to the concepts they represent—at least not directly. Also, we cannot
describe in these languages ontologies like those discussed in Section 2. Metadata
standards (such as MPEG-7, MPEG-21, SMPTE, EXIF, etc.) have been proposed as
a solution to combine the media content and semantics, but these standards usually
focus on low-level features, such as codecs, bit-rates, color spaces, etc.
The knowledge representation community, on the other hand, has focused on
the development of models for representing facts about the world and on methods
for querying and inferring things from these models. Applications in the knowledge
engineering domain tend to assume that knowledge bases are composed purely of
facts and often disregard any (multimedia) data that might be related to these facts.
For instance, we can use RDF or OWL for encoding facts in a knowledge base, but
the multimedia content described by these facts is usually kept in separated bases,
which are handled by diﬀerent tools and systems.
The goal of the Hyperknowledge model is to unify hypermedia and knowledge
representation, and with this to enable the development of both semantic-aware
multimedia applications and multimedia-aware knowledge bases.

15http://musicontology.com/

36

TBox-Context

directs

Directable

subclass

Director

subclass

Person

knows

Movie

subclass

Actor

acts-in

ABox-Context

directs

kubrick

is-a

Director

space-odyssey

knows- ≥2

stanley

Actor

de-niro

is-a-(cid:117)

Figure 8: A Hyperknowledge base corresponding to the movie facts KB.

4.1 Hyperknowledge in a nutshell

The entities of the Hyperknowledge model are inherited from the NCM [33]. These
entities comprise anchors, (atomic) nodes, compositions, links, and connectors. We
will introduce each of these entities through an example. Figure 8 shows a possible
representation in Hyperknowledge of a part of the movie facts KB, presented at the
end of Section 2. For simplicity, here we adopt the closed world assumption, that
is, we assume that facts not represented in the ﬁgure are false. (We discussed this
assumption and the more general open world assumption in Section 2.3.)
A Hyperknowledge context is a container element that groups related elements
and relationships. The characterization of related entities and the decision of
grouping them into contexts is a modeling decision which depends on the application.
In Figure 8, the contexts are depicted as the bounding boxes enclosing the other
elements. There are two contexts in this ﬁgure. Context TBox-Context contains
the elements and relationships that correspond to the TBox of the movie facts
KB. The other context, ABox-Context, contains the elements and relationships
corresponding to the ABox.
The ellipses and smaller rectangles in Figure 8 stand for atomic nodes. These
can represent either concepts (ellipses) or data (rectangles). Here we use the word
concept in the same sense in which it is used in DL. That is, a concept (or class in
OWL terminology) represents an abstract characteristic of certain individuals. In

Figure 8, all nodes in TBox-Context, namely, Person, Director, Actor, Movie,

37

and Directable, are concept nodes.
The other kind of atomic nodes which occur in Figure 8 are data nodes. A data
node is a node containing some data content. In the ﬁgure, the data nodes are the
rectangles labeled de-niro, kubrick, and space-odyssey, which occur in the
ABox-Context. The idea in this example is that data nodes stand for multimedia
content. For instance, de-niro and kubrick might refer to a JPEG picture of the
corresponding movie directors, and space-odyssey might refer to an Ogg video
of the corresponding ﬁlm.
The dashed nodes in Figure 8 are neither concept nodes nor data nodes; they
stand for references. That is, they are nodes that refer to other nodes, allowing that
the latter be reused in other situations (contexts). So, for instance, the concept nodes
Actor and Director, which are deﬁned in the TBox context, are reused in the
ABox context. Similarly, node stanley of the ABox context is a reference to the
node kubrick in the same context. The idea here is that anything which operates
over stanley is actually operating over kubrick.
This type of indirection is useful in cases where the same entity is associated
with diﬀerent names in possibly diﬀerent contexts. For instance, the singer and
song-writer Bob Dylan has recorded some folk songs under the pseudonym of Blind
Boy Grunt. Any references to Blind Boy Grunt are essentially references to Bob
Dylan. But the distinction between them might be important for some applications.
Back to Figure 8, the arrows in the ﬁgure stand for links representing relation-
ships between nodes. Each link is associated with a connector (not represented in
the ﬁgure) which deﬁnes the link type. A connector deﬁnes an abstract relation
and associates with it a label and zero or more restrictions. A link can be seen as
an instance of its connector, that is, as an actual realization of the abstract relation
deﬁned by the connectors.
In the ﬁgure, the link in the TBox context between Actor and Person labeled
“subclass” expresses the fact that every instance of Actor is also an instance of a
Person. In other words, it encodes the TBox axiom Actor (cid:118) Person. Similarly,
the link “directs” between Director and Directable encodes the TBox axiom

Director (cid:118) ∃directs.(cid:62).

Unlike the edges of RDF graphs, which are necessarily binary, Hyperknowledge
links can connect more than two entities. For instance, in Figure 8 the link “is-a-(cid:117)”
in the ABox context connects de-niro to both Actor and Director, and serves
to encode the ABox axiom Actor (cid:117) Director(de-niro).

4.2 HSL and HyQL

The Hyperknowledge model is accompanied by a speciﬁcation language, called
HSL, and a declarative query language, called HyQL. We will now present both of
these technologies.

HSL HSL (Hyperknowledge Speciﬁcation Language) is a language for the speci-
ﬁcation of hyperknowledge representations, which can be stored in hyperknowledge

38

bases, or HK bases. Figure 9 depicts the HSL document in JSON syntax corre-
sponding to the HK base of Figure 8.
An HSL document consists of a tree of elements. In the JSON syntax, each
element is an array of the form:

[tag, id, {attrs}, [children]]
where tag is the element tag (“hsl”, “connector”, “context”, “node”, etc.), id is
the element id, attrs is a key-value map of element attributes, and children is a
list of child elements. Depending on the tag, any of the last three components, id,
attrs, or children, are optional. The meaning and allowed values for each of these
components also varies from tag to tag. Instead of giving the full syntax of HSL,
we will introduce its main elements using Figure 9 as a guide.
The root element of an HSL document is element “hsl” (line 1 of Figure 9).
Three kinds of elements may appear inside the root: connectors, contexts, and
atomic nodes. A connector speciﬁes the format of the links of the document. For
each distinct link (arrow) label in Figure 8 there is a connector in the HSL document.
For instance, the connectors with ids “subclass”, “is-a”, and “is-a-cap” (lines 2–11)
deﬁne the homonymous relations and are referenced by the links on lines 21–25 and
45–49.
Each context (bounding box) in Figure 8 becomes a “context” element in the
HSL document (lines 14–29 and 31–54) and the concepts (ellipses) and data objects
(rectangles) of Figure 8 become “node” elements inside the corresponding contexts.
For instance, the concept Director in the TBox context becomes the node with id
“Director” and type attribute “Concept” (line 17). The data object kubrick in the
ABox context becomes the node with id “kubrick”, type “Data”, and content URI
“http://example.org/kubrick.jpg” (lines 32–33). Note that node references—dashed
ellipses and dashed rectangles in Figure 8—become nodes of type “Reference”
(lines 34–39) with the “refer” attribute deﬁning the id of the target node.
The links (arrows) of Figure 8 become “link” elements in the HSL document.
Each link must reference one of the connectors deﬁned just below the root element
of the document. For instance, the link (arrow) from Director to Person with
label subclass in Figure 8 becomes the link element deﬁned on lines 21–23 whose
attribute “connector” has value “subclass”, which is the id of the connector that
deﬁnes the subclass relation (lines 2–4). Each element “role” in the connector, in
this case the roles “subject” and “object” (lines 3 and 4) of connector “subclass”,
must be matched by a corresponding bind in the link, in this case the “bind” elements
on lines 22–23, which establish that in this particular instantiation of connector
“subclass” node “Director” is the subject and node “Person” is the object. The
omitted connectors and links in the HSL document of Figure 9 (lines 12, 28, and 53)
all follow a similar pattern.

HyQL From a graph-theoretic point of view, the Hyperknowledge model supports
advanced features, such as nested nodes (contexts) and hyperedges (n-ary links),

39

1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55

["hsl", [
["connector", "subclass", {"type": "fact"}, [
["role", "subject"],
["role", "object"]]],
["connector", "is-a", {"type": "fact"}, [
["role", "subject"],
["role", "object"]]],
["connector", "is-a-cap", {"type": "fact"}, [
["role", "subject"],
["role", "object1"],
["role", "object2"]]],

. . .

["context", "TBox-Context", [
["node", "Actor", {"type": "Concept"}],
["node", "Directable", {"type": "Concept"}],
["node", "Director", {"type": "Concept"}],
["node", "Person", {"type": "Concept"}],
["node", "Movie", {"type": "Movie"}],

["link", {"connector": "subclass"}, [
["bind", {"subject": "Director"}],
["bind", {"object": "Person"}]]],

["link", {"connector": "subclass"}, [
["bind", {"subject": "Actor"}],
["bind", {"object": "Person"}]]]

. . .

]],

["context", "ABox-Context", null, [
["node", "kubrick", {"type": "Data",
"uri": "http://example.org/kubrick.jpg"}],
["node", "stanley", {"type": "Reference",
"refer": "kubrick"}],
["node", "Director", {"type": "Reference",
"refer": "TBox-Context/Director"}],
["node", "Actor", {"type": "Reference",
"refer": "TBox-Context/Actor"}],
["node", "space-odyssey", {"type": "Data",
"uri": "http://example.org/odyssey.ogv"}],
["node", "de-niro", {"type": "Data",
"uri": "http://example.org/de-niro.jpg"}],

["link", {"connector": "is-a"}, [
["bind", {"subject": "kubrick"}],
["bind", {"object": "Director"}]]],

["link", {"connector": "is-a-cap"}, [
["bind", {"subject": "de-niro"}],
["bind", {"object1": "Director"}],
["bind", {"object2": "Actor"}]]]

. . .

]]

]]

Figure 9: Partial HSL corresponding to the HK base of Figure 8.

40

which are not present in traditional knowledge graphs. A language for querying
Hyperknowledge graphs, thus, has to cope with these features and with the peculiar-
ities of the data which is stored in a Hyperknowledge base. For instance, queries
involving multimedia objects often need to refer to temporal or spatial fragments of
these objects and to correlate objects and fragments in time and space.
HyQL (Hyperknowledge Query Language) is a declarative language for querying
hyperknowledge graphs. A HyQL query speciﬁes a complex Hyperknowledge-graph
pattern, possibly involving path navigation, level shifts, aggregation, ﬁlters, and
speciﬁc features or fragments of the underlying data. The complete syntax of HyQL
is presented in Figure 10. We will not discuss this syntax and its accompanying
semantics in detail, though. Instead, we will introduce HyQL gradually, through
example queries over the HK base of Figure 8.
Here is a HyQL query that lists all instances of concept “Director” in the HK
base of Figure 8:

select Director

The results in this case are “kubrick”, “stanely”, and “de-niro”. And here is a query
that counts the number of actors in the HK base:

select count Actor

The answer in this case is 1, as just “de-niro” is an instance of the concept “Actor”.
HyQL queries can also contain ﬁlters. For instance, the query

select Director
where Director directs space-odyssey

contains a ﬁlter (where-clause) that ﬁlters out only the directors who have directed
(link “directs”) the node “space-odyssey”. The answer in this case is “kubrick” and
“stanley”. Filters can be combined with other ﬁlters and also test node attributes.
For instance, the query

select Director
where Director.uri == "http://example.org/kubrick.jpg"
and Director.type != "Reference"

selects all nodes which are instances of “Director” such that their “uri” attribute is
equal to “http://example.org/kubrick.jpg” and their type is not “Reference”. The
answer in this case is only “kubrick”.
We conclude the discussion of HyQL with a query that compares the spatial
position of objects in a picture. For this query, we will need to introduce the notion
of anchor [9]. An anchor speciﬁes a part of a data node. Anchors can be the source
and target of links and can also be independently designated via node references.
Consider the following HSL snippet:

41

query (cid:70) varlist ‘select’ [modiﬁer] targetlist [‘where’ clause]
varlist (cid:70) vardecl {‘,’ vardecl}
vardecl (cid:70) ‘let’ var
var (cid:70) name ‘as’ name | name ‘:’ name | name

modiﬁer (cid:70) ‘distinct’ | ‘count’ | ‘max’ | ‘min’ | ‘sum’ | ‘avg’

targetlist (cid:70) target {‘,’ target }
target (cid:70) node | nodeattr | nodeanchor | funcall
node (cid:70) var
nodeattr (cid:70) var ‘.’ var
nodeanchor (cid:70) var ‘#’ var
funcall (cid:70) name ‘(’ explist ‘)’
explist (cid:70) exp {‘,’ exp}
exp (cid:70) boolean | number | string | node | nodeattr
clause (cid:70) linkclause | timeclause | spaceclause | contextclause
| spoclause | attrclause | funclause | anchorclause
| clause ‘and’ clause
linkclause (cid:70) var ‘[’ {name ‘:’ var } ‘]’
timeclause (cid:70) var timeop var
spaceclause (cid:70) var spaceop var
contextclause (cid:70) var ‘from’ var
spoclause (cid:70) var var var
attrclause (cid:70) nodeattr binop exp
funclause (cid:70) funcall binop exp
anchorclause (cid:70) nodeanchor timeop nodeanchor
| nodeanchor timeop var
| nodeanchor spaceop nodeanchor
| nodeanchor spaceop var
| nodeanchor var var

timeop (cid:70) ‘before’ | ‘after’ | ‘meets’ | ‘overlaps’ | ‘start’
| ‘during’ | ‘finishes’ | ‘equals’
spaceop (cid:70) ‘side’ | ‘above’ | ‘bellow’ | ‘collides’ | ‘contains’

binop (cid:70) ‘<’ | ‘<=’ | ‘>’ | ‘>=’ | ‘==’ | ‘!=’

Figure 10: The complete syntax of HyQL. {A} means zero or more As, and [A]
means an optional A.

42

1

2

3

4

5

6

7

8

9

10

11

12

13

["node", "picture", {"type": "Data", "uri": "marat.jpg"}, [
["anchor", "knife",
{"x": "58px", "y": "766px", "w": "160px", "h": "37px"}],
["anchor", "marat",
{"x": "39px", "y": "334px", "w": "146px", "h": "111px"}]]],
["node", "Knife", {"type": "Concept"}],
["node", "Person", {"type": "Concept"}],
["link", {"connector": "is-a"}, [
["bind", {"subject": "picture#knife"}],
["bind", {"object": "Knife"}]]],
["link", {"connector": "is-a"}, [
["bind", {"subject": "picture#marat"}],
["bind", {"object": "Person"}]]],

This HSL snippet declares three nodes: “picture” (lines 1–5), which is a data node
whose URI points to the picture of Figure 1, and “Knife” (line 6) and “Person”
(line 7) which are concept nodes. The anchor elements (lines 2–3 and 4–5) of
the “picture” node specify rectangular regions in the picture, which correspond
roughly to the regions labeled “Jean-Paul Marat” and “Knife” in Figure 1. The idea
here is that we can use anchors to describe parts of nodes, in this case regions of
picture, and then use links to connect regions to their semantic descriptions. In the
above snippet, the links connect the region which depicts a knife with the concept
“Knife” (lines 8–10) and the region which depicts a person with the concept “Person”
(lines 11–13).
Now suppose that our HK base contains many more pictures whose regions are
semantically described as above. We can then use HyQL to ﬁnd precisely those
images in which a certain spatial relationship between the concepts represented in
the image hold. For instance, the HyQL query

select Picture where Person above Knife

lists all pictures in which a region described as a person appears above a region
described as a knife. Clearly, the previous data node “picture” (line 1) matches this
query.
HyQL has many more features, such as temporal operators (for comparing
temporal fragments of nodes), arithmetic operators, path and navigation operators,
etc. The description of these operators is beyond the scope of this chapter. We refer
the reader to [20, 22] for additional examples of HyQL queries involving spatial and
temporal anchors.
We now shift the discussion the tools which allow us to use the Hyperknowledge
model in practice.

4.3 Hyperknowledge tools

There are two main tools for developing applications based on Hyperknowledge,
namely, the Hyperknowledge Base (HKBase) and the Knowledge Explorer System

43

(KES).

HKBase The HKBase is a hybrid database system based on Hyperknowledge. By
hybrid we mean that it stores multimedia objects besides statements about a given
domain. Additionally, it has been designed from scratch to use Hyperknowledge as
both internal data model and external API. For compatibility reasons, the HKBase
also has features for importing and exporting RDF and OWL. In the case of im-
portation, these statements are converted to Hyperknowledge entities before being
stored in the underlying database. Figure 11 depicts the overall architecture of the
HKBase.

Figure 11: HKBase architecture.

The HKBase architecture consists of three layers. The ﬁrst one is the external
API which exposes a REST API to applications. The next layer is the services layer
which implements the core functionalities of the HKBase. Within this layer, the
RDF/OWL service handles the conversion among those formats and Hyperknowl-
edge. The query engine is the component that processes queries written in HyQL.
The entities service is responsible for creating, retrieving, updating and deleting
Hyperknowledge entities. And the transaction service manages requests that should
be executed within a transaction.
The third and last layer of the HKBase is the data layer which handles low level
access to storage back-ends. Its data source component is responsible for persisting
in a given database the structured statements represented in Hyperknowledge. And

44

Figure 12: Screenshot of the user interface of KES. (Soccer image by Abdul Rahman,
CC BY-NC-ND 4.0.)

its object manager component deals with the storage of multimedia objects.

KES KES (Knowledge Explorer System) [21] is an application built on top of the
HKBase. Using KES, users can visualize the content stored in a Hyperknowledge
base as well as curate it by adding, updating, or deleting entities and relationships.
The system is collaborative, that is, it supports multiple users working simultane-
ously on the same repository through diﬀerent devices. KES also has facilities for
importing and manipulating OWL and RDF ﬁles.
Figure 12 shows a screenshot of KES. The main canvas shows a graph-based
representation of the contents of a Hyperknowledge base. Besides Hyperknowledge
entities, KES permits the direct manipulation of multimedia content. For instance,
the screenshot of Figure 12 shows that the user has run the query: “Select Goal where
Goal by Neymar”. (The Hyperknowledge base, in this case, contains facts about
the soccer domain [23].) This query returns all goals scored by the player called
“Neymar”. Note that the answer set display by KES contains all Hyperknowledge
entities that satisfy the query, that is, all media nodes which are instances of Goal
and which have at least one link stating that the goal was scored by Neymar. The
content of these media nodes is displayed on the right-hand side of the screen.

5 Further Reading

In this chapter, we presented an overview of symbolic AI and discussed its appli-
cation to multimedia. Like any introduction, this one was necessarily incomplete,

45

especially given the breadth of the topics covered. Here are some suggestions for
further reading which complement those given along the text:

Logic A classic introduction to mathematical logic is [8]. The primary reference
for description logic is [2]. A good introduction to DL through SR OI Q is given
in [30]. For modal logics, especially temporal logic, a good starting-point is [10].
For a discussion of DL and multimedia, see [32].

Semantic Web For a seminal discussion of the Semantic Web vision, see [4]. An
overview of the principles and technologies of the Semantic Web is given in [15].
Speciﬁcally for OWL, a good place to start is [14]. For a comprehensive treatment
of ontologies, see [34].

Hyperknowledge The primary reference for Hyperknowledge is [25]. Some fur-
ther references describing particular applications of Hyperknowledge to document
understanding and temporal reasoning are [24] and [22].

References

[1] Angles, R. A comparison of current graph database models. In 2012 IEEE
28th International Conference on Data Engineering Workshops (April 2012),
IEEE, pp. 171–177.
[2] Baader, F., Calvanese, D., McGuinness, D. L., Nardi, D., and Patel-
Schneider, P. F., Eds. The Description Logic Handbook: Theory, Implemen-
tation and Applications, 2nd ed. Cambridge University Press, 2007.
[3] Baader, F., and Lippmann, M. Runtime veriﬁcation using the temporal
description logic A L C -LTL revisited. J. Appl. Log. 12, 4 (2014), 584–613.
[4] Berners-Lee, T., Hendler, J., and Lassila, O. The semantic web. Scientiﬁc
American (May 2001), 96––101.
[5] Borgwardt, S., and Peæaloza, R. Fuzzy description logics – a survey. In
Scalable Uncertainty Management (2017), Springer, pp. 31–45.
[6] Carothers, G., and Prudhommeaux, E.
RDF 1.1 Turtle.
ommendation, W3C, February 2014.

http://www.w3.org/TR/2014/

Rec-

REC-turtle-20140225/.

[7] Cristiani, M., and Gabrielli, N. Practical issues of description logics for
spatial reasoning. In AAAI Spring Symposium, Stanford University, Stanford,
21–23 March, 2011 (2011).
[8] Enderton, H. B. A Mathematical Introduction to Logic, 2nd ed. Academic
Press, 2001.

46

[9] Fiorini, S. R., dos Santos, W. S., Mesquita, R. C., Lima, G. F., and
Moreno, M. F. General fragment model for information artifacts, 2019.
[10] Goldblatt, R. Logics of Time and Computation, 2nd ed. CSLI, 1992.
[11] Grosof, B. N., Horrocks, I., Volz, R., and Decker, S. Description logic
programs: Combining logic programs with description logic. In Proceedings
of the 12th International Conference on World Wide Web (2003), WWW ’03,
ACM, pp. 48–57.

[12] Harris, S., and Seaborne, A.
SPARQL 1.1 query language. Rec-
ommendation, W3C, March 2013.

http://www.w3.org/TR/2013/

REC-sparql11-query-20130321/.

[13] Hayes, P., and Patel-Schneider, P.
ommendation, W3C, February 2014.

REC-rdf11-mt-20140225/.

RDF 1.1 semantics.

Rec-

http://www.w3.org/TR/2014/

[14] Hitzler, P., Kr(cid:246)tzsch, M., adn Peter F. Patel-Schneider, B. P., and
Rudolph, S. OWL 2 Web Ontology Language primer (second edition).
Recommendation, W3C, December 2014. http://www.w3.org/TR/2012/

REC-owl2-primer-20121211/.

[15] Hitzler, P., Kr(cid:246)tzsch, M., and Rudolph, S. Foundations of Semantic Web
Technologies. Chapman & Hall, 2010.
[16] Horrocks, I., Kutz, O., and Sattler, U. The even more irresistible SR OI Q .
In Proceedings of the Tenth International Conference on Principles of Knowl-
edge Representation and Reasoning (2006), KR’06, AAAI Press, pp. 57–67.
[17] Hudelot, C., , Atif, J., and Bloch, I. A L C (F): A new description logic
for spatial reasoning in images. In Computer Vision - ECCV 2014 Workshops
(2015), L. Agapito, M. M. Bronstein, and C. Rother, Eds., Springer, pp. 370–
384.

[18] Kr(cid:246)tzsch, M., Rudolph, S., and Hitzler, P. Description logic rules. In
Proceedings of the 18th European Conference on Artiﬁcial Intelligence, Patras,
February 2008 (2008), IOS Press, pp. 80–84.
[19] Milea, V., Frasincar, F., and Kaymak, U. tOWL: A temporal web ontology
language. IEEE Trans. Syst˙, Man, and Cybern., Part B (Cybernetics) 42, 1
(February 2012), 268–281.

[20] Moreno, M., Santos, R., Mozart, R., Santos, W., and Cerqueira, R. As-
sisting seismic image interpretations with hyperknowledge. In 2018 First Inter-
national Conference on Artiﬁcial Intelligence for Industries (AI4I) (September
2018), pp. 48–51.

47

[21] Moreno, M., Santos, R., Santos, W., Brandªo, R., Carrion, P., and
Cerqueira, R. Handling hyperknowledge representations through an interac-
tive visual approach. In 2018 IEEE International Conference on Information
Reuse and Integration (IRI) (July 2018), pp. 139–146.
[22] Moreno, M., Santos, R., Santos, W., Silva, R., and Cerqueira, R. Knowl-
edge bases enrichment with temporal reasoning using hyperknowledge. In
2018 IEEE First International Conference on Artiﬁcial Intelligence and Knowl-
edge Engineering (AIKE) (September 2018), pp. 125–128.
[23] Moreno, M., Santos, W. H. S. D., Santos, R. C. M., Ramos, I., and
Cerqueira, R. Supporting soccer analytics through hyperknowledge speciﬁ-
cations. In 2019 Second International Conference on Artiﬁcial Intelligence for
Industries (AI4I) (September 2019).
[24] Moreno, M., Schirmer, L., Bayser, M., Brandªo, R., and Cerqueira, R.
Understanding documents with hyperknowledge speciﬁcations. In Proceedings
of the ACM Symposium on Document Engineering 2018 (2018), DocEng ’18,
ACM, pp. 41:1–41:4.

[25] Moreno, M. F., Brandao, R., and Cerqueira, R. Extending hypermedia
conceptual models to support hyperknowledge speciﬁcations. Int. J. Semant.
Comput. 11, 1 (2017), 43–64.
[26] OWL@Machester. List of reasoners. http://owl.cs.manchester.ac.

uk/tools/list-of-reasoners/, 2019.

[27] Pfeiffer, S., Mannens, E., Troncy, R., and Deursen, D. V. Media Frag-
ments URI 1.0 (basic). W3C recommendation, W3C, September 2012.

http://www.w3.org/TR/2012/REC-media-frags-20120925/.

[28] Randell, D. A., Cui, Z., and Cohn, A. G. A spatial logic based on regions
and connection. In Proceedings of the Third International Conference on Prin-
ciples of Knowledge Representation and Reasoning (1992), KR ’92, Morgan
Kaufmann, pp. 165–176.
[29] Robinson, I., Webber, J., and Eifrem, E. Graph Databases. O’Reilly, 2013.
[30] Rudolph, S. Foundations of description logics.
In Reasoning Web. Se-
mantic Technologies for the Web of Data: 7th International Summer School
2011, Galway, Ireland, August 23-27, 2011, Tutorial Lectures. Springer, 2011,
pp. 76–136.

[31] Schmidt-Schau\377, M., and Smolka, G.Attributive concept descriptions
with complements. Artif. Intell. 48, 1 (1991), 1–26.
[32] Sikos, L. F. Description Logics in Multimedia Reasoning. Springer, 2017.

48

[33] Soares, L. F. G., and Rodrigues, R. F. Nested Context Model 3.0 part 1:
NCM core. Monographs in computer science, Informatics Department, PUC-
Rio, Rio de Janeiro, Brazil, 2005.
[34] Staab, S., and Studer, R., Eds. Handbook on Ontologies, 2nd ed. Springer-
Verlag, 2009.

[35] W3C OWL WG. OWL 2 Web Ontology Language document overview (second
edition). Recommendation, W3C, December 2012. http://www.w3.org/

TR/2012/REC-owl2-overview-20121211/.

[36] W3C Semantic Web Wiki. Semantic web development tools. https://www.

w3.org/2001/sw/wiki/Tools, 2019.

[37] Wang, Y., Chang, L., Li, F., and Gu, T. Veriﬁcation of branch-time property
based on dynamic description logic. In Intelligent Information Processing VII
(2014), Springer, pp. 161–170.
[38] Wessel, M. Qualitative spatial reasoning with the A L CI RCC family:
First results and unanswered questions. Memo 324/03, University of
Hamburg, 2003.

https://kogs-www.informatik.uni-hamburg.de/
publikationen/pub-wessel/report7.pdf.

[39] Wood, D., Lanthaler, M., and Cyganiak, R. RDF 1.1 concepts and abstract
syntax. Recommendation, W3C, February 2014. http://www.w3.org/TR/

2014/REC-rdf11-concepts-20140225/.

[40] Zolin, E. Complexity of reasoning in description logics. http://www.cs.

man.ac.uk/~ezolin/dl/, 2019.

49

