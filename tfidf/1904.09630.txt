Genuine Personal Identiﬁers and Mutual Sureties for
Sybil-Resilient Community Formation

Gal Shahaf1 , Ehud Shapiro1 & Nimrod Talmon2
1Weizmann Institute of Science
2Ben-Gurion University
{gal.shahaf, ehud.shapiro}@weizmann.ac.il, talmonn@bgu.ac.il

9
1
0
2

v
o

N

1
2

]

A

M

.

s

c

[

5
v
0
3
6
9
0

.

4
0
9
1

:

v

i

X

r

a

Abstract. While most of humanity is suddenly on the net, the value
of this singularity is hampered by the lack of credible digital iden-
tities: Social networking, person-to-person transactions, democratic
conduct, cooperation and philanthropy are all hampered by the pro-
found presence of fake identities, as illustrated by Facebook’s re-
moval of 5.4Bn fake accounts since the beginning of 2019.
Here, we introduce the fundamental notion of a genuine personal
identiﬁer—a globally unique and singular identiﬁer of a person—
and present a foundation for a decentralized, grassroots, bottom-up
process in which every human being may create, own, and protect
the privacy of a genuine personal identiﬁer. The solution employs
mutual sureties among owners of personal identiﬁers, resulting in a
mutual-surety graph reminiscent of a web-of-trust. Importantly, this
approach is designed for a distributed realization, possibly using dis-
tributed ledger technology, and does not depend on the use or storage
of biometric properties. For the solution to be complete, additional
components are needed, notably a mechanism that encourages hon-
est behavior [29] and a sybil-resilient governance system [30].

Introduction

Providing credible identities to all by 2030 is a UN Sustainable De-
velopment Goal. Yet, current top-down digital identity-granting solu-
tions are unlikely to close the 1Bn-people gap [6] in time, as they are
not working for citizens of failed states nor for people ﬂeeing phys-
ical or political harshness [17, 5]. Concurrently, humanity is going
online at an astonishing rate, with more than half the world popu-
lation now being connected. Still, online accounts do not provide a
solution for credible digital identity either, as they may easily be fake,
resulting in lack of accountability and trust. For example, Facebook
reports the removal of 5.4Bn (!) fake accounts since the beginning of
2019 [16, 21].
The profound penetration of fake accounts on the net greatly ham-
pers its utility for credible human discourse and any ensuing delib-
erations and democratic decision making; it makes the net unsuit-
able for vulnerable populations, including children and the elderly;
it makes the use of the net for person-to-person transactions, notably
direct philanthropy, precarious; and in general it turns the net into an
inhuman, even dangerous, ecosystem. As an aside, we note that the
panacea of cryptocurrencies for the lack of credible personal iden-
tities on the net is the reckless employment of the environmentally-
harmful proof-of-work protocol.

Our aim is a conceptual and mathematical foundation for al-
lowing every person to create, own, and protect the privacy of a
globally-unique and singular identiﬁer, henceforth referred to as

genuine personal identiﬁer. We believe that successful deployment
and broad adoption of genuine personal identiﬁers will afford solu-
tions to these problems and more, providing for: egalitarian digital
democratic governance in local communities and in global move-
ments; digital cooperatives and digital credit unions; direct philan-
thropy; child-safe digital communities; preventing unwanted digi-
tal solicitation; banishing deep-fake (by marking as spam videos
not signed by a genuine personal identiﬁer); credible and durable
digital identities for people ﬂeeing political or economic harsh-
ness; accountability for criminal activities on the net; and egalitarian
cryptocurrencies employing an environmentally-friendly Byzantine-
agreement consensus protocol among owners of genuine personal
identiﬁers. Furthermore, genuine personal identiﬁers may provide
the necessary digital foundation for a notion of global citizenship
and, subsequently, for democratic global governance [31].
Granting an identity document by a state is a complex process as
it requires careful veriﬁcation of the person’s credentials. The pro-
cess culminates in granting the applicant a state-wide identiﬁer that is
unique (no two people have the same identiﬁer) and singular (no per-
son has two identiﬁers). Granting a genuine personal identiﬁer might
seem even more daunting, as it needs to be globally-unique, not only
state-wide unique, except for following fundamental premise:
Every person deserves a genuine personal identiﬁer. Thus, there are
no speciﬁc credentials to be checked, except for the existence of the
person. As a result, a solution for all people to create and own gen-
uine personal identiﬁers may focus solely on ensuring the one-to-one
correspondence between people and their personal identiﬁers.
A solution that is workable for all must be decentralized, dis-
tributed, grassroots, and bottom-up. Solid foundations are being laid
out by the notion of self-sovereign identities [22] and the W3C De-
centralized Identiﬁers [13] and Veriﬁable Claims [34] emerging stan-
dards, which aim to let people freely create and own identiﬁers and
associated credentials. We augment this freedom with the goal that
each person declares exactly one identiﬁer as her genuine personal
identiﬁer. We note that besides the genuine personal identiﬁer, one
may create, own and use any number of identiﬁers of other types.
Becoming the owner of a genuine personal identiﬁer is simple.
With a suitable app, this could be done with a click of a button:

1. Choose a new cryptographic key-pair (v , v−1 ), with v being the
public key and v−1 the private key.

 
 
 
 
 
 
2. Claim v to be your genuine personal identiﬁer by publicly posting
a declaration that v is a genuine personal identiﬁer, signed with
v−1 .
Lo and behold! You have become the proud rightful owner of a gen-
uine personal identiﬁer.1 Note that a declaration of a genuine per-
sonal identiﬁer, by itself, does not reveal the person making the dec-
laration; it only reveals to all that someone who knows the secret key
for the public key v claims v as her genuine personal identiﬁer. De-
pending on personality and habit, the person may or may not publicly
associate oneself with v . E.g., a person with truthful social media ac-
counts may wish to associate these accounts with its newly-minted
genuine personal identiﬁer.
If becoming the rightful owner of a genuine personal identiﬁer
is so simple, what could go wrong? In fact, so many things can go
wrong, that this paper is but an initial investigation into describing,
analyzing, and preventing them. Some of them are enumerated be-
low; h denotes an agent:
1. The key-pair (v , v−1 ) is not new, or else someone got hold of it
between Step 1 and Step 2 above. Either way, someone else has
declared v to be a genuine personal identiﬁer prior to the declara-
tion by h. In which case h cannot declare v .
2. Agent h failed to keep v−1 secret so that other people, e.g. h(cid:48) ,
know v−1 , in which case h(cid:48) is also an owner of v and, thus, v is
compromised. Figure 1 (left) illustrates a compromised personal
identiﬁer.
3. The agent h intended to divulge his association with his public
key v only on a need-to-know basis, but the association of v and
h has become public knowledge, prompting agent h to replace his
genuine personal identiﬁer v with a new one.
4. Agent h declared v as his genuine personal identiﬁer, but later also
declared another personal identiﬁer v (cid:48) . Then, v and v (cid:48) are dupli-
cates, v (cid:48) is a sybil, and agent h is corrupt. An honest agent does
not declare sybils. Figure 1 illustrates honest and corrupt agents.
We aim to develop the foundation for genuine personal identiﬁers
utilizing basic concepts of public-key cryptography, graph theory, so-
cial choice theory and game theory. Here, we focus on utilizing the
ﬁrst two disciplines; see [30] for sybil-resilient social choice, which
provides a foundation for democratic governance of digital commu-
nities with bounded sybil penetration; incorporating sybils in cooper-
ative game theory, with the goal of forming a sybil-free grand coali-
tion, is work in progress.
Related Work. Sybil-resilience has received considerable attention
in AI research [2, 3, 7, 8, 10, 11, 12, 30, 35, 36] as elaborated below.
Philosophically, genuine personal identiﬁers aim to bridge the gap
between agents and their corresponding identiﬁers. This distinction,
acknowledged in semiotics as the difference between signiﬁed and
signiﬁer, strongly relates to the study of sense and reference initi-
ated by Frege [15] followed by vast literature in analytic philosophy
and the philosophy of language. Conceptually, the formal framework
suggested here may be viewed as an attempt to computationally re-
alize unique and singular signiﬁers of agents in a distributed setting.
Practically, digital identities are a subject of extensive study, with
many organizations aiming at providing solutions, notably Self-
Sovereign Identiﬁers [22]. Business initiatives include the Decen-
tralized Identity Foundation (identity.foundation), the Global Iden-
tity Foundation [14] and Sovrin [33]. None of these projects are con-
cerned with the uniqueness or singularity of personal identities.

1 As the public key may be quite long, one may also associate oneself with
a shorter “nickname”, a hash of the public key, e.g. a 128-bit hash (as a
UUID) or a 256-bit hash (as common in the crypto world).

Other high-proﬁle projects to provide nationwide digital identities
include India’s Aadhaar system [23], Sierra Leone’s Kiva identity
protocol [32] and the World Food Programmes cash aid distribution
program in refugee camps [19]. Here we are concerned with self-
sovereign and global personal identities, not bound to any national
boundaries or entities, and argue that top-down approaches fail to
provide such a solution. In this context, we mention the concept of
Proof of Personhood [7], aiming at providing unique and singular
identities by means of conducting face-to-face encounters, an ap-
proach suitable only for small communities.
Our solution is based upon the notion of trust, thus we men-
tion Andersen et al. [3], studying axiomatizations of trust systems.
They are not concerned, however, with sybils, but with quality of
recommendations. We mention work on sybil-resilient community
growth [26], describing algorithms for the growth of an online com-
munity that keep the fraction of sybils in it small; and work on sybil-
resilient social choice [30], describing aggregation methods to be ap-
plied in situations where sybils have inﬁltrated the electorate. In these
two papers, a notion of genuine identities and sybils is used without
specifying what they are; here, we deﬁne a concrete notion of gen-
uine personal identiﬁers, and derive from it a formal deﬁnition of
sybils and related notions of honest and corrupt agents and byzan-
tine identiﬁers. Finally, we mention the work of Conitzer
[12, 2]
regarding computerized tests for sybil ﬁghting: A test that is hard for
a person to pass more than once [12] and a test that is hard to pass
simultaneously by one person [2].

Genuine Personal Identiﬁers

Ingredients. The ingredients needed for a realization of genuine per-
sonal identiﬁers are:

1. A set of agents. It is important to note that, mathematically, the
agents form a set (of unique entities) not a multiset (with dupli-
cates). Intuitively, it is best to think of agents as people (or other
physical beings with unique personal characteristics, unique per-
sonal history, and agency, such as intelligent aliens), which cannot
be duplicated, but not as software agents, which can be.
2. A way for agents to create cryptographic key-pairs. This can be
realized, e.g., using the RSA standard [27]. Our solution does not
require a global standard or a uniform implementation for pub-
lic key encryption: Different agents can use different technologies
for creating and using such key-pairs, as long as the signatures-
veriﬁcation methods are declared.
3. A way for agents to sign strings using their key-pairs. As we as-
sume cryptographic hardness, an agent that does not know a cer-
tain key-pair cannot sign strings with this key-pair.
4. A bulletin board or public ledger, to which agents may post and
observe signed messages, where all agents observe the same order
of messages. The weaker requirement that the same order is ob-
served only eventually, as is standard with distributed ledger pro-
tocols, could also be accommodated. Considering partial orders is
a subject of future work.

Agents and their Personal Identiﬁers. We assume a set of agents

H that is ﬁxed over time.2 Agents can create new key-pairs (v , v−1 ).
We assume that an agent that has a key-pair can sign a string, and de-
note by v(x) the string resulting from signing the string x with v−1 .
Intuitively, each agent corresponds to a human being. Importantly,

2 Birth and death of agents will be addressed in future work.

Figure 1. A compromised identiﬁer (left), honest agent (middle), and corrupt agent (right).

members of the set H of agents (e.g., containing all human beings)
cannot be referenced explicitly and, in particular, posted signed mes-
sages never refer directly to agents h ∈ H. A key motivation for
our work is providing people with digital genuine personal identi-
ﬁers without accessing any of their intrinsic (e.g. biometric) private
properties and without depending upon such properties as identiﬁers.
As we aim personal identiﬁers to be self-sovereign identities that
conform to the W3C Decentralized Identiﬁers emerging standards,
we let agents create and own their personal identiﬁers. An agent
h can publicly declare a personal identiﬁer v for which it knows
the private key v−1 . A personal identiﬁer declaration has the form
v(g id(v)) and can be effected by agent h posting v(g id(v)) to a pub-
lic ledger. We denote this action by declareh (g id(v)) ∈ C . Recall
that all agents have the same view of the sequence of all declarations
made; subsequent work may relax this assumption.

Deﬁnition 1 (Personal Identiﬁer) Let C be a sequence of personal

identiﬁer declaration events and declareh (g id(v)) ∈ C the ﬁrst dec-
laration event in which v occurs. Then v is a personal identiﬁer and
h is the rightful owner of v , given C .

Deﬁnition 2 (Genuine Personal Identiﬁer, Sybil, Honest, and

Corrupt Agents) Let C be a sequence of personal identiﬁer dec-
laration events and h be the rightful owner of personal identiﬁer v in
C . Then v is genuine if it is the ﬁrst personal identiﬁer declared in C
by h, else v is a sybil. An agent h is corrupt if it declares any sybils,
else h is honest. (All notions are relative to C .)

See Figure 1 and some remarks: (1) An agent is the rightful owner
of its genuine personal identiﬁer as well as of any subsequent sybils
that it declares. (2) If h, the rightful owner of v , is corrupt, then its
ﬁrst declared identiﬁer is genuine and the rest of its declared iden-
tiﬁers are all sybils. (3) An honest agent may create and use many
key-pairs for various purposes, yet remain honest as long as it has
declared at most one public key as a personal identiﬁer.

Mutual Sureties and Their Graphs

A key element of our approach is the pledging of mutual sureties by
agents. Intuitively, mutual surety pledges provide a notion of trust
between the owners of personal identiﬁers. They allow two agents

that know each other and know the personal identiﬁers declared by
each other to vouch for the other regarding the good standing of the
personal identiﬁers. This notion is key to help honest agents fend-off
sybils. We consider several types of mutual sureties, of increasing
strength, and illustrate the corresponding sybil-resilience each type
of mutual sureties can obtain.
For an agent, say h, to provide surety regarding the personal iden-
tiﬁer of another agent, say h(cid:48) , h ﬁrst has to know h(cid:48) . How this knowl-
edge is established is not speciﬁed in our formal framework, but this
is quite an onerous requirement that cannot be taken lightly or sat-
isﬁed casually. E.g., we may assume that one knows one’s family,
friends and colleagues, and may diligently get to know new people
if one so chooses. We consider several types of sureties of increas-
ing strength, in which an agent h with personal identiﬁer v makes
a pledge regarding the personal identiﬁer v (cid:48) of another agent h(cid:48) ; all
assume that the agent h knows the agent h(cid:48) . We describe four Surety
Types, which are cumulative as each includes all previous ones, ex-
plain on what basis one may choose to pledge each of them, and
present results that utilize them,

h

Surety of Type 1: Ownership of a personal identiﬁer. Agent

pledges that agent h(cid:48) owns personal identiﬁer v (cid:48) .
Agent h(cid:48) can prove to agent h that she owns v (cid:48) without disclos-
ing v (cid:48)−1 to h. This can be done, for example, by h asking h(cid:48) to sign
a novel string x and verifying that v (cid:48) (x) is signed using v (cid:48)−1 . This
surety type is the weakest of all four, it is the one given in “key sign-
ing parties”, and is implicitly assumed by applications such as PGP
and web-of-trust [1]. For a given surety type, we say that the surety is
violated if its assertion does not hold; in particular, a surety of Type
1 is violated if h(cid:48) in fact does not know the secret key v (cid:48)−1 .
In general, mutual surety between two agents with two per-
sonal identiﬁers is pledged by each of the two agents pledging
a surety to the personal identiﬁer of the other agent.3 We de-
ﬁne below three additional surety types, where the format of a
surety pledge of Type X by the owner of v to the owner of v (cid:48) is
v(suretyX (v (cid:48) )), X ∈ {1, 2, 3, 4}. The corresponding surety event
is pledgeh v(suretyX (v (cid:48) )), and the surety enters into effect once
both parties have made the mutual pledges. We now take C to be a
record of both declaration events and pledge events.

3 We consider undirected graphs, as we require surety to be symmetric. In-
deed, one may consider directed sureties.

h, h(cid:48) ∈ H for which pledgeh v(suretyX (v (cid:48) )) ∈ C

Deﬁnition 3 (Mutual Surety) The personal identiﬁers v , v (cid:48) have
mutual surety of
type X, X ∈ {1, 2, 3, 4},
if
there are
pledgeh(cid:48) v (cid:48) (suretyX (v)) ∈ C , in which case h and h(cid:48) are the wit-
nesses for the mutual surety between v and v (cid:48) .

&

A sequence of events induces a sequence of surety graphs in which
the vertices are personal identiﬁers that correspond to personal iden-
tiﬁer declarations and the edges correspond to mutual surety pledges.
Deﬁnition 4 (Surety Graph) Let C = c1 , c2 , . . . be a sequence of
events and let Ck denote its ﬁrst k ≥ 0 events. Then, for each k ≥ 0,
Ck induces a surety graph of type X, GXk = (Vk , EXk ), X ∈
{1, 2, 3, 4}, as follows:4

Vk = {v | declareh (g id(v)) ∈ Ck for some h ∈ H}

EXk = {(v , v

(cid:48)

(cid:48)

(cid:48)

) | pledgeh v(suretyX (v
)) ∈ Ck ,
(suretyX (v)) ∈ Ck ,
pledgeh(cid:48) v
(cid:48) ∈ H, v , v

for some h, h

(cid:48) ∈ Vk }

Remark 1 Observe that mutual sureties can be easily pledged by
agents, technically. However, we wish agents to be prudent and sin-
cere in their mutual surety pledges. Thus, we expect a mechanism
that, on one hand, rewards the pledging of sureties but, on the other
hand, punishes for surety violations, for example based on the ap-
proach of [29]. While the speciﬁcs of such a mechanism is beyond
the scope of the current paper, note that with such a mechanism in
place, the commissive illocutionary force [28] of a surety pledge will
come to bear.

Updating a Personal Identiﬁer with Mutual Sureties

Once creating a genuine personal identiﬁer is provided for, one must
also consider the many circumstances under which a person may
wish to update their personal identiﬁer:

1. Identiﬁer loss: The private key was lost.
2. Identiﬁer theft: The private key was stolen, robbed, extorted, or
otherwise compromised.
3. Identiﬁer breach of privacy: The association between the per-
sonal identiﬁer and the person was accidentally or maliciously
disclosed with unwarranted consequences.
4. Identiﬁer refresh: Proactive identiﬁer update to protect against
all the above.

Update in Case of Loss or Theft. The personal identiﬁer declara-
tion event declareh (g id(v)) establishes v as a personal identiﬁer.
To support updating a personal identiﬁer, we add the personal iden-
tiﬁer update event declareh (g id(v , v (cid:48) )), which declares that v (cid:48) is a
new personal identiﬁer that replaces v . A public declaration of iden-
tiﬁer update has the form v(g id(v , v (cid:48) )), i.e., it is signed with the new
identiﬁer. We refer to declarations of both types as personal iden-
tiﬁer declarations, and extend the assumption that a new identiﬁer
can be declared at most once to this broader deﬁnition of identiﬁer
declaration. The validity of an identiﬁer update declaration is deﬁned
inductively, as follows.

4 We allow surety pledges to be made before the corresponding personal iden-
tiﬁer declarations, as we do not see a reason to enforce order.

Deﬁnition 5 (Valid identiﬁer Update declaration) Let C be a se-

declareh (g id(v , v (cid:48) )), v , v (cid:48) ∈ V .

quence of declarations, V the set of global identities declared in C ,
and h ∈ H. A personal identiﬁer update event over V has the form
A personal identiﬁer update event declareh (g id(v , v (cid:48) )) ∈ C is
valid and h is the rightful owner of v if it is the ﬁrst identiﬁer decla-
ration event of v and h is the rightful owner of v (cid:48) .
Valid personal identiﬁer declarations should form linear chains, one
for each agent, each starting from g id(v) and ending with the cur-
rently valid personal identiﬁer of the agent:

(cid:3)

Deﬁnition 6 (Identiﬁer Provenance Chain) Let C be a sequence of

declarations and V the declared set of global identities. An identiﬁer
provenance chain (provenance chain for short) is a subsequence of C
of the form (starting from the bottom):

declarehk (g id(vk , vk−1 )),
declarehk−1 (g id(vk−1 , vk−2 )),
. . .
declareh1 (g id(v1 )).

Such a provenance chain is valid if the declarations in it are valid.
Such a provenance chain is maximal if there is no declaration

declareh (g id(v , vk )) ∈ C

for any v ∈ V and h ∈ H. A personal identiﬁer v is current in C if it
is the last identiﬁer v = vk in a maximal provenance chain in C . (cid:3)
Note that it is very easy for an agent to make an update declaration
for its identiﬁer. However, it is just as easy for an adversarial agent
wishing to steal the identiﬁer to make such a declaration. Hence, this
ability must be coupled with a mechanism that protects the rightful
owner of an identiﬁer from identiﬁer theft through invalid identiﬁer
update declarations. Here we propose to use a stronger type of mu-
tual sureties to support valid identiﬁer update declarations and help
distinguish between them and invalid declarations.

Surety of Type 2: Rightful ownership of a personal identiﬁer.

Agent h pledges that h(cid:48) is the rightful owner of personal iden-
tiﬁer v (cid:48) .
In addition to proving to h that it owns v (cid:48) , h(cid:48) must provide evidence
that h(cid:48) itself, and not some other agent, has declared v (cid:48) . A selﬁe
video of h(cid:48) pressing the declare button with v (cid:48) , signed with a certiﬁed
timestamp promptly after the video was taken, and then signed by v (cid:48) ,
may constitute such evidence. A suitable app may record, timestamp,
and sign such a selﬁe video automatically during the creation of a
genuine personal identiﬁer. In particular, this surety is violated if h(cid:48)
in fact did not declared v (cid:48) as a personal identiﬁer.
Note that immediately following an identiﬁer update declaration,
the new identiﬁer may not have any surety edges incident to it. Thus,
as a crude measure, we may require that the identiﬁer update would
come to bear only after all the Type 2 surety neighbors of the old
identiﬁer, or a sufﬁciently large majority of them, would update their
mutual sureties to be with the new identiﬁer. To achieve that, an agent
wishing to update its identiﬁer would have to approach its neighbors
and to create such updated Type 2 mutual surety pledges.
Example 1 Consider two friends, agent h and agent h(cid:48) having a mu-
tual surety pledge between them. If h(cid:48) would lose her identiﬁer, she
would create a new key-pair, make an identiﬁer update declaration,
and ask h for a new mutual surety pledge between h’s identiﬁer and
h(cid:48) ’s new identiﬁer.

The following observation follows from: (1) a valid provenance
chain has a single owner; and (2) whether a Type 2 surety between
two identiﬁers is violated depends on their rightful owners.
Observation 1 Let C be a sequence of update declarations and
C1 , C2 be two valid provenance chains in C . If a Type 2 surety pledge
between two global identities v1 ∈ C1 , v2 ∈ C2 is valid, then any
Type 2 surety pledge between two personal identiﬁers in these prove-
nance chains, u1 ∈ C1 , u2 ∈ C2 is valid.

The import of Observation 1 is that a Type 2 mutual surety can
be “moved along” valid provenance chains as they grow, without be-
ing violated, as it should be. Below we argue that invalid identiﬁer
update declarations are quite easy to catch, thus the risk of stealing
identities can be managed. In effect, we show the value of Type 2
surety pledges in defending an identiﬁer against theft via invalid up-
date declarations.
Let C be a sequence of declarations, C1 , C2 be two provenance
chains in C , and assume that there is a valid Type 2 surety pledge be-
tween the two current global identiﬁers v1 ∈ C1 , v2 ∈ C2 , made by
h1 = Marry and h2 = John. Now assume that the identiﬁer update
declaration c = declareh (g id(v , v1 )) is made, namely, some agent
Sue (cid:54)= Marry has declared to replace v1 by v . Then, it will be hard for
Marry to secure surety from John and, if she attempts to do so, then
John will know that c is not valid and thus (if John is honest) a Type
2 mutual surety between v and v2 will not be established. Consider
the following case analysis:
• Assume Marry notices c. Then she would inform John that she did
not declare c, and thus John will know that c is not valid.
• Assume that John notices c. He would approach Marry to update
the Type 2 mutual surety between them accordingly; Marry would
deny owning v , and thus John will know that c is invalid.
• Alternatively, Sue would approach John to update the Type 2 mu-
tual surety of v2 with v1 to be with v instead; John will see (or
suspect, if Sue did not reveal herself) that Sue is not Marry, will
double check with Marry and deem the declaration c invalid.

Reset in Case of Breach of Privacy. Note that provenance chains

address identiﬁer update in case of loss of theft, but do not address
breach of privacy, as the updated new identiﬁer is publicly tied to the
previous one. To address breach of privacy, a person ﬁrst has to inval-
idate his existing identiﬁer, then create a new genuine identiﬁer that
is not linked to the previous one; this may result in loss of any public
credit and goodwill associated with the old genuine personal identi-
ﬁer, but there may be circumstances in which a person would need to
protect his privacy even at the expense of such loss. To facilitate that,
an identiﬁer reset declaration uses the special value null and has the
form declareh (g id(v , null)), which nulliﬁes v as a personal identi-
ﬁer, and enters into effect if supported by those who initially provided
the surety to v . Agent h would then be free to declare a new personal
identiﬁer v (cid:48) , which is not tied to the now-defunct v , and at the same
time without v (cid:48) being a sybil and without h becoming corrupt as a
result of this declaration.
We note that using null, an initial genuine identiﬁer declaration
could be of the form declareh (g id(null, v)), thus dispensing with
the unary declaration format declareh (g id(v)) altogether.
GDPR. In general, our approach does not imply any “data con-
trollers” or “data processors” [24] other than people and their trusted
friends, but if realized on a large scale it might require such, possibly
democratically-appointed by the large community that needs them.

Furthermore, our approach and does not record or store any “person-
ally identiﬁable information”, and as such we believe is compliant
with GDPR [24]. One exception is perhaps the association of a gen-
uine personal identiﬁer with the person that owns it, which could be
made public on purpose by the owner, inadvertently by the owner
or by another person, or maliciously by another person. Closely tied
to this exception is GDPR’s “right to be forgotten” [24, Article 17],
which is notoriously difﬁcult to realize in a distributed setting and
hence resulted in sweeping legal opinions regarding the inapplica-
bility of distributed ledger/blockchain technology for the storage of
personally identiﬁable information [25].
Our method of personal identiﬁer reset ﬁrst invalidates an existing
identiﬁer (which could be coupled with a demand of erasure of every
reference to this identiﬁer from any public data controller, e.g. Face-
book) and then creates an independent and unlinked new personal
identiﬁer. This may be the ﬁrst proposal on how to realize the “right
to be forgotten” in a decentralized setting.

Sybil- and Byzantine-Resilient Community Growth

Ideally, we would like to attain sybil-free communities, but acknowl-
edge that one cannot prevent sybils from being declared and, fur-
thermore, perfect detection and eradication of sybils is out of reach.
Thus, our aim is to provide the foundation for a digital community
of genuine personal identiﬁers to grow by admitting new identiﬁers
indeﬁnitely, while retaining a bounded sybil penetration. As noted
above, democratic governance can be achieved even with bounded
sybils penetration [30].
Community history. For simplicity, we assume a single global com-
munity A and consider elementary transitions obtained by either
adding a single member to the community or removing a single com-
munity member:

Deﬁnition 7 (Elementary Community Transition) Let A, A(cid:48) de-

note two communities in V . We say that A(cid:48) is obtained from A by an
elementary community transition, and we denote it by A → A(cid:48) , if:
• A(cid:48) = A, or
• A(cid:48) = A ∪ {v} for some v ∈ V \ A, or
• A(cid:48) = A \ {v} for some v ∈ A.

Deﬁnition 8 (Community History) Let C = c1 , c2 , ... be a se-

quence of events. A community history wrt. C is a sequence of com-
munities A = A1 , A2 , . . . such that Ai ⊆ Vi and Ai → Ai+1 holds
for every i ≥ 1.

We do not consider community governance in this paper, only the
effects of community decisions to add or remove members. Hence,
we assume that the sequence of events C includes the events addA (v)
and removeA (v). With this addition, C = c1 , c2 , . . . induces a com-

munity history A1 , A2 , ..., where Ai+1 = Ai ∪ {v} if ci = addA (v)
for v ∈ V \ Ai ; Ai+1 = Ai \ {v} if ci = removeA (v) for v ∈ Ai ;

else Ai+1 = Ai .

Deﬁnition 9 (Community, Sybil penetration rate) Let C be a se-

quence of events and let S ⊆ V denote the sybils in V wrt. C . A
community in V is a subset of identiﬁers A ⊆ V . The sybil penetra-
|A
tion σ(A) of the community A is given by σ(A) =

Observation 2 Let A1 , A2 , ... be the community history wrt. a se-
quence of declarations C . Assume that A1 ⊆ H , and that whenever
Ai+1 = Ai ∪ {v} for some v /∈ Ai , it holds that P r(v ∈ S ) ≤ σ
for some ﬁxed 0 ≤ σ ≤ 1. Then, the expected sybil penetration rate
for every Ai is at most σ .

That is, the observation above states that a sybil-free community can
keep its sybil penetration rate below σ , as long as the probability of
admitting a sybil to it is at most σ . While the simplicity of Observa-
tion 2 might seem promising, its premise is naively optimistic. Due
to the ease in which sybils can be created and to the beneﬁts of own-
ing sybils in a democratic community, the realistic scenario is of a
hoard of sybils and a modest number of genuine personal identiﬁers
hoping to join the community. Furthermore, once a fraction of sybils
has already been admitted, it is reasonable to assume that all of them
(together with their perpetrators of course) would support the admis-
sion of further sybils. Thus, there is no reason to assume neither the
independence of candidates being sybils, nor a constant upper bound
on the probability of sybil admission to the community. Hence, in the
following we explore sybil-resilient community growth under more
realistic assumptions.

Sybil-Resilient Community Growth

A far more conservative assumption includes a process employed by
the community with the aim of detecting sybils. We shall use the ab-
stract notion of sybil detector in order to capture such process, that
may take the form of a query, a data-based comparison to other iden-
tiﬁers, or a personal investigation by some other agent. To leverage
this detector to sybil-resilient community growth regardless of the
sybil distribution among the candidates, we shall utilize a stronger
surety type, deﬁned as follows:

Surety of Type 3: Rightful ownership of a genuine personal

identiﬁer. Agent h pledges Surety Type 2 and that v (cid:48) is the gen-
uine personal identiﬁer of h(cid:48) .

Providing this surety requires a leap of faith. In addition to h ob-
taining from h(cid:48) a proof of rightful ownership of v (cid:48) , h must also trust
h(cid:48) not to have declared any other personal identiﬁer prior to declar-
ing v (cid:48) . There is no reasonable way for h(cid:48) to prove this to h, hence the
leap of faith.
Since Type 3 sureties inherently aim to distinguish between gen-
uine identiﬁers and sybils, sybil-resilient community growth is es-
tablished upon the underlying G3 surety graph. Speciﬁcally, we con-
sider a setting where potential candidates to join the community are
identiﬁers with a surety obtained from current community members.
Conversely, we consider a violation of a surety in one direction as
a strong indication that the surety in the other direction is violated.
That is, if (v , v (cid:48) ) ∈ E and v (cid:48) was shown to be sybil, (i.e., h(cid:48) has
declared some other v (cid:48)(cid:48) as a personal identiﬁer before declaring v (cid:48) as
a personal identiﬁer), then v should undergo a thorough investigation
in order to determine whether it is sybil as well.
Next, we formalize this intuition in a simple stochastic model
where admissions of new members are interleaved with random sybil
detection among community members:

(1) An identiﬁer is admitted to the community via an elementary com-
munity transition A → A ∪ {v} only if there is some a ∈ A with

(a, v) ∈ E .

(2) Every admittance of a candidate is followed by a random sybil
detection within the community: An identiﬁer a ∈ A is chosen

uniformly at random. If a is genuine it is declared as such. If a is
sybil, it is successfully detected with probability 0 < p ≤ 1.
(3) The detection of a sybil implies the successful detection of its en-
tire connected sybil component (with probability 1). That is, if a is
detected as sybil, then the entire connected component of a in the
sybil subgraph G|S is detected and expelled from the community.
(4) The sybils are operated from at most j ≤ k disjoint sybil compo-
nents in A. Furthermore, we assume that sybils join sybil compo-
nents uniformly at random, i.e., a new sybil member has a surety
to a given sybil component with probability 1
k , else, it forms a new
sybil component with probability k−j
k .

Note that assumption (2) is far weaker than the premise in Obser-
vation 2 as it presumes nothing on the sybil penetration among the
candidates, but rather on the proactive ability to detect a sybil, once
examined. Assumption (3) exploits the natural cooperation among
sybils, especially if owned by the same agent, and assumes that if a
sybil is detected by a shallow random check with probability p, then
all its neighbours will be thoroughly investigated and will be detected
if sybil with probability 1, continuing the investigation iteratively un-
til the entire connected sybil component of the initially-detected sybil
is identiﬁed. In assumption (4), the parameter k and the locations of
the components are adversarial – the attacker may choose how to op-
erate. While realistic attackers may also choose to which component
shall the new (sybil) member join, uniformity is assumed to simplify
the analysis. Possible relaxations of this model are future work.
For this setting we show an upper bound on the expected sybil pen-
etration, assuming bounded computational resources of the attacker.

Proof.

Theorem 1 In the stochastic model described above, obtaining an
expected sybil penetration E [σ(A)] ≥  is NP-hard for every  > 0.
Let Xi ⊆ A denote a sybil component within the commu-
nity at time i. In the stochastic model described above, Xi is detected
and immediately expelled with probability p · |Xi |
|Ai | . The expected size
of the component in this model is obtained in a steady state, i.e., in a
state i in time where E [|Xi+1 |] = |Xi |, that is:

(1 − px/n) · 1
k

· (x + 1) + (1 − px/n) · (1 − 1
) · x = x,
k
k x − n
pk = 0.

where n := |Ai | and x = |Xi |. It follows that x2 + 1
component in the steady state is x ≤ (cid:112)n/pk . It follows that the
number of sybils in the community in a steady state is xk ≤ (cid:112)nk/p.
Solving this quadratic equation implies that the size of a single sybil
The crucial observation now is that operating from k nonempty
sybil components corresponds to obtaining an independent set of
size k (at least, choosing a single vertex in each component). The
theorem follows from the fact that approximating independent set
within a constant factor is NP-hard (see, e.g., [4]).

(cid:3)

The following corollary establishes an upper bound on the sybil
penetration rate regardless of the attacker’s computational power.
The result is formulated in terms of the second eigenvalue of the
graph restricted to Ai . (λ(G|Ai ) is deﬁned in the supplementary ma-
terials section.
Corollary 1 Let A = A1 , A2 , . . . be a community history wrt. a
sequence of events C . If every community Ai ∈ A with Ai = Ai−1 (cid:93)
{v} satisﬁes λ(G|Ai ) < λ, then the expected sybil penetration in
every Ai ∈ A under the stochastic model depicted above, is at most

(cid:112)λ/p.

Figure 2. Violations of Sureties of Type 3 and Type 4. The axis of time
goes from left to right, with the points in time in which v (cid:48) was declared by
h(cid:48) and the surety from h to h(cid:48) was declared. Then, the braces describe the
time regions in which, if another identiﬁer v (cid:48)(cid:48) was to be declared by h(cid:48) ,
would correspond to a violation of a surety of Type 3 or 4.

Proof.

Recall that the size of the maximal independent set is
a trivial upper bound on k . The cardinality of an independent set
in a λ-expander is at most λn [18]; thus, k ≤ λn. It follows
that the number of sybils in the community in a steady state is

xk ≤ (cid:112)nk/p ≤ n(cid:112)λ/p.

(cid:3)

Byzantine-Resilient Community Growth

Here we consider the challenge of byzantine-resilient community
growth. Intuitively, the term byzantines aims to capture identiﬁers
owned by agents that are acting maliciously, possibly in collabora-
tion with other malicious agents. Formally, we deﬁne byzantines as
follows.

Deﬁnition 10 (Byzantine and harmless identiﬁers, Byzantine

penetration) An identiﬁer is said to be byzantine if it is either a
sybil or the personal identiﬁer of a corrupt agent. Non-byzantine
identiﬁers are referred to as harmless. We denote the byzantine and
harmless identiﬁers in V by B , H ⊆ V , respectively. The byzantine
penetration β (A) of a community A ⊆ V is given by β (A) =
|A

References

[9]

[1] Alfarez Abdul-Rahman, ‘The pgp trust model’, in EDI-Forum: the
Journal of Electronic Commerce, volume 10 (3), pp. 27–31, (1997).
[2] Garrett Andersen and Vincent Conitzer, ‘Atucapts: Automated tests that
a user cannot pass twice simultaneously.’, in Proceedings of IJCAI ’16,
pp. 3662–3669, (2016).
[3] R. Andersen, C. Borgs, J. Chayes, U. Feige, A. Flaxman, A. Kalai,
V. Mirrokni, and M. Tennenholtz, ‘Trust-based recommendation sys-
tems: an axiomatic approach’, in Proceedings of WWW ’08, pp. 199–
208, (2008).
[4] Sanjeev Arora and Boaz Barak, Computational complexity: a modern
approach, Cambridge University Press, 2009.
[5] R. Baird, K. Migiro, D. Nutt, A. Kwatra, S. Wilson, J. Melby,
A. Pendleton, M. Rodgers, and J. Davison. Human tide: the real mi-
gration crisis, 2007.
[6] World Bank.
Identiﬁcation for development (ID4D) global dataset,
2018.
[7] M. Borge, E. Kokoris-Kogias, P. Jovanovic, L. Gasser, N. Gailly, and
B. Ford, ‘Proof-of-personhood: Redemocratizing permissionless cryp-
tocurrencies’, in Proceedings of EuroS&PW ’17, pp. 23–26, (2017).
[8] Maria Borge, Eleftherios Kokoris-Kogias, Philipp Jovanovic, Linus
Gasser, Nicolas Gailly, and Bryan Ford, ‘Proof-of-personhood: Re-
democratizing permissionless cryptocurrencies’, Proceedings of Eu-
roS&PW ’17, 23–26, (2017).
Jeff Cheeger, ‘A lower bound for the smallest eigenvalue of the lapla-
cian’, in Proceedings of the Princeton conference in honor of Professor
S. Bochner, (1969).
[10] V. Conitzer, N. Immorlica, J. Letchford, K. Munagala, and L. Wag-
man, ‘False-name-proofness in social networks’, in Proceedings of the
6th International Workshop on Internet and Network Economics (WINE
’10), pp. 209–221, (2010).
[11] V. Conitzer and M. Yokoo, ‘Using mechanism design to prevent false-
name manipulations’, AI magazine, 31(4), 65–78, (2010).
[12] Vincent Conitzer, ‘Using a memory test to limit a user to one account’,
in Proceedings of AMEC ’08, pp. 60–72, (2008).
[13] D. Longley C. Allen R. Grant M. Sabadello D. Reed, M. Sporny, ‘De-
centralized identiﬁers (DIDs) v0. 12–data model and syntaxes for de-
centralized identiﬁers (DIDs)’, Draft Community Group Report, 29,
(2018).
[14] The Global Identity Foundation. Global identity challenges, pitfalls and
solutions, 2014.
[15] Gottlob Frege, ‘On sense and reference’, oversatt av Max Black, i J.
Guit ´errez-Rexach (red.): Semantics: Crictical concepts in linguistics,
1, 7–25, (2003).
[16] Brian Fung and Ahiza Garcia, ‘Facebook has shut down 5.4 billion fake
accounts this year’, CNN, (November 2019).
[17] Charles Geisler and Ben Currens, ‘Impediments to inland resettlement
under conditions of accelerated sea level rise’, Land Use Policy, 66,
322–330, (2017).
[18] Shlomo Hoory, Nathan Linial, and Avi Wigderson, ‘Expander graphs
and their applications’, Bulletin of the American Mathematical Society,
43(4), 439–561, (2006).
[19] Nir Kshetri and Jeffrey Voas, ‘Blockchain in developing countries’, It
Professional, 20(2), 11–14, (2018).
[20] Maciek Laskus. Decentralized identity trilemma, 2018. Available at
http://maciek.blog/dit/?cookie- state- change=1574327093444.
[21] Niall McCarthy, ‘Facebook deleted more than 2 billion fake accounts
in the ﬁrst quarter of the year’, Forbes, (May 2019).
[22] A. M ¨uhle, A. Gr ¨uner, T. Gayvoronskaya, and C. Meinel, ‘A survey on
essential components of a self-sovereign identity’, Computer Science
Review, 30, 80–86, (2018).
[23] Government of India. Home - unique identiﬁcation authority of india,
2018. Available at https://uidai.gov.in.
[24] European Parliament. General data protection regulation (gdpr).
[25] European Parliament. Blockchain and the general data protection regu-
lation: Can distributed ledgers be squared with european data protection
law?, 2019.
[26] Ouri Poupko, Gal Shahaf, Ehud Shapiro, and Nimrod Talmon, ‘Sybil-
resilient conductance-based community growth’, in Proceedings of
CSR ’19, (2019). A preliminary version appears in https://arxiv.org/
abs/1901.00752.
[27] R. L. Rivest, A. Shamir, and L. Adleman, ‘A method for obtaining dig-
ital signatures and public-key cryptosystems’, Communications of the
ACM, 21(2), 120–126, (1978).

[28]

J. R. Searle, S. Willis, and D. Vanderveken, Foundations of illocution-
ary logic, CUP Archive, 1985.
[29] Sven Seuken and David C Parkes, ‘Sybil-proof accounting mechanisms
with transitive trust’, in Proceedings of the 2014 international confer-
ence on Autonomous agents and multi-agent systems, pp. 205–212. In-
ternational Foundation for Autonomous Agents and Multiagent Sys-
tems, (2014).
[30] G. Shahaf, E. Shapiro, and N. Talmon, ‘Sybil-resilient reality-aware
social choice’, in IJCAI ’19, pp. 572–579, (2019).
[31] E. Shapiro, ‘Point: foundations of e-democracy’, Communications of
the ACM, 61(8), 31–34, (2018).
[32] Susan Staats, Alfonso Sintjago, and Renata Fitzpatrick, ‘Kiva mi-
croloans in a learning community: An assignment for interdisciplinary
synthesis’, Innovative Higher Education, 38(3), 173–187, (2013).
[33] A. Tobin and D. Reed, ‘The inevitable rise of self-sovereign identity’,
The Sovrin Foundation, 29, (2016).
[34] W3C. Veriﬁable credentials data model 1.0, 2019.
[35] B. Waggoner, L. Xia, and V. Conitzer, ‘Evaluating resistance to false-
name manipulations in elections.’, in Proceedings of the 26rd AAAI
Conference on Artiﬁcial Intelligence (AAAI ’12), (2012).
[36] L. Wagman and V. Conitzer, ‘Optimal false-name-proof voting rules
with costly voting.’, in Proceedings of the 22st AAAI Conference on
Artiﬁcial Intelligence (AAAI ’08), pp. 190–195, (2008).

Supplementary Material
Graph notations and terminology

(cid:80)

We provide some more detailed notations regarding graphs and con-
ductance.
Let G = (V , E ) be an undirected graph. The degree of a vertex
x ∈ V is deg(x) := |{y ∈ V | (x, y) ∈ E }|. The volume of a
given subset A ⊆ V is the sum of degrees of its vertices, vol(A) :=
x∈A deg(x). Additionally, we denote the subgraph induced on the
set of vertices A as G|A , by degA (x) the degree of vertex x ∈ A
x∈B degA (x) the volume of a set
B ⊆ A in G|A . Given two disjoint subsets A, B ⊆ V , the size of the
cut between A and B is denoted by

in G|A , and by volA (B ) := (cid:80)

e(A, B ) = |{(x, y) ∈ E | x ∈ A, y ∈ B}| .

Connectivity measures. In the following, we deﬁne two fundamen-
tal notions of graph connectivity that play a substantial role in safe
community growth.

Deﬁnition 11 (Combinatorial Conductance) Let G = (V , E ) be a

graph. The conductance of G is deﬁned by:

Φ(G) = min

∅(cid:54)=A⊂V
(Ac := V \ A is the complement of A.)

e(A, Ac )
min{vol(A), vol(Ac )} .

The following deﬁnition is an algebraic measure for connectivity.

Deﬁnition 12 (Algebraic conductance) Let G be a graph, and let

λn ≤ λn−1 ≤ ... ≤ λ2 ≤ λ1 be the eigenvalues of its random walk
matrix. Then, G is a said to be a λ-expander if its generalized second
eigenvalue λ(G) := maxi (cid:54)=1 |λi | satisﬁes λ(G) ≤ λ.

We note that the notions of conductance and algebraic conduc-
tance are tightly related via the celebrated Cheeger inequality [9].
We refer the reader to the text of Hoory et al. [18] for through ex-
position and elaborate discussion regarding conductance and graph
expansion.

Proof of Theorem 2

Theorem 2 follows by induction from the following Lemma:
Lemma 1 Let G = (V , E ) be a surety graph with A ⊆ A(cid:48) ⊆ V ,

and set α, β , γ , δ ∈ [0, 1] and d > 0.

Assume:
1. deg(v) ≤ d for all v ∈ A(cid:48) .
[The graph has a bounded degree].
2. Every a ∈ A(cid:48) satisﬁes |{x∈A(cid:48) | (a,x)∈E}|
≥ α.
[Sufﬁciently many edges are within members of A(cid:48) ]
|A

d

3.

