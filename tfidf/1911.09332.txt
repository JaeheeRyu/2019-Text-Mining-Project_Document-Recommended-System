9
1
0
2

v
o

N

1
2

]

V

I

.

s
s

e
e

[

1
v
2
3
3
9
0

.

1
1
9
1

:

v

i

X

r

a

2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)

Heart Segmentation From MRI Scans Using
Convolutional Neural Network

Shakeel Muhammad Ibrahim

Department of Computer Science,
University of Karachi,
Karachi-75270, Pakistan.
shak.ibrhm.97@gmail.com

Muhammad Sohail Ibrahim

College of Electrical Engineering
Zhejiang University,
Hangzhou, Zhejiang, China 310027.
msohail@zju.edu.cn

Muhammad Usman

FEST,
Iqra University,
Karachi-75500, Pakistan.
musman@iqra.edu.pk

Imran Naseem

College of Engineering,
Karachi Institute of Economics and Technology,
Karachi 75190, Pakistan.
imrannaseem@pafkiet.edu.pk

Muhammad Moinuddin

CEIES,
King Abdulaziz University
Saudi Arabia.
mmsansari@kau.edu.sa

Abstract—Heart is one of the vital organs of human body.
A minor dysfunction of heart even for a short time interval
can be fatal, therefore, efﬁcient monitoring of its physiological
state is essential for the patients with cardiovascular diseases.
In the recent past, various computer assisted medical imaging
systems have been proposed for the segmentation of the organ
of interest. However, for the segmentation of heart using MRI,
only few methods have been proposed each with its own merits
and demerits. For further advancement in this area of research,
we analyze automated heart segmentation methods for magnetic
resonance images. The analysis are based on deep learning
methods that processes a full MR scan in a slice by slice fashion
to predict desired mask for heart region. We design two encoder-
decoder type fully convolutional neural network models (1) Multi-
Channel input scheme (also known as 2.5D method), (2) a single
channel input scheme with relatively large size network. Both
models are evaluated on real MRI dataset and their performances
are analysed for different test samples on standard measures
such as Jaccard score, Youden’s index and Dice score etc.
Python implementation of our code is made publicly available at
https://github.com/Shak97/iceest2019 for performance evaluation.

Index Terms—Medical Imaging, Segmentation, Cardiovascular
Imaging, Machine learning, Neural Networks, Deep Learning, Fully
Convolution Neural Network (FCNN), Magnetic Resonance Imaging
(MRI).

I . IN TRODUC T ION

Heart is one of the vital organs of human body. It is the most
hardworking organ that keeps circulating the blood in the body,
thus playing indispensable role in maintaining the energy lev-
els of the body. A minor dysfunction of heart even for a short
time interval can be fatal, therefore efﬁcient monitoring of its
physiological state is essential for patients with cardiovascular
diseases (CVD). To accomplish this important task, variety of
medical imaging modalities have been introduced in the last
few decades such as ultrasound, X-Ray computed tomography
(CT), and magnetic resonance (MR) imaging etc.
The Ultrasound (US) is a real-time, radiation free and non-
invasive and the safest imaging modality. However, it has some
limitations such as, low contrast, perspective visualization (2D

projection of 3D object), low penetration, and small ﬁeld of
view etc [1]. On the other hand, CT provides 3D tomography
with high quality speckle free images that have desired contrast
information which can help in better diagnosis. But similar to
X-Ray, CT imaging is also a radiation based imaging therefore
it is used as an ofﬂine imaging system that suits best in
emergency situations. Due to its ionization characteristics, it is
unsuitable for the patients who are at high risk e.g., pregnant
women or young children etc [2].
MR imaging (MRI) is the second most safest
imaging
modality. Unlike CT which works on the principle of radiation,
in MRI, the body is magnetized by powerful magnets and the
spin of the protons in hydrogen or other elements of choice
(depending on the application of MRI) are synchronized with
the resonant frequency. The change in the resonance of the spin
is measured in Fourier domain and with the help of inverse
Fourier transform high quality MR images are produced. To
scan the region of interest (ROI), variety of scanning schemes
are used which affect
the quality,
interpretation of pixel
intensity, and acquisition time. By properly manipulating the
control parameters, the desired quality of MRI can be obtained.
A drawback of obtaining MRI is its scan time, which is several
times higher than the CT or US imaging. However, for ofﬂine
applications where highest contrast and superior resolution
is required without the risk of radiation exposure, MRI is
considered as a gold standard option. One such application
is the detailed diagnosis of heart for its physical structural
and metabolic functional analysis [3].
With the advent of modern medical facilities it has now
become an standard practice to store and analyse biomedical
data to further improve the diagnostic processes. The type of
data ranges from molecular level to the 3D MRI scan of fully
human body. Substantially, large medical imaging datasets are
being introduced and the demand for automated medical assis-
tance system is increasing subsequently. A thorough research
in the domain of biomedical engineering has been observed

978-1-7281-4956-1/19/$31.00 c(cid:13)2019 IEEE

 
 
 
 
 
 
2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)

in the recent years. The medical data is mostly heterogeneous
as it is obtained after a variety of different clinical analysis
procedures and the wide range of medical imaging modalities.
Manual processing of such data is extremely difﬁcult task
which costs both the time and money to analyze the underlying
information. In order to effectively utilize the acquired data,
machine learning techniques have been effectively used for
a wide number of biomedical applications such as protein
prediction [4], [5], [6] and cancer classiﬁcation [7], [8].
Various computer assisted medical imaging systems have
been proposed for variety of biomedical applications such
as classiﬁcation of tumor, segmentation of organ of interest,
and registration of multi-modality images etc. For computer
assisted surgeries and diagnosis systems, the detection and
identiﬁcation of ROIs is one of many challenging tasks. The
age, size and gender of the humans have direct impact on
the shapes and sizes of the internal organs. Therefore a great
degree of variation is taken into account. The complications
in identifying the upper and lower part of the heart can put
even an experienced radiologist in a great inconvenience.
Supplementary hitches are added while seeking computer
based assistance. To design a computer based medical imaging
system, there is a need of high quality images in which ROIs
can be easily distinguished e.g., in MRI. To the best of our
knowledge only a few methods exist for the segmentation of
heart [9], [10], [11]. Previously the segmentation task was per-
formed using the conventional methods such as edge detection
[9]. 2D and 3D CNN were investigated for the tasks of heart
segmentation in [10]. The use of few parameters were explored
and it was revealed that the use of an optimized 2D approach
yields better results than that of the 3D counterpart. More
recently, in [12] the authors proposed a shape reconstruction
neural network (SCNN) and spatial constraint network (SCN)
to achieve two different tasks. Firstly, SCNN was developed
to maintain the shape of the heart in the segmentation results,
secondly SCN was utilized to solve the problem of large
variation in the 2D slices. In [13] cardiopath classiﬁcation
of heart disease was performed. The ROIs were generated
using the you only look once (YOLO) based object detection
method. The proposed approach produced adequate accuracy
results compared to the previous methods. A cluster based
approach named vantage point is proposed in [14]. Complete
feature vector was used and representation pattern in higher
dimensions feature space were found.
For further advancement in this area of research, in this pa-
per, we implemented an automated heart segmentation method
for MR images. The proposed approach is a deep learning
based method that processes a full MR scan in a slice by slice
fashion to predict desired mask for heart region.
The contributions of this research are as follows:
1) A fully automated computer assisted method is proposed
for the segmentation of heart region from MRI.
2) Two U-Net [15] like fully convolutional network models
are designed for the said task (i) multi-channel input
scheme (also known as 2.5D method), (ii) a single
channel input scheme with relatively large size network.

3) A comparative analysis for both schemes are presented
exhibiting their performances.
4) The proposed models are evaluated on real MRI dataset
and their performance is analyzed for different standard
measures such as Jaccard score and Dice score etc.
5) Python implementation of our method is made public
for the performance evaluation.
We organized this paper in following sections: in Section
II, we discuss the details of our proposed method followed by
the experimental results and discussion in section III and the
conclusion of this study is presented in section IV.

I I . M ETHOD

The method is based on fully convolutional neural net-
work, which is trained using the concept of data driven
supervised learning, where representative examples are used
to ﬁne tune the learning parameter of the model. Typically
medical imaging datasets are huge in size and have highly
imbalanced distributions which make it difﬁcult
to design
machine learning based model using conventional approaches.
In this regard, the deep learning has proven to show great
success [16]. MR scan produce 3D tomographic view of
the body which is computationally very expensive to process
with deep learning algorithms [10]. Therefore, to perform the
heart segmentation from MRI scans, we divide 3D cubes into
multiple 2D images. For these 2D image planes, we trained
a convolutional neural network that generates desired masks
for each input image. Details of dataset, network conﬁguration
and training strategies are discussed in subsequent sections.

A. Dataset
The dataset is downloaded from the medical segmentation
decathlon (MSD) challenge dataset from (https://decathlon- 10.
grand- challenge.org/home/). The MSD challenge dataset
is
specially designed for generalized segmentation task and con-
sists of 3D MR scans of 10 different body parts including liver,
pancreas and heart. For this study, we used ’Task2’ dataset
which is comprised of 20 heart MRI scans. Out of these 20
scans, 14 and 2 scans are randomly selected for the training
and validation of the model respectively, while remaining 4
scans were used as test scans. Each 3D scan is converted
into a set of images, having dimensions of 320 × 320 × 1.
In particular there are 1578, 218, and 455 pairs of input/label
images in training, validation, and test datasets respectively.

B. Network Speciﬁcation and Training
We design 5 different models which can be classiﬁed into
two groups (1) thin networks with 1, 3, 5, and 7 input chan-
nels. (2) thick network with only 1 input channel. All other
hyper-parameters in both groups are same. Fig.1 shows the
generalized block diagram of models. The variable parameters
are deﬁned by number of input channels (CH) and number of
ﬁlters (NF). As shown in Fig.1, the proposed design consists
of two types of modules Mod 1 and Mod 2, the conﬁguration
of which are depicted in Fig.2. In particular, Mod 1 consists
of two convolution layers, two batch normalization layers and

2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)

the K number of ﬁlters, which for instance in C 3 equals to
2×NF, whereas, Mod 2 contains an additional concatenation
layer along with the two convolutional and batch normalization
layers. As stated earlier the conﬁguration of thin networks
is N F = 16 and CH = {1, 3, 5, 7} and for thick network
N F = 16 and CH = 1 is chosen. In all models, ReLU acti-
vation function is used in every layer except the output layers
where sigmoid function is used as an activation function. The
Dropout and Max-pooling layers are also used as speciﬁed in
Fig.1.

Fig. 1: Architecture of our convolutional neural network
model.

Fig. 2: Schematic diagram of individual modules of Fig. 1

The model is implemented in Python TensorFlow using
Keras library. To train a neural network, variety of algorithms

have been proposed [17], [18], [19]. Each has its own merits
and demerits. However in general, the Adam optimizer [20]
is considered as the best choice for variety of problems.
Therefore, to train our model we opt to use Adam optimizer,
keeping the default value of all parameters. In the proposed
method, we minimized the categorical cross entropy loss
function L for 10 epochs. The categorical cross entropy loss
function is deﬁned as

L(y , ˆy) = − R(cid:88)

Q(cid:88)

(yq ,r log( ˆyq ,r )),

(1)

r=0

q=0

where y is the original mask and ˆy is the predicted mask in
vector form, while Q is the number of training samples and
R is the number of categories which is 2 in this study i.e., (0:
background pixel and 1: segment pixel). For each epoch, we
monitor the training and validation losses along with the Dice
scores (deﬁned in (5)).

C. Performance Metrics
We used following metrics to analyze the performance of
the CNN models presented in this study.
1) True positive rate (TPR), recall, or sensitivity

T P R =

T P
T P + F N

2) False positive rate (FPR), fallout, or (1- speciﬁcity)

F P R =

F P
F P + T N

3) Positive predicted value (PPV), or precision

P P V =

T P
T P + F P

4) F1 / Dice score

Dice =

2T P
2T P + F P + F N

5) Jaccard index (JI) or Jaccard similarity coefﬁcient

J I =

T P
T P + F P + F N

6) Youden index (YI) or informedness

Y I = T P R − F P R

(2)

(3)

(4)

(5)

(6)

(7)

where TP, FP, TN, and FP are the number of true positive,
false positive, true negative, and false negative predictions of
the number of pixels respectively.

I I I . EX PER IM EN TA L R E SU LT S AND D I SCU S S ION

In this study we implemented ﬁve different models which
are categorized into two groups (1) thin networks with N F =
16 and CH = {1, 3, 5, 7} and (2) thick network with N F =
64 and CH = 1. For all models, same datasets and hyper-
parameters are used. The thin models with CH = {1, 3, 5, 7}
achieved dice score of 0.65, 0.73, 0.75, and 0.77 respectively.
This indicates that the model with same number of learning
parameters (NF), performs better if adequate neighbourhood

2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)

information is provided. Although, the computational cost of
the prediction is deﬁned by the N F and number of layers,
however for each image we need to process CH number of
images simultaneously. Which means the memory requirement
for each training epochs will increase. Another method to
exploit the memory is to increase the size of network, which
eventually increases the computational complexity.
To analyze the effect of model’s complexity, we design
a relatively thick model with N F = 64 and CH = 1.
This model presented signiﬁcant performance improvement
compared to the thin models. For better understanding of the
performance we calculated variance statistics of our predicted
masks and also analyze the visual difference in ground truth
and prediction of the thick network. Fig. 3 shows the dice
coefﬁcient and loss curves of 10 epochs for training and
validation phases. Fig. 3(a) shows the dice coefﬁcient verses
numbers of training epochs. A signiﬁcant increase in the dice
similarity is observed with subsequent increase in the number
of epochs. The behavior of loss function with respect to the
increase in epochs for the training phase is shown in Fig. 3(b).
The dice coefﬁcient and loss function behavior of validation
phase is depicted in Fig. 3(c) and (d) respectively. Since no
further increment in the validation performance is observed,
therefore we stop the training after 10 epochs.

Fig. 3: (a) Dice coefﬁcient curves for training dataset, (b) Cross
entropy loss curve for training dataset, (c) Dice coefﬁcient
curves for validation dataset, (d) Cross entropy loss curve for
validation dataset.

TABLE I: Performance statistics of model#5

Performance metrics

Recall
Fallout
Precision
Dice score
Jaccard index
Youden’s index

0.7697 ± 0.3519
0.0007 ± 0.0012
0.8471 ± 0.1602
0.8216 ± 0.2067
0.7361 ± 0.2260
0.7685 ± 0.3513

The visual examples of prediction are shown in Fig. 4. It
is evident from the ﬁgure that the ground truth has been ac-

curately predicted, achieving a signiﬁcant dice score of 0.973,
0.953, and 0.924, for the examples 1, 2, and 3 respectively.

Fig. 4: Three good example results of heart segmentation using
single channel CNN model

For the sake of comparison, some worst case scenarios in
terms of prediction are also shown. These cases may occur due
to various reasons such as over-ﬁtting, inappropriate selection
of input channels/ﬁlters, etc. Such schemes result in very low
dice scores as shown in Fig. 5.
This model yielded a dice score of 0.8216 with a standard
deviation of ± 0.2067. The detailed statistical analysis is
summarized in Table I.
This clearly corroborates the proposition that a simple
encoder-decoder styled CNN model with skip-connections can
effectively predict the segmentation of heart region from MRI
scans. It is noteworthy to point out that the the performance
in large region’s segmentation is very good however, for small
sized segment the performance is very low which is also
evident in inferior dice scores.

IV. CONCLU S ION

Herein, we demonstrated the application of deep learning
for the segmentation of heart region from MRI scans. We
design a fully convolution neural network based system which
is trained using the concept of data driven supervised learn-
ing, where representative examples are used to ﬁne tune the
learning parameter of the model. Two approaches presented
in this study revealed that a signiﬁcant improvement in the
performance can be achieved by either processing multiple
images simultaneously through multiple input channels or by
increasing the number of ﬁlters in each convolution layer. In-
creasing the input dimensions or the network parameters both
contribute to the constructive performances. It can therefore be

2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)

[6] M. Usman and J. A. Lee, “Afp-cksaap: Prediction of antifreeze proteins
using composition of k-spaced amino acid pairs with deep neural
network,” arXiv preprint arXiv:1910.06392, 2019.
[7] S. Khan, I. Naseem, R. Togneri, and M. Bennamoun, “A novel adaptive
kernel for the rbf neural networks,” Circuits, Systems, and Signal
Processing, pp. 1–15, 2016.
[8] S. Khan, J. Ahmad, I. Naseem, and M. Moinuddin, “A novel fractional
gradient-based learning algorithm for recurrent neural networks,” Cir-
cuits, Systems, and Signal Processing, pp. 1–20, 2017.
[9] S. Xie and Z. Tu, “Holistically-nested edge detection,” in Proceedings of
the IEEE international conference on computer vision, 2015, pp. 1395–
1403.
[10] C. F. Baumgartner, L. M. Koch, M. Pollefeys, and E. Konukoglu, “An
exploration of 2d and 3d deep learning techniques for cardiac mr image
segmentation,” in International Workshop on Statistical Atlases and
Computational Models of the Heart. Springer, 2017, pp. 111–119.
[11] O. Oktay, E. Ferrante, K. Kamnitsas, M. Heinrich, W. Bai, J. Caballero,
S. A. Cook, A. De Marvao, T. Dawes, D. P. ORegan et al., “Anatomi-
cally constrained neural networks (acnns): application to cardiac image
enhancement and segmentation,” IEEE transactions on medical imaging,
vol. 37, no. 2, pp. 384–395, 2017.
[12] Q. Yue, X. Luo, Q. Ye, L. Xu, and X. Zhuang, “Cardiac segmentation
from lge mri using deep neural network incorporating shape and spatial
priors,” arXiv preprint arXiv:1906.07347, 2019.
[13] Y. Chang, B. Song, C. Jung, and L. Huang, “Automatic segmentation and
cardiopathy classiﬁcation in cardiac mri images based on deep neural
networks,” in 2018 IEEE International Conference on Acoustics, Speech
and Signal Processing (ICASSP).
IEEE, 2018, pp. 1020–1024.
[14] M. P. Heinrich and M. Blendowski, “Multi-organ segmentation using
vantage point forests and binary context features,” in International
Conference on Medical Image Computing and Computer-Assisted In-
tervention. Springer, 2016, pp. 598–606.
[15] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
for biomedical image segmentation,” in International Conference on
Medical image computing and computer-assisted intervention. Springer,
2015, pp. 234–241.
[16] A. Kumar, J. Kim, D. Lyndon, M. Fulham, and D. Feng, “An ensemble
of ﬁne-tuned convolutional neural networks for medical image classi-
ﬁcation,” IEEE journal of biomedical and health informatics, vol. 21,
no. 1, pp. 31–40, 2016.
[17] S. Khan, I. Naseem, M. A. Malik, R. Togneri, and M. Bennamoun, “A
fractional gradient descent-based rbf neural network,” Circuits, Systems,
and Signal Processing, pp. 1–22, 2018.
[18] O. Oktay, E. Ferrante, K. Kamnitsas, M. Heinrich, W. Bai, J. Caballero,
S. A. Cook, A. De Marvao, T. Dawes, D. P. ORegan et al., “Anatomi-
cally constrained neural networks (acnns): application to cardiac image
enhancement and segmentation,” IEEE transactions on medical imaging,
vol. 37, no. 2, pp. 384–395, 2017.
[19] A. Kumar, J. Kim, D. Lyndon, M. Fulham, and D. Feng, “An ensemble
of ﬁne-tuned convolutional neural networks for medical image classi-
ﬁcation,” IEEE journal of biomedical and health informatics, vol. 21,
no. 1, pp. 31–40, 2016.
[20] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
arXiv preprint arXiv:1412.6980, 2014.

Fig. 5: Example results when single channel CNN model failed
to predict correct mask.

concluded that a simple encoder-decoder styled CNN model
with skip-connections can effectively predict the segmentation
of heart region from MRI scans, specially in the images with
large segmentation region. However, for small segments the
performance is not satisfactory, and therefore, the efﬁcacy of
the advanced CNN architectures and loss functions that can
improve the accuracy for small size segments can be explored
in future studies.

R E FERENC E S
[1] Y. H. Yoon, S. Khan, J. Huh, J. C. Ye et al., “Efﬁcient b-mode ultrasound
image reconstruction from sub-sampled rf data using deep learning,”
IEEE transactions on medical imaging, 2018.
[2] E. Robbins, “Radiation risks from imaging studies in children with
cancer,” Pediatric blood & cancer, vol. 51, no. 4, pp. 453–457, 2008.
[3] L. Wang, H. Nie, Q. Wang, G. Zhang, G. Li, L. Bai, T. Hua, and S. Wei,
“Use of magnetic resonance imaging combined with gene analysis for
the diagnosis of fetal congenital heart disease,” BMC medical imaging,
vol. 19, no. 1, p. 12, 2019.
[4] I. Naseem, S. Khan, R. Togneri, and M. Bennamoun, “Ecmsrc: A sparse
learning approach for the prediction of extracellular matrix proteins,”
Current Bioinformatics, vol. 12, no. 4, pp. 361–368, 2017.
[5] S. Khan, I. Naseem, R. Togneri, and M. Bennamoun, “Rafp-pred: Robust
prediction of antifreeze proteins using localized analysis of n-peptide
compositions,” IEEE/ACM Transactions on Computational Biology and
Bioinformatics, vol. PP, no. 99, pp. 1–1, 2017.

