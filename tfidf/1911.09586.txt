The Performance of Machine and Deep Learning
Classiﬁers in Detecting Zero-Day Vulnerabilities

Faranak Abri1 , Sima Siami-Namini2 , Mahdi Adl Khanghah3 , Fahimeh Mirza Soltani3 , and Akbar Siami Namin1

1Department of Computer Science, Texas Tech University, USA
2Department of Mathematics and Statistics, Texas Tech University University, USA
3Department of Computer Science, University of Debrecen, Hungary
{faranak.abri, sima.siami-namini, akbar.namin}@ttu.edu; {adl.mahdi1365, soltani.fahimeh1364}@gmail.com

9
1
0
2

v
o

N

1
2

]

R
C

.

s

c

[

1
v
6
8
5
9
0

.

1
1
9
1

:

v

i

X

r

a

Abstract—The detection of zero-day attacks and vulnerabilities
is a challenging problem. It is of utmost importance for network
administrators to identify them with high accuracy. The higher
the accuracy is, the more robust the defense mechanism will be.
In an ideal scenario (i.e., 100% accuracy) the system can detect
zero-day malware without being concerned about mistakenly
tagging benign ﬁles as malware or enabling disruptive malicious
code running as none-malicious ones. This paper investigates
different machine learning algorithms to ﬁnd out how well they
can detect zero-day malware. Through the examination of 34
machine/deep learning classiﬁers, we found that the random
forest classiﬁer offered the best accuracy. The paper poses several
research questions regarding the performance of machine and
deep learning algorithms when detecting zero-day malware with
zero rates for false positive and false negative.
Index Terms—zero-day vulnerability, machine learning

I . IN TRODUC T ION

Malware is a malicious application, speciﬁcally developed
to perform malicious activities including disruption, damaging
the underlying computer system and data, or gaining autho-
rized access to the computer systems. A common approach
to identify malicious applications is through signature-based
matching, where the proﬁle of a suspicious application is
compared against the reported ones. The popular intrusion
detection systems often employ such pattern-matching tech-
niques and tools such as YARA [1] to implement rule-based
detection mechanisms. These pattern matching approaches to
the malware detection problem, however, are static and thus
not capable of detecting all types of malware. Broadly speak-
ing, pattern and signature-based malware detection mecha-
nisms have the ability of detecting only a small subset of
all classes of malware software and thus these approaches
are less effective in detecting more sophisticated, obfuscated,
unknown, or newly developed malware software. A special
case of interest is zero-day, a type of malware with no history
or clear remediation strategy.
The software vulnerability, which is unknown to system
administrators and thus there is no known security patches or
remedies to confront it, is called a zero-day vulnerability. Due
to the absent of a structured remediation strategy and mitiga-
tion plan, such vulnerabilities are exploitable by adversaries.
The signature-based approaches to malware detection can-
not be utilized to catch zero-day malware applications. As a
result, instead of syntactical approaches (i.e., signature-based)

analytical techniques should be employed. Approaches such
as behavioral-based [2], data mining-based [3], learning-based
[4], machine learning [5], and more notably deep learning-
based [6] have already been proposed to detect malware.
The conventional machine learning algorithms developed
for addressing clustering problems employ various forms of
classiﬁcation techniques to group a given dataset into distinct
sub-classes. For instance, regression-based approaches parti-
tion the given data into two or more clusters and then ﬁt
multiple linear regression lines on the data within each cluster;
whereas, the Support Vector Machine (SVM) algorithms in-
tend to partition the given data into clusters by ﬁtting a hyper-
plane into the data with acceptable margins. Furthermore,
ensemble learning-based approaches such as random forest
build multiple decision trees and then take the majority votes
of these decision trees and then perform clustering.
As an extension to conventional machine learning algo-
rithms, the deep learning-based approaches [7]–[9] take the
clustering problem into a deeper level by exploring the hidden
relationships between the features of the dataset and then
building a hierarchical model to perform clustering. While the
time complexity of building such models is high, the deep
exploration of data helps in building more accurate clustering.
Given the recent advancement in deep learning-based ap-
proaches to model prediction problems, a major challenging
question is whether these learning-based techniques and in
particular machine and deep learning algorithms are effective
in detecting zero-day malicious software. This paper inves-
tigates the performance of the conventional machine learn-
ing techniques in comparison with their counterparts, deep
learning-based algorithms. The goal is to empirically observe
whether these learning-based approaches are a suitable model-
ing approach for detecting zero-day vulnerabilities. The paper
conducts several experiments with respect to four learning-
based clustering techniques:
1) Conventional machine learning
2) Simple neural network learner (i.e., Single layer)
3) Deep learning with multiple layers
4) Deep(er) learning with multiple hidden layers
While it is expected that these learning-based algorithms
demonstrate acceptable performance and accuracy, it is crucial
that the malware detection systems learned and developed
for catching zero-day vulnerabilities do not label legitimate

 
 
 
 
 
 
applications as malware (i.e., zero false positive), and do
not label malicious applications as legitimate (i.e., zero false
negative). An elevated false positive and false negative rates
will cause either eliminating important ﬁles or enabling ma-
licious applications to be installed and then activated on the
underlying operating systems and thus it leads to serious loss
or damage to the assets. Hence, it is of utmost importance
to achieve extremely high accuracy and extremely low false
positive/negative predictions when building the model.
This paper investigates the performance of the aforemen-
tioned learning-based classes of algorithms for a given dataset
and measures the accuracy of the models built using popular
cross validation approaches (k-fold). The key contributions of
this paper are as follows:
1) Conduct several experimental studies to compare the
performance of various types of machine and deep
learning algorithms in detecting zero-day vulnerabilities.
2) Report that no individual learning algorithm was able to
achieve 100% accuracy when ﬁtting the models.
3) Report
that
the conventional machine learning algo-
rithms are as good as deep learning-based models.
4) Report that random forest outperforms other machine
and deep learning algorithms in providing the best
models for detecting zero-day vulnerabilities.
The paper is organized as follows: Section II highlights
the research questions to address. A background on zero-day
malware and vulnerability detection is presented in Section
III. The experimental setup is provided in Section IV. Section
V lists the classiﬁers along with their parameters studied
in this paper. Section VI reports the results and compares
the performance of different machine and deep learning al-
gorithms. Section VII discusses some implications observed
while analyzing the experimental data. Section VIII concludes
the paper and highlights the future research directions.

I I . CHAL LENGE S AND R E SEARCH QU E S T ION S

This paper empirically investigates whether it is possible to
train learning-based algorithms and then employ the developed
model to predict whether a zero-day vulnerability or malware
with no prior historical data can be detected. More speciﬁcally,
the experiments conducted in this paper intend to address the
following research questions:
RQ. 1 Does standardization of data help in enhancing the
accuracy?
RQ. 2 Is it possible to train a machine/deep learning algo-
rithm and achieve 100% accuracy for prediction and
thus reduce the false positive/negative ratios to zero
for detecting zero-day vulnerabilities/malware?
RQ. 3 Which machine/deep learning algorithm performs the
best for detecting zero-day malware?
RQ. 4 Does the batch size, i.e., the size of the next batch
of data for training a model, inﬂuence the accuracy
of predictions?
RQ. 5 Does over-training a machine/deep learning model
increase the accuracy of detecting zero-day malware?

I I I . S TAT E -O F - THE -ART: Z ERO -DAY AT TACK S

Bileg and Dumitras [10] conducted a study on zero-day
attacks to identify their characteristics before and after dis-
closure. Based on their study, a zero-day attack lasts ap-
proximately for 312 days and at most 30 months. It was
also reported that once these vulnerabilities are revealed, the
number of their exploitation increases ﬁve times. They also
suggested a heuristic approach for identifying zero-day attacks.
Miller [11] investigated several research questions about
efﬁcient machine learning systems for detecting zero-day mal-
ware including the application of feature selection techniques
for this problem. It was suggested that the best approach
for feature selection is using a combination of features but
at
the same time reducing the number of features based
on the classiﬁer type. Miller also suggested that combining
classiﬁcation and clustering techniques and taking advantage
of using different classiﬁers would lead to better results and a
safety net against false positives.
Sharma et al. [12] proposed a prevention strategy, called
Distributed Diagnosis System (DDS), based on the context
graph strategy. The DDS system consists of three parts: 1)
Central Diagnosis System (CDS), 2) Local Diagnosis System
(LDS), and 3) Semi Diagnosis System (SDS). The DDS
system was developed to guarantee the protection of IoT
devices once a possible zero-day vulnerability is identiﬁed.
Their strategy considers a protocol for sharing sensitive data
among IoT devices and other network entities. As a general
prevention strategy, if an IoT device is infected, it will be
removed from the network before exploiting other entities.
Alazab et al. [13] developed a machine learning framework
to detect zero-day vulnerability. They trained eight different
classiﬁers which worked based on the API call sequences and
frequencies, as the feature set. Their framework ﬁrst retrieves
the API call sequences from the disassembled executable
and then updates the signature database based on these API
calls and then reports the similarity value. The classiﬁcation
is applied using a supervised learning algorithm with eight
classiﬁers. They achieved an acceptable true positive and false
positive rates using Support Vector Machine (SVM) to detect
unknown malware samples with obfuscated code.
Comar et al. [14] developed a two-level framework for zero-
day malware detection. The framework consists of six parts:
1) a data capture module, 2) an intrusion detection/prevention
system (IDS/IPS), 3) an information storage, 4) the feature ex-
traction and transformation module, 5) a supervised classiﬁer,
and 6) an UI portal. Using a class-based proﬁling technique,
their framework was able to separate unknown malware form
the known ones and then using network trafﬁc features for
their SVM classiﬁer it could detect zero-day malware.
Zho and Pezaros [15] evaluated six different machine learn-
ing models for zero-day intrusion detection. The train dataset
consists of fourteen different intrusions and their test dataset
consists of eight different types of zero-day attacks. Using a
decision tree classiﬁer, they achieved 96% accuracy, 5% false
positive rate with acceptable overhead.

Xiao et al. [16] designed an IoT attack model and discussed
different
learning techniques for IoT security. The super-
vised, unsupervised, and reinforcement learning algorithms
were employed for different security aspects such as malware
detection, authentication, and access control. They provided
a few backup security solutions with the machine learning-
based security schemes to enable reliable and secure IoT
services. They also recommended some solutions to avoid
problems such as oversampling, insufﬁcient training data, and
bad feature extraction in the learning methods.

IV. EX PER IM EN TA L S E TU P

A. Dataset and Features
We obtained the data from the Kaggle Website [17]. Ac-
cording to the hosting Website, the raw dataset had been
obtained from the malware security partner of Meraz’18, the
annual techno-cultural festival of IIT Bhiali. According to the
contributor, the raw dataset included features for both malware
and legitimate ﬁles. The dataset is offered in two pieces: The
ﬁrst piece of data is the training dataset with 138, 047 records
of sample data. The sample data itself consists of 96, 724
records whose legitimate parameter is labeled as “0” and
41, 323 records are labeled as “1”. The number of features is
reported as 55. The second part of the data is “unlabeled” test
data with 88, 258 records of sample data and 55 features. Since
the second part of the data is unlabeled, we only conducted
experiments on the ﬁrst part of the (i.e., the training dataset).
We ignored three features while building our classiﬁers

namely: ID, Machine, and SizeOfOptionalHeader,

since these features appeared to be constant over the data.
Table I lists the features that were used for building the
classiﬁers (i.e., 52). As the class label, the legitimate
feature was utilized, where values “0” and “1” represent the
benign and malicious ﬁles, respectively. A cross-validation
strategy (i.e., k-fold) is utilized to “validate” the ﬁtness of
the models built.
Figure 1 illustrates the correlation matrix of the features.
The correlation values vary in the range of (−0.6, +0.3). Most
of the correlation values are close to zero indicating that there
is no strong correlation between most of the features.

B. Evaluation Metrics

The model_selection.cross_val_score method

was used to evaluate the performance of the classiﬁers studied.
The method is offered by the Python sklearn package. Ac-
cording to its documentation, the method returns the accuracy
of cross validation where accuracy is deﬁned as the fraction
of true (i.e., correct) predictions of the model. The accuracy
metric can be formally computed as following:

Accuracy =

=

#C orrect P redictions
#T otal P redictions
T P + T N
T P + T N + F P + F N

(1)

Where TP, TN, FP, and FN represent True Positives, True
Negatives, False Positive, and False Negatives, respectively.

TH E SE LECT ED FEATUR E S O F THE DATA S ET.

TABLE I

Features

Characteristics
MajorLinkerVersion
MinorLinkerVersion
SizeOfCode
SizeOfInitializedData
SizeOfUninitializedData
AddressOfEntryPoint
BaseOfCode
BaseOfData
ImageBase
SectionAlignment
FileAlignment
MajorOperatingSystemVersion MinorOperatingSystemVersion
MajorImageVersion
MinorImageVersion
MajorSubsystemVersion
MinorSubsystemVersion
SizeOfImage
SizeOfHeaders
CheckSum
Subsystem
DllCharacteristics
SizeOfStackReserve
SizeOfStackCommit
SizeOfHeapReserve
SizeOfHeapCommit
LoaderFlags
NumberOfRvaAndSizes
SectionsNb
SectionsMeanEntropy
SectionsMinEntropy
SectionsMaxEntropy
SectionsMeanRawsize
SectionsMinRawsize
SectionMaxRawsize
SectionsMeanVirtualsize
SectionsMinVirtualsize
SectionMaxVirtualsize
ImportsNbDLL
ImportsNb
ImportsNbOrdinal
ExportNb
ResourcesNb
ResourcesMeanEntropy
ResourcesMinEntropy
ResourcesMaxEntropy
ResourcesMeanSize
ResourcesMinSize
ResourcesMaxSize
LoadConﬁgurationSize
VersionInformationSize
legitimate (class Label)

C. Experimental Setup
We used the open-source Anaconda with Python 3.7.4,
TensorFlow 1.14.0, and ran the experiments on a MacBook
Pro laptop computer with 2.9 GHz Intel Core i9 processor
and 32GB of Ram with 2400 MHz DDR4.

V. TH E CHO SEN C LA S S I FIER S

The research team chose a diverse set of machine and deep
learning algorithms grouped into three major classes:

– Conventional Machine Learners including 1) Gaus-

sian Naive Bayes, 2) Quadratic Discriminant Analysis
(QDA), 3) Logistic Regression, 4) AdaBoost, 5) K -
Nearest Neighbors, 6) Decision Tree, and 6) Random
Forest.

– Simple Neural Network with a single Layer, in which

the primary algorithm was the Multi-Layer Perceptron
(MLP) with a single layer of training.

– Simple Neural Network with Multiple Layers and
a Small Value for Epoch,

in which an MLP-based
algorithm was utilized with multiple layers and a small
number of model ﬁtting.

– Simple Neural Network with Multiple Layers and a

Larger Value for Epoch, in which an MLP was utilized
with multiple layers and a large number of training.
The research team developed several Python scripts and
utilized relevant packages to carry out the experiments. These
machine/deep learning algorithms take in several parameters
that were controlled for the purpose of this study. Table II lists
the Python packages used and the parameters sets.

Fig. 1. Correlation heat map of the features.

– AdaBoostClassifier() is a meta-estimator that
starts off with ﬁtting a classiﬁer on the original dataset.
It then ﬁts additional classiﬁer with different weights on
the same dataset to take the classiﬁers attention towards
those instances, which have been classiﬁed incorrectly.
The n_estimators parameter is the maximum number
of estimators to consider when boosting is performed.
The remaining parameters were left as default.

– The DecisionTreeClassifier() classiﬁer is a de-

cision tree classiﬁer whose parameters were set as default.
– GaussianNB() performs online updates to model pa-
rameters. The default parameter values were used.
– LinearSVC() is an efﬁcient implementation of SVC
with a linear kernel. The parameters were left as default.
The Python SVC... library, an inefﬁcient implementa-
tion of the SVM classiﬁer, did not produce any results

even after several hours of executions.
– LogisticRegression() An implementation of reg-
ular logistic regression. The default values for the param-
eters were used.

– The KNeighborsClassifier() classiﬁer is an im-

plementation of the k nearest neighbors clustering. The
parameter n_neighbors was used to determine the
number of clusters. The remaining parameters set as
default.

– QuadraticDiscriminantAnalysis() A classi-

ﬁer that employs a quadratic decision boundary to group
data. The parameters left as default.

– RandomForestClassifier() An ensemble-based

classiﬁer that ﬁts a number of decision tree classi-
ﬁers on different subsets of the data. The parameter
n_estimators is the number of trees in the forest.

TH E PY THON PACKAG E S AND PARAM ET ER SET T ING S EX P LOR ED IN TH I S STUDY.

TABLE II

Classiﬁer

Type

Python Package
Conventional Machine Learning

Parameter Set & Values

n_estimators n = 50, 100, 200

Default
Default
Default
Default

n_neighbors n = 3, 5, 7

Default

n_estimators n = 10, 50, 100

Number of Neurons

Adaptive Boosting
Decision Tree
Gaussian Naive Bayes
Linear SVM (LinearSVC)
Logistic Regression
k Nearest Neighbors
Quadratic Discriminant Analysis
Random Decision Forests

Multi-Layer Perceptron: MLP

Multi-Layer Perceptron: MLP

Multi-Layer Perceptron: MLP

Feature Reduction
Tree-based Decision Support
Probabilistic
Supervised Learning
Logistic function
Unsupervised Learning
General form of Linear Classiﬁer
Ensemble Learners

AdaBoostClassifier(...)
DecisionTreeClassifier(...)
GaussianNB(...)
LinearSVC(...)
LogisticRegression(...)
KNeighborsClassifier(...)
QuadraticDiscriminantAnalysis(...)
RandomForestClassifier(...)

Feed-forward Neural Network

MLPClassifier(...)

Neural Networks with Multiple Layers and Small Epoch

Neural Networks with Single Layer

Feed-forward Neural Network

Feed-forward Neural Network

Neural Networks with Multiple Layers and Larger Epoch

Self-Developed

Self-Developed

The remaining parameters left as default.
– MLPClassifier() A feed-forwarding neural network.
The parameter hidden_layer_sizes represents the
number of neurons in the hidden layer:
– A call to this library with only one parameter value
implies that there is only one layer with the num-
ber of neurons speciﬁed. MLPClassifier(100)
implies that there is only one layer with 100 neurons.
– A call to this library with two values implies that
there are two hidden layers whose number of neurons
is speciﬁed. For instance, MLPClassifier(100,
1) means that there are two hidden layers each with
100 and 1 neurons, respectively.
– A call to this library with three parameter values
implies that
there are three hidden layers whose
number of neurons is speciﬁed as inputs. For in-

stance, MLPClassifier(100, 50, 1) means

that there are three hidden layers each with 100, 50,
and 1 neurons, respectively.
We noticed some differences in the performance when
dealing with raw (i.e., non-standardized) versus standardized
data. The standardization of data means changing the values
to enforce the distribution of standard deviation from the
mean to be equal to one. For the comparison purposes and
discovering whether standardization affects the performance,
we performed the experiments on both non-standardized and
standardized data. The Python StandardScaler(...)
library was used for standardization.
We performed a stratiﬁed 10-fold cross validation on the
dataset. Furthermore, we employed the Python pipeline (i.e.,
pipeline(...)) to sequentially apply a list of transforms
and produce a ﬁnal estimator. The primary purpose of utilizing
the pipeline is to add several layers of ﬁtting-assessing proce-
dure. More speciﬁcally, the pipeline helped us with stacking
two processes: 1) the standardization of the data, and 2) the
application of the speciﬁed classiﬁer.

V I . R E SU LT S

Table III reports the performance of each classiﬁers The
performance is measured in terms of the mean values of accu-
racy obtained along with their standard deviations. The table

also reports the performance achieved by each classiﬁer when
their data were standardized or left as raw (non-standardized).
The classiﬁers are ordered with respect to accuracy achieved
by each classiﬁer.
The classiﬁers are grouped into ﬁve classes with respect to
their demonstrated performance: I) Poorly performed classi-
ﬁers, II) Conventional Machine Learning classiﬁers with good
performance, III) Simple Neural Network with Single Hidden
Layer, IV) Deep Learners with small Epochs, and V) Deep
Learners with larger Epochs.

A. RQ. 1: The Inﬂuence of Standardization?

A quick glance at the accuracy achieved by applying each
classiﬁer on non-standardized and standardized forms of data
shows that (except a couple of cases (Gaussian, Naive Bayes
and Quadratic Discriminant Analysis (QDA))), the classiﬁers
demonstrated an improved accuracy when the given data are
standardized. It was also observed that it takes much smaller
amount of time and effort to train models with standardized
data; whereas, when non-standardized data are fed into the
classiﬁers, it takes considerable amount of time for training
and ﬁtting the models.
The average mean values for accuracy obtained for different
classes of classiﬁers when non-standardized data are mod-

eled are 61.57%, 90.61%, 94.78%, and 58.70% for Poorly

performed classiﬁers, conventional machine learners, Simple
Neural Networks with only one hidden layer, and Deep learn-
ing models, respectively. Whereas, the calculated mean values
for accuracy when standardized data are used are 47.79%,
98.88%, 99.21%, and 98.90% for Poorly performed classiﬁers,
conventional machine learners, Simple Neural Networks with
only one hidden layer, and Deep learning models, respectively.
Excluding the poorly performed classes of classiﬁers, we
observe that standardization help in improving accuracy by
98.90 − 58.70 = 40.2%, for conventional machine learners,
Simple Neural Networks with only one hidden layer and Deep
learning models, respectively. It was also observed that the
standard deviations calculated for accuracy were much higher
for non-standardized data compared to standardized data. The

98.88 − 90.61 = 8.27%, 99.21 − 94.78 = 4.43%, and

TH E PER FORMANC E O F CLA S S I FIER S IN A SC END ING ORD ER O F “ACCURACY ” FOR P I PED AND STANDARD I ZED DATA (cv = 10) .

TABLE III

I) Poorly Performed Learners

61.57%
II) Conventional Machine Learning

Classiﬁer

Gaussian Naive Bayes
Quadratic Discriminant Analysis (QDA)
Average

Logistic Regression
Linear SVM (LinearSVC)
AdaBoost(n = 50)
AdaBoost(n = 100)
AdaBoost(n = 200)
Nearest Neighbors (k = 7)
Nearest Neighbors (k = 5)
Nearest Neighbors (k = 3)
Decision Tree
Random Forest (n = 10)
Random Forest (n = 100)
Random Forest (n = 50)

Average

Accuracy %
No Standardized
Piped and Standardized
Mean
SD
Mean
SD
(Sorted)

76.60% 39.49%
46.55% 34.29%

30.28% 45.20%
84.51% 27.68%
97.57%
3.65%
97.77%
3.35%
97.53%
3.87%
97.88%
2.01%
2.12%
2.45%
9.60%
6.94%
6.89%
6.66%

97.81%
95.20%
96.85%
97.04%
97.07%

97.89%

94.70%
95.19%
95.52%
93.72%

4.36%
4.55%
4.12%
5.05%

65.01% 11.97%
57.13% 16.26%
45.04% 17.57%
65.88% 11.99%
58.03% 18.26%
67.58% 15.08%
45.04% 17.57%
50.02% 20.05%
64.54% 18.83%
66.05% 12.04%
50.02% 20.05%
70.07%
0.00%

46.31%
49.28%

47.79%

97.51%
97.61%
98.78%
98.88%
98.99%
98.99%
99.07%
99.12%
99.24%

99.45%
99.51%
99.51%
98.88%

99.14%
99.21%
99.24%

99.25%
99.21%

98.73%
98.79%
98.83%
98.88%
98.90%
98.90%
98.92%
98.95%
98.95%
98.97%
98.99%
98.99%

98.90%

99.24%
99.28%
99.29%
99.33%

99.28%

0.46%
0.45%

0.19%
0.16%
0.09%
0.06%
0.08%
0.08%
0.08%
0.06%
0.07%
0.06%
0.08%
0.06%

0.07%
0.11%
0.09%
0.08%

0.09%
0.07%
0.07%
0.09%
0.09%
0.07%
0.10%
0.10%
0.09%
0.07%
0.10%
0.10%

0.10%
0.08%
0.06%
0.06%

90.61%
III) Simple Neural Network (One Layer)

Multi-Layer Perceptron: MLP (52)[BatchS ize = Auto]
Multi-Layer Perceptron: MLP (100)[BatchS ize = Auto]
Multi-Layer Perceptron: MLP (200)[BatchS ize = Auto]
Multi-Layer Perceptron: MLP (400)[BatchS ize = Auto]
Average

94.78%
IV) Deep Learning (Multiple Layers): E poch = 5

Multi-Layer Perceptron: MLP (30, 1)[BatchS ize = 100]
Multi-Layer Perceptron: MLP (52, 1)[BatchS ize = 100]
Multi-Layer Perceptron: MLP (100, 1)[BatchS ize = 100]
Multi-Layer Perceptron: MLP (30, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (52, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (52, 30, 1)[BatchS ize = 100]
Multi-Layer Perceptron: MLP (100, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 100]
Multi-Layer Perceptron: MLP (52, 30, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (100, 80, 60, 40, 20, 10, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 5]
Multi-Layer Perceptron: MLP (100, 80, 60, 40, 20, 10, 1)[BatchS ize = 100]
Average

58.70%
V) Deep Learning (Multiple Layers Different Epochs

Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 100],[E poch = 50]
Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 100],[E poch = 100]
Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 100],[E poch = 400]
Multi-Layer Perceptron: MLP (100, 50, 1)[BatchS ize = 100],[E poch = 200]
Average

–
–
–
–

–

–
–
–
–
–

primary reason might be due to the fact that larger and wider
scale of numerical raw values were used in model ﬁtting.

B. RQ. 2: Achieving 100% Accuracy?
The research team tested different classiﬁers with different
tuning parameters with the goal of achieving the mean value
of 100% for accuracy. It turned out that achieving such a high
accuracy on model ﬁtting and prediction was infeasible. While
some of the classiﬁers demonstrated very high accuracy and
thus promising results, it seems that building a model that
reduces the false positive and false negative ratios to zero is
very difﬁcult and hence there are some penalties with missing
such cases for detecting zero-day malware. However, it is also
possible that building a perfect model with 100% accuracy
may imply that the model is overﬁtted and may perform poorly
for classifying unseen data. To avoid such overﬁtting problem,

we employed a 10-fold cross-validation to optimize the models
and that might explain why it was infeasible to build a perfect
model with zero false positive and false negative values.

C. RQ. 3: The Best Classiﬁer?
As Table III shows, the random forest was the best classiﬁer
with outstanding performance of achieving 99.51% on average
for accuracy, followed by decision tree achieving 99.24%.
The simple neural networks with a single hidden layer also
performed very well. On average, they achieved 99.21% on
accuracy. The number of neurons on the singleton hidden
layer seems to have some light impacts on accuracy. For
instance, an MLP model with only one hidden layer and
50 neurons achieved 99.14% accuracy; whereas, increasing
the number of neurons to 100, 200, and 400 increased the
accuracy to 99.21%, 99.24%, and 99.25%, respectively. Since

V I I . D I SCU S S ION

A. Standardization Is Important for Classiﬁcation
According to our results, standardization is critical for
classiﬁcation. The primary reason might be because of compu-
tational expenses involved in dealing with large numbers and
thus with higher standard variations. Some of these classiﬁers
utilize a distance metric (e.g., Euclidean distance) where the
square roots of the sum of the squared differences between
the observations are calculated for clustering the data items.
As a result,
to accommodate such expensive computation
when larger values are provided as data, the demands for
computational needs will be increased. Hence, since a larger
standard deviation will affect the accuracy of the prediction.

B. Feature Reductions and Parameters Tuning
The authors tuned several parameters of the classiﬁers.
Furthermore, they studied several machine/deep learning al-
gorithms. These learners perform the task of classiﬁcations
differently. For instance, one utilizes hyperplanes to create
clusters (e.g., SVM); whereas, some other uses ensemble
learning and take the majority votes to decide (e.g., random
forest). Moreover, some of these techniques apply feature
reductions and thus tune the parameters and build a model;
whereas, some other more advanced algorithms try to take into
account all features and then through deeper analysis adjust
their contributions and weights to the ﬁnal model. A potential
drawback of utilizing all features in the computation is the
overﬁtting problem and thus the model may suffer from being
tightly coupled to the seen data and thus unable to perform
well for unseen data. It also may cause adding noisy features
into the computations. On the other hand, reducing features
may cause the problem of missing important relationships
between parameters. The choice of feature reduction depends
on the type of dataset and is an important decision and should
be handled with additional care.

C. Conventional vs. Deep Learning Classiﬁers
The authors expected to observe much better performance
from deep learning-based algorithms. While these deep learn-
ers performed very well, surprisingly, some of the conventional
machine learning classiﬁers performed comparatively similar
or even better. Given the lower cost of training associated with
the conventional machine learning algorithms and at the same
time a considerably greater cost for training deep classiﬁers,
the conventional machine learning algorithms might be even a
better choice compared to the deep learning-based algorithms.
The deep learning-based classiﬁers demonstrate a consistent
improvement achieved by building larger models and addi-
tional training. However, a simple random forest algorithm
still outperforms even larger deep learning-based classiﬁers
with additional training. For instance, the performance demon-
strated by Random Forest (i.e., 99.51%) and the best per-
formance achieved by deep learning (i.e., 99.33%) after 200
epochs with three hidden layers is remarkable.

Fig. 2. Accuracy vs. Epochs.

there are some computational costs associated with the number
of neurons on the layer, and given the slights improvement
on the observed accuracy, the question is whether a more
complex model is worthy to be built or a simpler model with
slightly lower accuracy would be sufﬁcient for the prediction.
The choice of this trade-off totally depends on the application
domain. As a special case, detecting zero-day malware is an
important and critical task and thus increasing the accuracy as
much as possible is indeed needed regardless of the cost.

D. RQ. 4: The Inﬂuence of Batch Size in Deep Learning?

The authors controlled the batch size parameters for deep
learning classiﬁers with multiple layers. According to our
observations: the smaller batch size is, the better/ﬁtter the
model will be. For instance, a neural network with two hidden
layers each with 10 and 1 neurons but with batch size of
100 and 5 achieved the accuracy of 98.73% and 98.88%,
respectively. The improvement seems to be very small. On the
other hand, training with smaller batch size appeared to take
more computation time and thus more expensive than training
a model with a larger batch size.
It was also observed that for deep learning-based approaches
with multiple layers: the larger and deeper the model is, the
better and ﬁtter the classiﬁcation will be. For instance, a model
with two layers each having 30 and 1 neurons and batch size
of 100 achieved the accuracy of 98.73%. Whereas, a deeper
model with seven layers each having 100, 80, 60, 40, 20, and
1 neurons and with the batch size equal to 100 achieved the
accuracy of 98.99%. However, the improvement is very small.

E. RQ. 5: The Inﬂuence of Epochs in Deep Learning?

The authors performed a systematic analysis on the inﬂu-
ence of the number of iterations needed to train the classiﬁers.
It was observed that: the greater the number of epochs is, the
more accurate the model will be. For instance, an MLP model

(100, 50, 1) with E pochs = 50 achieved 99.24% accuracy;

whereas, an increase of Epochs to 200 enhanced the accuracy
to 99.33%. This observation might indicate that a smaller
number of epochs might be sufﬁcient to learn the key and
signiﬁcant features of the data and thus by adding more rounds
of training stages, the model will not learn anything further
(i.e., all features are already learned). As an example, Figure
2 illustrates the improvement of accuracy over epochs for the

model M LP (100, 50, 1)[BatchS ize = 100][E poch = 200].

[3] Y. Ye, T. Li, D. Adjeroh, and S. S. Iyengar, “A survey on malware
detection using data mining techniques,” ACM Comput. Surv., vol. 50,
no. 3, pp. 41:1–41:40, Jun. 2017.
[4] K. Rieck, T. Holz, C. Willems, P. D ¨ussel, and P. Laskov, “Learning
and classiﬁcation of malware behavior,” in Conference on Detection of
Intrusions and Malware, and Vulnerability Assessment (DIMVA), 2008,
pp. 108–125.
[5] D. Gavrilu, M. Cimpoeu, and D. A. L. Ciortuz, “Malware detection
using machine learning,” in International Multi-conference on Computer
Science and Information Technology (IMCSIT), 2009.
[6] W. Hardy, L. Chen, S. Hou, Y. Ye, and X. Li, “Dl4md: A deep learning
framework for intelligent malwaredetection,” in Int’l Conf. Data Mining
(DMIN’16), 2016.
[7] S. Siami-Namini, N. Tavakoli, and A. S. Namin, “A comparison of
ARIMA and LSTM in forecasting time series,” in International Con-
ference on Machine Learning and Applications, ICMLA, Orlando, FL,
USA, 2018, pp. 1394–1401.
[8] N. Tavakoli, “Modeling genome data using bidirectional LSTM,” in
Annual Computer Software and Applications Conference, COMPSAC,
Milwaukee, WI, USA., 2019, pp. 183–188.
[9] M. Chatterjee and A. S. Namin, “Detecting phishing websites through
deep reinforcement learning,” in Annual Computer Software and Appli-
cations Conference, COMPSAC, WI, USA, 2019, pp. 227–232.
[10] L. Bilge and T. Dumitras, “Before we knew it: An empirical study of
zero-day attacks in the real world,” in ACM Conference on Computer
and Communications Security, 10 2012, pp. 833–844.
[11] M. G. Miller, “Are we protected yet? developing a machine learning de-
tection system to combat zero-day malware attacks,” Ph.D. dissertation,
2018.
[12] V. Sharma, J. Kim, S. Kwon, I. You, K. Lee, and K. Yim, “A framework
for mitigating zero-day attacks in IoT,” CoRR, vol. abs/1804.05549,
2018.
[13] M. Alazab, S. Venkatraman, P. Watters, and M. Alazab, “Zero-day
malware detection based on supervised learning algorithms of API call
signatures,” in Ninth Australasian Data Mining Conference - Volume
121, ser. AusDM ’11, 2011, pp. 171–182.
[14] P. M. Comar, L. Liu, S. Saha, P. Tan, and A. Nucci, “Combining
supervised and unsupervised learning for zero-day malware detection,”
in 2013 Proceedings IEEE INFOCOM, April 2013, pp. 2022–2030.
[15] Q. Zhou and D. Pezaros, “Evaluation of machine learning classiﬁers for
zero-day intrusion detection - an analysis on CIC-AWS-2018 dataset,”
CoRR, vol. abs/1905.03685, 2019.
[16] L. Xiao, X. Wan, X. Lu, Y. Zhang, and D. Wu, “Iot security techniques
based on machine learning: How do IoT devices use AI to enhance
security?” IEEE Signal Processing Magazine, vol. 35, no. 5, pp. 41–49,
Sep. 2018.
[17] “Malware detection - make your own malware security system, in asso-
ciation with meraz’18 malware security partner max secure software,”
https://www.kaggle.com/c/malware-detection, Accessed 2019.
[18] S. Kakarla, S. Momotaz, and A. S. Namin, “An evaluation of mutation
and data-ﬂow testing: A meta-analysis,” in International Conference on
Software Testing, Veriﬁcation and Validation, ICST, Berlin, Germany,
Workshop Proceedings, 2011, pp. 366–375.
[19] M. Chatterjee, A. S. Namin, and P. Datta, “Evidence fusion for malicious
bot detection in iot,” in International Conference on Big Data, WA, USA,
2018, pp. 4545–4548.
[20] S. Sartoli and A. S. Namin, “Adaptive reasoning in the presence of
imperfect security requirements,” in Annual Computer Software and
Applications Conference, COMPSAC, GA, USA, 2016, pp. 498–499.
[21] J. Zheng and A. S. Namin, “A markov decision process to determine
optimal policies in moving target,” in ACM SIGSAC Conference on
Computer and Communications Security, Toronto, ON, Canada, 2018,
pp. 2321–2323.

D. Deep or Deeper Classiﬁers?
According to our results, larger and deeper classiﬁers tend
to perform better and they build a more accurate model.
However, the improvement does not seem to be signiﬁcant.
A simpler deep learning classiﬁer (e.g., M LP (30, 1) with
batch size = 100 and accuracy of 98.73%) might perform
comparatively very similar to a deeper and larger classiﬁer

(e.g., M LP (100, 80, 60, 40, 20, .10, 1) with batch size = 100

and accuracy of 98.99%. Hence, the choice of the depth of
deep classiﬁers depends on the desired level of accuracy.

V I I I . CONC LU S ION S AND FU TUR E WORK

This paper empirically explored whether machine and deep
learning classiﬁers are effective in detecting zero-day malware.
Addressing such a question is important from security per-
spective because zero-day malware are unknown applications
and thus there might not be any malicious signature similar
to their patterns. We empirically compared a good number of
well-known conventional machine learning and deep learning
classiﬁers and observed that some of the conventional machine
learning algorithms (e.g., random forests) perform very well
in comparison with their deep learning-based counterparts.
This result implies that some of the conventional and deep
learning-based approaches are good classiﬁers for detecting
zero-day malware. However, even though they achieve very
high accuracy (e.g., 99.51%), these algorithms never achieve
a 100% accuracy and thus these classiﬁers might slightly
misclassify some of the zero-day malware.
This paper focused on measuring the accuracy of classiﬁers
using a 10-fold cross validation. It is important to carry out
additional experiments and measure precision, recall, accuracy,
and F1 measures all together along with the ROC measure
for these classiﬁers and capture the exact values for false
positive and false negative. It is also important to replicate
the experiments reported in this paper with some other datasets
and perform a meta analysis [18] to have a better insights about
the machine leaning algorithms and their classiﬁcation per-
formances. Furthermore, given the outstanding performance
of random forest, it would be interesting to observe whether
ensemble-based deep learning classiﬁers perform better than
other classiﬁers. It is also an interesting question to investigate
whether evidence theory [19], uncertainty reasoning [20], or
control-theoretical approaches and decision-based processes
[21] can be utilized in accordance with learning algorithms
to detect zero-day vulnerabilities.

ACKNOW LEDGM ENT

This work is supported in part by National Science Foun-
dation (NSF) under the grants 1821560 and 1723765.

R E FERENC E S

[1] “Yara - the pattern matching swiss knife for malware researchers,”
https://virustotal.github.io/yara/, Accessed 2019.
[2] L. Xie, X. Zhang, J.-P. Seifert, and S. Zhu, “pbmds: A behavior-based
malware detection system for cellphone devices,” in ACM Conference
on Wireless Network Security, ser. WiSec ’10, 2010, pp. 37–48.

