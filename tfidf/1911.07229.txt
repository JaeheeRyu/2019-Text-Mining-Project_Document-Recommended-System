Learning Query Inseparable ELH Ontologies

Ana Ozaki, Cosimo Persia, Andrea Mazzullo

KRDB Research Centre, Free University of Bozen-Bolzano

9
1
0
2

v
o

N

1
2

]
I

A

.

s

c

[

2
v
9
2
2
7
0

.

1
1
9
1

:

v

i

X

r

a

Abstract

We investigate the complexity of learning query insepara-
ble ELH ontologies in a variant of Angluin’s exact learning
model. Given a ﬁxed data instance A∗ and a query language
Q, we are interested in computing an ontology H that entails
the same queries as a target ontology T on A∗ , that is, H and
T are inseparable w.r.t. A∗ and Q. The learner is allowed to
pose two kinds of questions. The ﬁrst is ‘Does (T , A) |= q?’,
with A an arbitrary data instance and q and query in Q. An
oracle replies this question with ‘yes’ or ‘no’. In the second,
the learner asks ‘Are H and T inseparable w.r.t. A∗ and Q?’.
If so, the learning process ﬁnishes, otherwise, the learner re-
ceives (A∗ , q) with q ∈ Q, (T , A∗ ) |= q and (H, A∗ ) 6|= q
(or vice-versa). Then, we analyse conditions in which query
inseparability is preserved if A∗ changes. Finally, we con-
sider the PAC learning model and a setting where the algo-
rithms learn from a batch of classiﬁed data, limiting interac-
tions with the oracles.

Introduction

Ontologies are a formal and popular way of representing
knowledge. Taxonomies, categorisation of websites, prod-
ucts and their features, as well as more complex and spe-
cialized domain knowledge, can be represented with on-
tologies. Domain experts use ontologies while sharing and
annotating information in their ﬁelds because in this way
knowledge can be unambiguously understood and easily dis-
tributed. Medicine, for example, has produced large, stan-
dardised, and scalable ontologies (e.g. Galen and SNOMED
CT). Broad and general so called knowledge graphs are
emerging such as DBPedia (Bizer et al. 2009), Wiki-
data (Vrande ˇci ´c and Kr ¨otzsch 2014), YAGO (Suchanek,
Kasneci, and Weikum 2008). An ontology enables machines
to process relations and deﬁnitions and reason about that
knowledge. Sharing information, formalising a domain, and
making assumptions explicit are some of the main reasons
for using an ontology.
Designing ontologies is a hard and error-prone task. The
research community has approached the problem by devel-
oping editors that help ontology engineers to build ontolo-
gies manually (Knublauch et al. 2004) and deﬁned design
principles (Stuckenschmidt, Parent, and Spaccapietra 2009).

Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

Even with tools, building ontologies is a laborious task that
also needs expertise. An expert in designing ontologies is
called an ontology engineer. Such an expert is normally fa-
miliar with the tools, languages, and techniques necessary
to design an ontology through the communication with do-
main experts. The ontology engineer must communicate and
understand the knowledge given by domain experts and then
design an ontology that captures what is relevant in the do-
main.
One of the main challenges in the process of building
an ontology is that it often relies on the communication
between the ontology engineer (or multiple ontology engi-
neers) and domain experts that, in order to share knowledge,
use the ambiguous natural language. Indeed, it can happen
that some errors are made while designing it due to the dif-
ﬁculty of sharing knowledge. The ontology engineer can
misunderstand the domain experts or they can inadvertently
omit precious details. Moreover, knowledge can be implicit
and while designing an ontology it is not easy to understand
what are the real relationships between concepts and imag-
ine all the possible consequences of designing concepts and
their relationships in a particular way. There are several as-
pects which can inﬂuence the difﬁculty of creating an ontol-
ogy.
Following the approach by (Konev et al. 2018; Konev,
Ozaki, and Wolter 2016), we focus on the problem of ﬁnding
how concepts should be logically related, assuming that the
relevant vocabulary is known by the domain experts, which
can share this information with the ontology engineer. In this
approach, the problem of building an ontology is treated as
a learning problem in which the ontology engineer plays the
role of a learner and communicates with the domain experts,
who play the role of a teacher (also called an oracle). We
assume that (1) the domain experts know the relevant knowl-
edge about the domain and act in a consistent way as a single
teacher; (2) the vocabulary that should be used in the ontol-
ogy is known by the teacher and the learner; (3) the learner
can pose queries to the teacher in order to acquire missing
knowledge or check if it has learned enough in order to stop
learning. The described model can be seen as an instance of
Angluin’s exact learning model (Angluin 1988) with mem-
bership and equivalence queries. The queries asked by the
learner in order to acquire knowledge can be considered as
membership queries and the queries that ask if the hypothe-

 
 
 
 
 
 
p

e

s

E

v

i

u
q

Framework
. AQ
IQ
CQr
CQ
. AQ
IQ
CQr
CQ
AQ
IQ
CQr
CQ

C

A

P

n

I

EL(H)lhs

✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓
✓

EL(H)rhs
–

EL(H)
–

✓
✓
✗
✓
✓
✓
✗
✓
✓
✓
✓

✗

?

✗
✓
✓
✓
✗
✓
✓
✓
✓

Table 1: Polynomial query learnability of learning frameworks.

sis of the learner correctly represents the relevant knowledge
of the domain experts can be treated as equivalence queries.
In the exact learning literature, one of the main goals is
to determine the complexity of learning an abstract target.
The complexity depends on the number and size of queries
posed by the learner. In the work by (Konev et al. 2018;
Konev, Ozaki, and Wolter 2016) it has been shown that ex-
actly learnability of ontologies formulated in the very popu-
lar ELH (Baader et al. 2007a) ontology language is not possi-
ble with polynomially many polynomial size queries. Here,
we investigate a more ﬂexible setting, where the ontology
does not need to be logically equivalent but only inseparable
w.r.t. a query language (Lutz and Wolter 2010) and a ﬁxed
data instance1 . Query inseparability is the basic require-
ment for ontology mediated query answering (OMQA) (Bi-
envenu 2016). In OMQA, relevant tasks such as ontology
versioning, modularisation, update, and forgetting, depend
on comparisons between ontologies based on answers given
to queries (Botoeva et al. 2019). We study polynomial query
and time learnability of the ELH ontology language in the
OMQA setting. The query languages considered are atomic
queries (AQ), instance queries (IQ), conjunctive queries
(CQ) and a fragment of CQs called rooted CQs (denoted
CQr ). In particular, we show that in our setting the picture
is brighter and ELH can be polynomially learned from IQs,
however, it is still not possible to learn this language from
CQs.
Table 1 shows the different results obtained by previous
works (Konev et al. 2018; Konev, Ozaki, and Wolter 2016)
for logical equivalence and our results (shaded in gray) for
query inseparability, taking into account the ontology (upper
side) and the query languages (left side). ✓ means a posi-
tive result, i.e. polynomial query learnability; − means that
the query language is not expressive enough for exchang-
ing information and ✗ means that polynomial query learn-
ability cannot be achieved. Polynomial time learnability im-
plies polynomial query learnability but the converse does not
hold. All positive results for AQs, IQs, and CQr s also hold
for polynomial time learnability. Since the learned ontology

1Here the term ‘query’ refers to queries in the context of
databases and query answering. Our data instances are ABoxes.

is not equivalent to the target, it may be the case that af-
ter the data is updated the learned ontology and the target
are no longer query inseparable. We thus investigate condi-
tions under which query inseparability is preserved when the
data changes, which means that no further learning steps are
needed after the change. In many applicaton scenarios, inter-
actions with teachers may not be a viable option. We also
consider learnability when the learner has only access to a
batch of classiﬁed examples. Finally, we adapt the Proba-
bly Approximately Correct (PAC) model (Valiant 1984) to
our OMQA setting, which we separate from the exact and
query inseparable problem settings (Theorem 15). Our poly-
nomial time results for query inseparability are transferable
to the PAC model extended with membership queries (Theo-
rem 14). Omitted proofs are available in the appendix.

Related Work. To cover the vast literature on ontology
learning, we point to the collection edited by (Lehmann and
V ¨olker 2014) and surveys authored by (Cimiano, V ¨olker,
and Buitelaar 2010) and (Wong, Liu, and Bennamoun 2012).
The closest works are the already mentioned papers on ex-
act learning of lightweight description logics (DLs) (Konev
et al. 2018; Duarte, Konev, and Ozaki 2018; Konev, Ozaki,
and Wolter 2016). Exact learning of concepts formulated
in the DL CLASSIC has been investigated by (Cohen and
Hirsh 1994) and (Frazier and Pitt 1996). Some other works
which are more closely related include works on learn-
ing EL concepts (Funk et al. 2019; Lehmann and Haase
2009). Formal Concept Analysis has been applied for learn-
ing DL ontologies (Rudolph 2004; Baader et al. 2007b;
Borchmann and Distel 2011; Borchmann 2014; Ganter et
al. 2016). Learnability of EL ontologies from ﬁnite interpre-
tations has also been investigated (Klarman and Britz 2015).
Association rule mining has been used to learn DL ontolo-
gies (with concept expressions of limited depth) (Sazonau
and Sattler 2017; V ¨olker and Niepert 2011; Fleischhacker,
V ¨olker, and Stuckenschmidt 2012; V ¨olker, Fleischhacker,
and Stuckenschmidt 2015).

Basic Deﬁnitions

Ontologies and Queries. The ELH syntax is deﬁned upon
mutually disjoint countably inﬁnite sets of concept names
NC , denoted with A, B , role names NR , denoted with r, s,
and individual names NI , denoted with a, b. EL-concept ex-
pressions C are deﬁned inductively according to the rule

C ::= A | ⊤ | C ⊓ C | ∃r.C , where A ∈ NC and r ∈ NR .

For simplicity, we omit EL- from EL-concept expressions.
An ELH ontology, also called TBox, is a ﬁnite set of concept
inclusions (CI) C ⊑ D , where C, D are concept expressions,
and role inclusions (RI) r ⊑ s, where r, s ∈ NR . We call an
ELH TBox T a terminology if for all C ⊑ D ∈ T either C
or D is a concept name2 and T has at most one3 inclusion of

2 In the literature, the term terminology commonly refers to sets
of concept inclusions A ⊑ C and concept deﬁnitions A ≡ C , with
no concept name occurring more than once on the left. As A ≡ C
can be equivalently rewritten as A ⊑ C and C ⊑ A, our deﬁnition
is a natural extension of this one.
3 If a terminology contains A ⊑ C and A ⊑ D one can always
rewrite it into A ⊑ C ⊓ D.

the form A ⊑ C for every A ∈ NC . From now on we assume
all ELH TBoxes we deal with are terminologies. An ABox
A is a ﬁnite set of expressions of the form A(a) or r(a, b),
called assertions, with A ∈ NC , r ∈ NR and a, b ∈ NI . We
denote by ind(A) the set of individual names occurring in
an ABox A. The signature ΣT of a TBox T is the set of
concept and role names occurring in it, and similarly for the
signature ΣA of an ABox A. A knowledge base (KB) is a
pair (T ,A) where T is a TBox and A is an ABox. We inves-
tigate classical query languages considered in the OMQA
literature. An AQ takes the form of an assertion. An IQ is
of the form C (a) or r(a, b), where C is a concept expres-
sion, r ∈ NR and a, b ∈ NI . A CQ is a ﬁrst-order sentence
∃~xϕ(~a, ~x), where ϕ is a conjunction of atoms of the form
r(t1 , t2 ) or A(t), where t1 , t2 , t (called terms) can be indi-
vidual names from ~a or individual variables from ~x. With an
abuse of notation, we denote by AQ, IQ and CQ the sets of
atomic, instance and conjunctive queries q , respectively, and
we call a query language a set Q ∈ {AQ, IQ, CQ}. The size
of a concept expression C (TBox T , ABox A, query q ), de-
noted by |C | (and, respectively, |T |, |A|, |q |) is the length of
the string that represents it, where concept, role, and individ-
ual names are considered to be of length one.
The semantics of ELH is given as follows. An interpre-
tation is a pair I = (∆I , ·I ), where ∆I is a non-empty set,
called domain, and ·I is a function that maps every a ∈ NI to
aI ∈ ∆I , every A ∈ NC to AI ⊆ ∆I and every r ∈ NR to
rI ⊆ ∆I × ∆I . The function ·I extends to other concept ex-
pressions as follows: ⊤I = ∆I , (C ⊓ D)I := C I

computation) of computation the time used by A up to that
step is bounded by a polynomial p(|t|, |e|), where t ∈ L is
the target and e ∈ S is the largest counterexample seen so far.
We denote by PQUERYL and PT IMEL the class of learning
frameworks which are, respectively, polynomial query and
polynomial time learnable. Clearly, PT IMEL ⊆ PQUERYL .
We now introduce the special case of learning frameworks
which we focus in this work, called OMQA learning frame-
works. Let L, A∗ , and Q be, respectively, an ontology lan-
guage, a ﬁxed but arbitrary ABox, and a query language. An
OMQA learning framework F(L, A∗ , Q) is a learning frame-
work (E , S , L, µ) where E is the set of all pairs (A, q) with
A an ABox (may be different from A∗ ) and q ∈ Q; L is the
set of all TBoxes formulated in L sharing a common ﬁnite
signature (we write ΣT to refer to the signature of the target,
which is assumed to be same as the one used for the hypoth-
esis); S is the set of elements (A, q) of E where A = A∗ ;

and, for all T ∈ L, µ(T ) = {(A, q) ∈ E | (T , A) |= q}.

We assume that the signature of q , i.e., the set of concept
and role names occurring in q , is ΣT ∪ ΣA . Moreover, we
deﬁne the size of an example (A, q), denoted by |(A, q)|, as
the sum of the size of A and q . Given an OMQA learning

framework F(L, A∗ , Q) = (E , S , L, µ), for all H, T ∈ L,
if µ(H)

of the form C ⊑ A which ensure AQ-inseparability w.r.t.
A∗ can be learned with membership queries. It remains to
show how one can learn CIs of the form A ⊑ C , so that
H is IQ-inseparable from T (w.r.t. A∗ ). By Theorem 4, we
can assume that one can construct a hypothesis H such that
T |= H, since there is a positive bounded learning algorithm.
The next lemma states that if T |= H and (H, A∗ ) ≡AQ
(T , A∗ ) then one can transform a counterexample of the
form (A∗ , D(a)) into a CI such that T |= A ⊑ C , and
H 6|= A ⊑ C , with C a subconcept of D and A ∈ ΣT such
that (H, A∗ ) |= A(b) for some b ∈ NI . Since |ΣT | is poly-
nomial in |T | and the number of subconcepts of D is also
polynomial in |D |. One can ﬁnd such A ⊑ C in polynomial
time w.r.t. |T | and |(A∗ , D(a))|.
Lemma 5. Let T and H be ELH terminologies and
let A∗ be an ABox. Assume (H, A∗ ) ≡AQ (T , A∗ ). If

(A∗ , D(a)) ∈ µ(T ) \ µ(H) then there is A(b) and a sub-

concept C of D such that (H, A∗ ) |= A(b), T |= A ⊑ C ,

and H 6|= A ⊑ C .

Given A ⊑ C such that T |= A ⊑ C , and H 6|= A ⊑ C ,
one can compute with polynomially many polynomial size
queries another CI A′ ⊑ C ′ entailed by T but not by H
belonging to a class of CIs called T -essential (Konev et al.
2018, Lemma 29). In fact this can be done in polynomial
time given the complexity of entailment checking (Baader,
Lutz, and Brandt 2008) (no inverse roles). Such T -essential
CIs have the property that their size is bounded polynomi-
ally in the size of T (Konev et al. 2018, Lemma 32) and if
α1 = A′ ⊑ C1 and α2 = A′ ⊑ C2 are T -essential and not
equivalent then one can compute in polynomial time a T -
essential CI A′ ⊑ C ′ such that it entails α1 and α2 (Konev
et al. 2018, Lemma 30). All in all, if the learner computes
such T -essential counterexamples and adds/reﬁnes them in
the hypothesis (see (Konev et al. 2018, Algorithm 2)) then,
after learning from polynomially many counterexamples, it
will terminate and output a hypothesis IQ-inseparable from
the target (w.r.t. A∗ ). The presence of CIs of the form C ⊑ A
does not affect this result (Duarte, Konev, and Ozaki 2018).

Theorem 6. F(ELH, A∗ , IQ) is in PT IMEL .
In contrast, the learning framework F(ELH, IQ) is not in
PQUERYL (Konev, Ozaki, and Wolter 2016). We observe
that the counterexamples used in such hardness proof are
based on an exponential number of ABoxes encoding con-
cept expressions of the form Cb = ⊓i≤nCi , where b =
b1 . . . bn is a sequence with bi ∈ {0, 1}, Ci = Ai if bi = 1,
and Ci = Bi if bi = 0. In the OMQA setting, the ABox is
ﬁxed and, as stated in Theorem 6, this lowers the complexity.

Learning ELH ontologies with CQ. ELH ontologies are not
polynomial query learnable in the data retrieval setting with
CQs as the query language (in fact not even the fragment
ELHrhs ) (Konev, Ozaki, and Wolter 2016). The counterex-
amples used by the oracle in the hardness proof are of the
form ({A(a)}, q) (Konev, Ozaki, and Wolter 2016, proof of
Lemma 8), so {A(a)} can be considered as the ﬁxed ABox
given as part of the input in an OMQA learning framework.
Thus, the mentioned hardness result can be transferred to our
setting. We formalise this result with the next theorem.

a

r

r

x1

x2

x3
x4
x5

s
s
s
s

→

r

s

x3

x1

a

Figure 1: Assume T = {A ⊑ ∃r.∃s.⊤}, A∗ = {A(a)}

and H = ∅. A call to EQF,T can output (A∗ , ∃~x(r(a, x1 ) ∧

r(a, x2 ) ∧ s(x1 , x3 ) ∧ s(x1 , x4 ) ∧ s(x2 , x4 ) ∧ s(x2 , x5 )),

which can be converted into (A∗ , ∃r.∃s.⊤(a)) by merging
variables and asking MQF,T whether the new query holds.

Theorem 7. F(ELH, A∗ , CQ) is not in PQUERYL .
The hardness proof in the mentioned paper uses a very
simple CQ of the form ∃xM (x), which has a match in the
anonymous part of the model but ‘hides’ the concept on the
right side of a CI that causes the entailment of this query.
This phenomenon makes one wonder whether restricting to
the class of queries in which every variable needs to be reach-
able by an individual name (as it happens with IQs) can tame
the complexity of the problem. Our next theorem proves this.
Given a CQ q , we deﬁne Gq as the directed graph (V , E )
where the nodes V are the terms of q and the edges E are the
pairs (t1 , t2 ) such that there is an atom of the form r(t1 , t2 )
in q . We say that a CQ q = ∃~xϕ(~a, ~x) is rooted if for every x
in ~x, we have that x is reachable from a node in Gq that is in
~a. We denote by CQr the class of all rooted CQs. The next
lemma establishes that one can transform queries in CQr
into queries in IQ (by posing membership queries).
Lemma 8. Let T and H be ELH TBoxes and assume T
and H entail the same RIs. Given a positive counterexample
(A∗ , q) (for T and H), with q ∈ CQr , one can contruct a
positive counterexample (A∗ , q ′ ) with q ′ ∈ IQ in polynomial

time in |(A∗ , q)||ΣT |.

In Figure 1, it is shown an example of this conversion.
Even though the conversion involves deciding query answer-
ing, which is NP-hard, these checks are on the ‘side’ of the
oracle, and so, they do not affect the complexity of learn-
ing. By Lemma 8 a IQ-inseparable hypothesis can be found
by following the same steps of a learning algorithm for IQ
after q in (A∗ , q) is converted into an instance query. For
ELH, if TBoxes entail the same RIs then IQ-inseparability
implies CQr -inseparability. Since RIs can be easily learned
with membership queries, we obtain our next theorem.
Theorem 9. F(ELH, A∗ , CQr ) is in PT IMEL .

Data Updates

The algorithm presented in the previous section for IQs
computes an ontology H that is IQ-inseparable from the
target T w.r.t. a ﬁxed ABox A∗ . In this section, we
ﬁrst study when IQ-inseparability is preserved, without
changes to the hypothesis H,
if A∗ is updated to an
ABox A. Then, given an OMQA learning framework
F(ELH, A∗ , IQ) = (E , S , L, µ), we determine conditions
on an updated ABox A, sufﬁcient to guarantee that a learn-
ing framework (E , S ′ , L, µ) with S ′ ⊇ S is still in PT IMEL .
To characterise when IQ-inseparability is preserved if A∗
is updated to an ABox A, we use the classical notion of

bisimulation. Let I = (∆I , ·I ), J = (∆J , ·J ) be two in-
terpretations. A bisimulation is a non-empty relation Z ⊆
∆I ×∆J satisfying the following conditions, for all (d, e) ∈
Z : (1) for all concept names A ∈ NC , d ∈ AI iff e ∈ AJ ;
(2) for all role names r ∈ NR , if (d, d′ ) ∈ rI , d′ ∈ ∆I , then
there exists e′ ∈ ∆J such that (e, e′) ∈ rJ and (d′ , e′ ) ∈ Z ;
(3) for all role names r ∈ NR , if (e, e′ ) ∈ rJ , e′ ∈ ∆J , then
there exists d′ ∈ ∆I such that (d, d′ ) ∈ rI and (d′ , e′) ∈ Z .

If (d, e) ∈ Z , we write (I , d) ∼ (J , e).

Theorem 10. Let T and H be ELH terminologies entailing
the same RIs, and let A∗ and A be ABoxes. If, for all b ∈
ind(A), there is a ∈ ind(A∗ ) such that (IA∗ , a) ∼ (IA , b),

then (H, A∗ ) ≡IQ (T , A∗ ) implies (H, A) ≡IQ (T , A).

Theorem 10 does not hold if we require the ABoxes A∗
and A to be homomorphically equivalent, i.e., if there are
ABox homomorphisms from A∗ to A and from A to A∗ .
Example 11. Consider T = {∃r.A1 ⊑ B} and A∗ =

{r(a, b), A1 (b), A2 (b)}. The hypothesis H = {∃r.(A1 ⊓

A2 ) ⊑ B} is IQ-inseparable. However, if A = A∗ ∪
{r(a′ , b′ ), A1 (b′ )}, then IQ-inseparability is not preserved,
even though A∗ and A are homomorphically equivalent. ⊳
The problem here is that the left-hand side of CIs in
H could be biased and too speciﬁc for the individuals in
A∗ . Indeed, in Example 11, if the more general concept ex-
pression ∃r.A1 on the left-side had been learned, then IQ-
inseparability would have been preserved after the update. If
we allow for modiﬁcations to the learned hypothesis H, we
can extend the class of updated ABoxes A not only to those
in which every individual in A is bisimilar to an individual
in A∗ but in which a more relaxed condition is required. It
is easy for the learner to make certain kinds of generalisa-
tion, for instance, check whether T |= ∃r.A1 ⊑ B and add
such more general CI to H. Therefore, the idea is to suit-
ably ‘generalise’ the left-hand side of CIs in the hypothesis
H computed by the learning algorithm.
Generalisation of C ⊑ A ∈ H for T consists of replacing
C by the result C ′ of (1) replacing a concept name B in C
with ⊤ or B ′ such that T |= B ⊑ B ′ and T 6|= B ′ ⊑ B if
T |= C ′ ⊑ A; or (2) replacing a role name r in C with s

such that T |= r ⊑ s and T 6|= s ⊑ r if T |= C ′ ⊑ A. We

say that C ⊑ A ∈ H is generalised for T if generalization
of C ⊑ A ∈ H for T has been exhaustively applied. H is
generalised for T if all the CIs in it are generalised. We may
omit ‘for T ’ if this is clear from the context.
With the following deﬁnitions, we deﬁne a class of
ABoxes that are guaranteed to preserve IQ-inseparability if
the hypothesis is generalised. Given a TBox T and concept
names A, B ∈ ΣT

PAC learning. Let F = (E , S , L, µ) be a learning frame-
work. A probability distribution D on S is a function

D : 2S → [0, 1] ⊂ R such that D(Si∈I Xi ) = Pi∈I D(Xi )

for mutually disjoint Xi , where I is a countable set of in-
dices, Xi ⊆ S , and D(S ) = 1. Given a target t ∈ L, let
EXD
F,t be the oracle that takes no input, and outputs a classi-
ﬁed example (e, ℓt(e)), where e ∈ S is sampled according
to the probability distribution D, ℓt(e) = 1, if e ∈ µ(t)

on the complexity of learning ontologies formulated in more
expressive languages. We leave the problem of exactly learn-
ing ELH TBoxes with CQr s as an open problem. Learning
with a more expressive query language is not easier because
the oracle can formulate counterexamples which are not in-
formative. Neither it is more difﬁcult because on the other
hand, with a more expressive language, the learner can pose
more informative membership queries. It would also be inter-
esting to investigate a similar data model in which the ABox
is ﬁxed for all the examples, so that the data pool contains
examples in the form of queries alone.

Acknowledgments

This research has been supported by the Free University of
Bozen-Bolzano through the projects PACO and MLEARN.

References

Angluin, D. 1988. Queries and concept learning. Machine
Learning 2(4):319–342.

Arias, M., and Khardon, R. 2006. Complexity parameters for
ﬁrst order classes. Machine Learning 64(1-3):121–144.

Arias, M.; Khardon, R.; and Maloberti, J. 2007. Learning horn
expressions with LOGAN-H. Machine Learning Research
8:549–587.

Arias, M. 2004. Exact learning of ﬁrst-order expressions from
queries. Ph.D. Dissertation, Citeseer.

Baader, F.; Calvanese, D.; McGuinness, D.; Nardi, D.; and
Patel-Schneider, P., eds. 2007a. The Description Logic Hand-
book: Theory, Implementation, and Applications. Cambridge
University Press, second edition.

Baader, F.; Ganter, B.; Sertkaya, B.; and Sattler, U. 2007b.
Completing description logic knowledge bases using formal
concept analysis. In IJCAI, 230–235.

Baader, F.; Lutz, C.; and Brandt, S. 2008. Pushing the EL
envelope further. In OWLED.

Bienvenu, M. 2016. Ontology-mediated query answering: Har-
nessing knowledge to get more from data.
In IJCAI, 4058–
4061.

Bizer, C.; Lehmann, J.; Kobilarov, G.; Auer, S.; Becker, C.; Cy-
ganiak, R.; and Hellmann, S. 2009. DBpedia – A crystalliza-
tion point for the Web of Data. Web Semantics 7(3):154–165.

Blum, A. L. 1994. Separating distribution-free and mistake-
bound learning models over the boolean domain. SIAM J. Com-
put. 23(5):990–1000.
Borchmann, D., and Distel, F. 2011. Mining of E L-GCIs. In
ICDM Workshops, 1083–1090.

Borchmann, D. 2014. Learning terminological knowledge
with high conﬁdence from erroneous data. Ph.D. Dissertation,
Higher School of Economics.

Botoeva, E.; Lutz, C.; Ryzhikov, V.; Wolter, F.; and Za-
kharyaschev, M. 2019. Query inseparability for ALC ontolo-
gies. Artif. Intell. 272:1–51.

Cimiano, P.; V ¨olker, J.; and Buitelaar, P. 2010. Ontology con-
struction. In Handbook of Natural Language Processing, Sec-
ond Edition. Chapman and Hall/CRC. 577–604.

Cohen, W. W., and Hirsh, H. 1994. Learning the CLASSIC
description logic: Theoretical and experimental results. In KR,
121–133.

Duarte, M. R. C.; Konev, B.; and Ozaki, A.
2018. Ex-
actLearner: A tool for exact learning of E L ontologies. In KR,
409–414.

Fleischhacker, D.; V ¨olker, J.; and Stuckenschmidt, H. 2012.
Mining RDF data for property axioms.
In On the Move to
Meaningful Internet Systems: OTM 2012. Springer. 718–735.

Frazier, M., and Pitt, L. 1996. Classic learning. Machine
Learning 25(2-3):151–193.

Funk, M.; Jung, J. C.; Lutz, C.; Pulcini, H.; and Wolter, F. 2019.
Learning description logic concepts: When can positive and
negative examples be separated? In IJCAI, 1682–1688.

Ganter, B.; Obiedkov, S. A.; Rudolph, S.; and Stumme, G.
2016. Conceptual exploration. Springer.

Hell, P., and Neˇsetˇril, J. 1990. On the complexity of h-coloring.
J. Comb. Theory Ser. B 48(1):92–110.

Klarman, S., and Britz, K. 2015. Ontology learning from inter-
pretations in lightweight description logics. In ILP, 76–90.

Knublauch, H.; Fergerson, R. W.; Noy, N. F.; and Musen, M. A.
2004. The Prot ´eg ´e OWL plugin: An open development envi-
ronment for semantic web applications. 229–243. Springer.

Konev, B.; Lutz, C.; Ozaki, A.; and Wolter, F. 2018. Exact
Learning of Lightweight Description Logic Ontologies. Ma-
chine Learning Research 18(201):1–63.

Konev, B.; Ozaki, A.; and Wolter, F. 2016. A model for learn-
ing description logic ontologies based on exact learning.
In
AAAI, 1008–1015.

Lehmann, J., and Haase, C. 2009. Ideal Downward Reﬁnement
in the E L Description Logic. In ILP, 73–87.
Lehmann, J., and V ¨olker, J. 2014. Perspectives on Ontology
Learning, volume 18. IOS Press.

Lutz, C., and Wolter, F. 2010. Deciding inseparability and
conservative extensions in the description logic EL. J. Symb.
Comput. 45(2):194–228.

Mohri, M.; Rostamizadeh, A.; and Talwalkar, A. 2012. Foun-
dations of Machine Learning. Adaptive computation and ma-
chine learning. MIT Press.

Rudolph, S. 2004. Exploring relational structures via FLE.
In International Conference on Conceptual Structures, ICCS,
196–212.

Sazonau, V., and Sattler, U. 2017. Mining hypotheses from
data in OWL: advanced evaluation and complete construction.
In ISWC, 577–593.

Stuckenschmidt, H.; Parent, C.; and Spaccapietra, S., eds.
2009. Modular Ontologies: Concepts, Theories and Tech-
niques for Knowledge Modularization, volume 5445 of Lecture
Notes in Computer Science. Springer.

Suchanek, F. M.; Kasneci, G.; and Weikum, G. 2008. YAGO:
A large ontology from Wikipedia and WordNet. Web Semantics
6(3):203–217.

Valiant, L. G. 1984. A theory of the learnable. Commun. ACM
27(11):1134–1142.

Vapnik, V. N. 1995. The Nature of Statistical Learning Theory.
Springer-Verlag.

V ¨olker, J., and Niepert, M. 2011. Statistical schema induction.
In The Semantic Web: Research and Applications. Springer.
124–138.

V ¨olker, J.; Fleischhacker, D.; and Stuckenschmidt, H. 2015.
Automatic acquisition of class disjointness. Web Semantics
35:124–139.

Vrande ˇci ´c, D., and Kr ¨otzsch, M. 2014. Wikidata: A Free Col-
laborative Knowledgebase. Commun. ACM 57(10).

Wong, W.; Liu, W.; and Bennamoun, M. 2012. Ontology
Learning from Text: A Look Back and into the Future. ACM
Computing Surveys 44(4):20:1–20:36.

Proofs for Section “Polynomial Learnability”

We introduce some basic deﬁnitions and lemmas that will be
used in our proofs. We are going to use the deﬁnition of the tree
interpretation of a concept, the notion of a canonical model, of
a homomorphism, and of a simulation.

Deﬁnition 18 (Canonical model of an ABox). The canonical
model IA = (∆IA , ·IA ) of an ABox A is deﬁned as follows:

• ∆IA = ind(A);

• aI = a for all individuals a ∈ ind(A);

• AIA = {a | A(a) ∈ A};
• rIA = {(a, b) | r(a, b) ∈ A}.

A path in a ELH concept expression C is a ﬁnite sequence
of the form C0 · r0 · C1 · r1 · · · rn · Cn where Ci is a con-
cept expression, ri is a role name, C0 = C , and, for all
i ∈ {0, . . . , n − 1}, the concept expression ∃ri+1 .Ci+1 is a
top-level conjunct of Ci . The set paths(C ) contains all paths in
C . The set tail(p) = {A | A ∈ NC is a top-level conjunct of
Ck where Ck is the last concept expression in p}.
Deﬁnition 19 (Tree interpretation). Let C be an ELH concept
expression. The tree interpretation IC = (∆IC , ·IC ) of a con-
cept C is deﬁned as follows:

• ∆IC = paths(C );

• AIC = {p ∈ paths(C ) | A ∈ tail(C )};

• rIC = {p ∈ paths(C ) × paths(C ) | there exists p′ =

p · r · D and p, p′ ∈ ∆IC for some concept expression D}.
We may denote the root path C of IC with ρC .
Deﬁnition 20 (Canonical model of a KB). The canonical
model IT ,A of an ELH KB (T , A) is deﬁned inductively. For
each r ∈ NR , I0 is deﬁned by extending the canonical model
IA of an ABox A with

rI0 = {(a, b) | s(a, b) ∈ A and T |= s ⊑ r}.

Assume that Ii has been deﬁned. We deﬁne Ii+1 as follows. If
there exist C ⊑ D ∈ T such that p ∈ ∆Ii , p ∈ C Ii , p 6∈ DIi
and D = d1≤j≤l Aj ⊓ d1≤j ′ ≤l′ ∃sj ′ .Dj ′ , we create Ii+1 in
the following way:

• ∆Ii+1 = ∆Ii ∪ {p · sj ′ · q | q ∈ paths(Dj ′ ), 1 ≤ j ′ ≤ l ′};

• AIi+1 = AIi ∪

{p · sj ′ · q | q ∈ paths(Dj ′ ), A ∈ tail(q), 1 ≤ j ′ ≤ l ′} ∪
{p | Aj = A, 1 ≤ j ≤ l};

• rIi+1 = rIi ∪

{(p · sj ′ · q), (p · sj ′ · q ′ ) | (q , q ′ ) ∈ sID
j′ , T |= s ⊑ r, 1 ≤
j ′ ≤ l ′} ∪
{(p, p · sj ′ · Dj ′ ) | T |= sj ′ ⊑ r, 1 ≤ j ′ ≤ l ′}.

Deﬁnition 22 (Simulation). Let I = (∆I , ·I ), J =
(∆J , ·J ) be two interpretations. A simulation S is a non-empty
relation S ⊆ ∆I × ∆J satisfying the following properties:
• for all concept names A ∈ NC and all (d, e) ∈ S it holds
that if
d ∈ AI then e ∈ AJ .
• for all role names r ∈ NR , if (d, e) ∈ S and (d, d1 ) ∈
rI , d1 ∈ ∆I then there exists e1 ∈ ∆J such that (e, e1 ) ∈

rJ and (d1 , e1 ) ∈ S .

If I and J are tree interpretations, we write I ⇒ J if there is
a simulation S ⊆ ∆I × ∆J containing the pair with the roots
of I and J .

The following standard lemmas are going to be used
throughout the remaining of this section in order to show prop-
erties of the algorithms.
Lemma 23. If (I1 , d1 ) ∼ (I2 , d2 ), then the following holds
for all ELH concept expressions C : d1 ∈ C I1 iff d2 ∈ C I2 .
Moreover, given an arbitrary TBox T and ABoxes A1 and A2 ,
(IA1 , d1 ) ∼ (IA2 , d2 ) implies that, for all ELH concept ex-
pressions C : d1 ∈ C IT ,A1 iff d2 ∈ C IT ,A2 .
Lemma 24. Let C be an ELH concept expression and let I be
an interpretation with d ∈ ∆I . Then, d ∈ C I if, and only if,
there is a homomorphism h : TC → I such that h(ρC ) = d.
Lemma 25. Let C be an ELH concept expression, T a TBox
and A an ABox. The following statements are equivalent:

1. T |= C ⊑ D;

2. ρC ∈ DIT ,C ;
3. There is a homomorphism h : TD → IT ,C such that

h(ρD ) = ρC .

Learning ELH ontologies with AQ

We now present
in full detail a learning algorithm for
F(ELH, A∗ , AQ). Our algorithm is based on the approach
used to learn a fragment of ELH where complex concept ex-
pressions are only allowed on the left side of inclusions (Konev,
Ozaki, and Wolter 2016). Algorithm 1 shows the steps that the
learner should do to learn an AQ-inseparable TBox. It ﬁrst com-
putes an initial part of the hypothesis H which consists of all
RIs and all CIs with concept names on both sides entailed by
the target ontology T . This initial H is constructed by asking
O(|ΣT |2 ) membership queries. More precisely, in this phase
the learner calls MQF(ELH,A∗ ,AQ),T with ({A(a)}, B (a)) as
input, for all A, B ∈ ΣT

Finally, the canonical model of a KB (T , A) is IT ,A =

S∞

i=0 Ii .

Deﬁnition 21 (Homomorphism). Let I be an interpretation
and let TC = (VC , EC , lC ) be the tree representation of con-
cept expression C . A homomorphism h : TC → I is a function
from VC to ∆I such that
• for all ν ∈ VC and A ∈ NC , if A ∈ lC (ν ) then h(ν ) ∈
AI ;
• for all ν1 , ν2 ∈ VC and r ∈ NR , if lC (ν1 , ν2 ) = r then

(h(ν1 ), h(ν2 )) ∈ rI .

Algorithm 1: ELH AQ learning algorithm
Input: Signature ΣT
Output: Hypothesis H

1 H = {A ⊑ B | T |= A ⊑ B , A, B ∈ ΣT } ∪ {r ⊑ s |
T |= r ⊑ s, r, s ∈ ΣT }
2 while (T , A∗ ) 6≡AQ (H, A∗ ) do

3

4

5

Let (A∗ , A(a)) be a positive counterexample
A ← TreeShape(ΣT , A, H)
Find B such that T |= CA ⊑ B and H 6|= CA ⊑ B ,
add CA ⊑ B to H

6 end
7 return H

in Line 3 that counterexamples are positive is justiﬁed by the
fact that the algorithm maintains the invariant that T |= H. In-
deed, the algorithm adds only CIs that are logical consequences
of the target T . This property holds before the ﬁrst insepara-
bility query is asked and it remains true when the next (posi-
tive) counterexamples CIs are received. When a new counterex-
ample (A∗ , A(a)) is received, the learner should ﬁnd a tree
shaped ABox A rooted in ρ obtained from A∗ such that there

is B ∈ ΣT

Then, h∗ : IA′ → IA is a homomorphism.
Remark 1. In the domain and role minimization steps, we as-
sume that the algorithm always attempts to remove the ‘clones’
(that is, elements in nodes(bc)) generated in the unfold step ﬁrst
(that is, before attempting to remove elements of ind(A∗ )). By
Lemmas 26 and 27 this assumption is w.l.o.g. This means that
we can assume that there is a positive example (A, A(a)) with
a ∈ ind(A∗ ) whenever an ABox A is returned by Algorithm 2.

Lemma 28. If (T , A) |= A(a) and (H, A) 6|= A(a) where

A is the output of Algorithm 3, then (A∗ , A(a)) is a positive
counterexample.

Proof. Assume (T , A) |= A(a) and (H, A) 6|= A(a) where

A is the output of Algorithm 3. By Lemma 27 and the fact
that minimization only removes nodes and role assertions from
A, there is an ABox homomorphism from A to A∗ , and
so, (T , A∗ ) |= A(a) (by Remark 1, we can assume that
a ∈ ind(A∗ )). We need to show that (H, A∗ ) 6|= A(a).
In Line 1 the algorithm saturates A∗ with H. This means
that if (H, A∗ ) |= A(a) then A(a) ∈ A∗ (after saturat-
ing A∗ with H). By construction of A, if A(a) ∈ A∗ then
A(a) ∈ A, which contradicts the fact that (H, A) 6|= A(a).

So (H, A∗ ) 6|= A(a).

By Lemma 28 and the fact that A is tree shaped, we can
see that one can compute a CI CA ⊑ B such that (T , A∗ ) |=

B (b), (H, A∗ ) 6|= B (b), and (H ∪ {CA ⊑ B}, A∗ ) |= B (b),

for some b ∈ ind(A∗ ). We now show that one can compute
such CI in polynomial time in |A∗ | and |T |.
Lemma 29. For any ELH target T and any ELH hypothesis
H with size polynomial in |T |, given a positive counterexample
(A∗ , A(a)), Algorithm 3 terminates in polynomial time in |A∗ |
and |T |.

Proof. Entailment in ELH is in PT IM E (Baader et al. 2007a)
and saturating an ABox with H does not require any query to
the oracle, thus all steps in saturation with H can be computed
in polynomial time. For each concept name A ∈ ΣT , domain
minimization asks at most |ind(A∗ )| membership queries and
role minimization asks at most |A∗ | membership queries (each
query to the oracle counts as one computation step).

We now show that Algorithm 2 also runs in polynomial time
in |A∗ | and |T |. In each iteration, unfold adds new individuals
to the ABox and minimize removes individuals. To show that
the algorithm terminates (in polynomial time), we show that on
one hand the size of an ABox after minimization is polynomial
in |T |. On the other hand, we show that each time the algorithm
unfolds the number of individuals after minimization is larger
than before the unfolding step (see (Konev, Ozaki, and Wolter
2016)).
Lemma 30. Let T be an ELH ontology, C ′ a concept ex-
pression and A a concept name such that ∅ 6|= C ′ ⊑ A.
If T |= C ′ ⊑ A then there is C ⊑ A ∈ T such that

T |= C ′ ⊑ C .

Proof. Let IT ,C ′ be the canonical model of C ′ with respect to
T . We have that ρC ′ ∈ AIT ,C ′ because T |= C ′ ⊑ A. Since
∅ 6|= C ′ ⊑ A, by the construction of the canonical model, there
is C ⊑ A ∈ T such that there is a homomorphism h : TC →
IT ,C ′ with h(ρC ) = ρC ′ . Then, by Lemma 25, T |= C ′ ⊑

C .

Given a concept expression C , we write C ′ ≺ C if C ′ is the
concept expression corresponding to the tree that results from
replacing a subtree TD of TC by a concept name A such that
T |= A ⊑ D . We write C ′ ≺∗ C if C ′ = C or there is a
sequence C1 ≺ C2 ≺ . . . ≺ Cn with C1 = C ′ , Cn = C and
n > 1. By this deﬁnition, the following lemma is straightfor-
ward.
Lemma 31. For all concept expressions C ′ , C , we have that
C ′ ≺∗ C iff T |= C ′ ⊑ C . Moreover, |C ′ | ≤ |C |.
Lemma 32. Let A be a minimal ABox. Then |ind(A)| ≤ |T |.

Proof. Let A be the ABox returned by Algorithm 3. Then there

is A(a) such that (T , A) |= A(a) and (H, A) 6|= A(a). This

means that there is a CI C ′ ⊑ A such that T |= C ′ ⊑ A,
H 6|= C ′ ⊑ A and a ∈ (C ′ \ A)IA . By Lemma 30, there
is C ⊑ A ∈ T such that T |= C ′ ⊑ C . By Lemma 31,
C ′ ≺∗ C and |C ′ | ≤ |C |. If a ∈ C ′IA then (by Lemma 25)
there is a homomorphism h : IC ′ → IA mapping ρC to a,
where ρC is the root of IC . Since |C ′ | ≤ |C |, we only need
to show that h is surjective. Suppose this is not the case. Then,
there is b ∈ ∆IA such that b /∈ Imh , where Imh = {e ∈
∆IA | e = h(p) for some p ∈ ∆IC ′ }.
Denote as IA−b the result of removing b /∈ Imh from
IA . Since IA−b is a subinterpretation of IA , if a /∈ AIA
then a /∈ AIA−b . So a ∈ (C ′ \ A)IA−b , which means that

(T , A−b ) |= A(a) while we still have (H, A−b ) 6|= A(a).

This contradicts the fact that A is minimal. Thus, |ind(A)| ≤

|∆IC ′ | ≤ |∆IC | ≤ |T |.

Lemma 33. Let An be the minimal ABox computed in the n-th
iteration in Line 4 of Algorithm 2. Assume An has a cycle. For

all n ≥ 0, |ind(An+1 )| > |ind(An )|.

Proof. The argument is similar to the one presented in (Konev,
Ozaki, and Wolter 2016, Lemma 51). There is an ABox ho-
momorphism from An+1 to An , which is surjective because
otherwise An would not be minimal. This homomorphism is
not injective because at least one element of a cycle in An has
been unfolded and remained in An+1 after minimization.

Lemmas 32 and 33 bound the number of iterations of Al-
gorithm 2. We already argued in Lemma 29 that Algorithm 3
terminates in polynomial time (in |T | and |A∗ |) and it is easy
to see that unfolding can also be performed in polynomial time
(ﬁrst it doubles a cycle in A∗ and in subsequent iterations it
doubles a cycle in an ABox of size polynomial in |T |). Thus,
Algorithm 2 also runs in polynomial time.

Learning ELH ontologies with IQ

Our proof strategy is based on the proof for the learning frame-
work F(ELHrhs , IQ) (Konev, Ozaki, and Wolter 2016). We as-
sume w.l.o.g. that the target T does not entail non-trivial role
equivalences (that is, there are no distinct r and s such that
T |= r ⊑ s and T |= s ⊑ r). This simpliﬁes our presentation,
in particular, Line 8 of Algorithm 4 relies on it. The assump-
tion can be dropped using the notion of a representative role
(see (Konev et al. 2018, Theorem 34)).
The learning algorithm for F(ELH, A∗ , IQ) is given by Al-
gorithm 4. In Line 1, Algorithm 4 computes a hypothesis H
that is AQ-inseparable from T (with only membership queries).

Then, the algorithm iterates in a ‘while loop’ posing insepara-
bility queries regarding the IQ language. Upon receiving a pos-
itive counterexample (A∗ , C (a)), some operations are made
in order to learn a CI of the form A ⊑ D entailed by T but
not by H. The assumption in Line 3 that counterexamples are
positive is justiﬁed by the fact that the algorithm maintains the
invariant that T |= H. Indeed, in the OMQA setting, a learn-
ing algorithm can always ensure this property by keeping in
the hypothesis only CIs C ⊑ D such that a membership query
with (AC , D(ρC )) as input has returned ‘yes’. In particular,
Algorithm 4 only adds to the hypothesis CIs that are entailed
by T .
We now explain the notion of a T -essential CI (Konev
et al. 2018) which appears in Algorithm 4. This notion is
based on some operations performed on examples of the form
({A(a)}, C (a)) representing CIs A ⊑ C , where A ∈ NC ,
a ∈ NI , and C an arbitrary concept expression. Intuitively, a
T -essential CI is a CI that is in a sense informative for the
learning algorithm and its size is bounded by a polynomial in
T . For the ontology language ELH, the operations are: con-
cept saturation for T , role saturation for T , sibling merging
for T and decomposition on the right for T . We may omit ‘for
T ’ if this is clear from the context. We now recall these oper-
ations (Konev et al. 2018), adapted to the OMQA setting. In
the following, assume we are given an example of the form

({A(a)}, C (a)).

Concept saturation for T consists of updating C with the re-
sult C ′ of choosing a node ν in TC and adding a new concept
name from ΣT to the label of ν if ({A(a)}, C ′ (a)) is still a
positive example. A positive example ({A(a)}, C (a)) is con-
cept saturated for T if concept saturation for T is applied ex-
haustively. Similarly, role saturation for T consists of updating
C with the result C ′ of choosing an edge (ν, ν ′ ) in TC and
replacing the role name r in the label of (ν, ν ′ ) by a distinct

s ∈ ΣT such that T |= s ⊑ r if ({A(a)}, C ′ (a)) is still a

positive example. A positive example ({A(a)}, C (a)) is role
saturated for T if role saturation for T is applied exhaustively.

Example 34. Let the signature be ΣT = {A, B , r, s}, the

target be T = {B ⊑ A, A ⊑ ∃s.B , s ⊑ r}, the ﬁxed

ABox be A∗ = {A(a)}, the hypothesis be H = {B ⊑
A, s ⊑ r} and the received counterexample be (A∗ , ∃r.A(a)).

Note that (T , A∗ ) |= ∃r.A(a) and (H, A∗ ) 6|= ∃r.A(a). Af-

⊳

ter having concept saturated the counterexample, it becomes
(A∗ , A ⊓ ∃r.(A ⊓ B )(a)), and after having role saturated we
obtain (A∗ , A ⊓ ∃s.(A ⊓ B )(a)), changing the order does not
make any difference in this example.
Sibling merging for T updates C with the result C ′ of choos-
ing nodes ν, ν1 , ν2 in TC such that ν1 and ν2 are r-successors
of ν and merging them (the merged node is connected to the
successors of ν1 , ν2 and the label of it is the union of the la-
bels of ν1 , ν2 ) if ({A(a)}, C ′ (a)) is still a positive example.
A positive example ({A(a)}, C (a)) is sibling merged for T if
sibling merging for T is applied exhaustively. We now deﬁne
decomposition on the right for T . Let Cν be the concept corre-
sponding to the sub-tree rooted in ν in TC and let C |−
ν ↓ be the
concept corresponding to the result of removing the sub-tree
rooted in ν from TC . If ν ′ is an r-successor of ν in TC , A′
is in the node label of ν , and ({A′ (a)}, ∃r.Cν ′ (a)) is a posi-
tive example plus A′ 6≡T A if ν is the root of C , then replace

({A(a)}, C (a)) by

(a) ({A′ (a)}, ∃r.Cν ′ (a)) if H 6|= A′ ⊑ ∃r.Cν ′ ; or
(b) ({A(a)}, C |−

ν ′ ↓ (a)), otherwise.
A CI A ⊑ C is concept saturated/role saturated/sibling
merged/decomposed on the right for T , that is, it is T -essential,
if this is the case for ({A(a)}, C (a)).
Lemma 35. Let A ⊑ C be T -essential, then |C | ≤ |ΣT ||T |.
Lemma 35 is an easy consequence of (Duarte, Konev, and
Ozaki 2018, Lemma 2). The only difference is that our ontolo-
gies may also have RIs, so our notion of a T -essential CI in-
cludes role saturation (as in (Konev et al. 2018)).

Algorithm 4: ELH IQ learning algorithm
Input: Signature ΣT
Output: Hypothesis H
1 Compute H such that (T , A∗ ) ≡AQ (H, A∗ )

2 while (T , A∗ ) 6≡IQ (H, A∗ ) do

Let (A∗ , C (a)) be the positive counterexample
returned by the oracle

Let A = {α ∈ AQ | (H, A∗ ) |= α}

α = ReduceCounterexample((A∗ ∪ A, C (a)), H)
Compute a T -essential CI A ⊑ D from α
if there is A ⊑ D ′ ∈ H then
Find a T -essential A ⊑ D∗ such that

3

4

5

6

7

8

9

∅ |= D∗ ⊑ D ⊓ D ′

11

12

10

Replace A ⊑ D ∈ H by A ⊑ D∗
end
else
Add A ⊑ D to H
end
14 end
15 return H

13

To show that Algorithm 4 runs in polynomial time (where
each call to an oracle counts as one step of computation), we
show that (1) the number of iterations is polynomially bounded;
and (2) each iteration can be computed in polynomial time. We
start by arguing that each iteration requires polynomially many
steps (Point 2). Line 5 of Algorithm 4 can be computed in poly-
nomial time using the same algorithm as the one used to learn
DL-Lite∃
R ontologies (Konev, Ozaki, and Wolter 2016), except
that here we do not use parent-child merging because ELH
does not have inverse roles. Line 4 ensures that one can indeed
ﬁnd a singleton ABox, even though ELH allows CIs of the
form C ⊑ A. For convenience of the reader we provide here
the algorithm (Algorithm 5) for reﬁning counterexamples. Al-
gorithm 5 ‘walks inside’ A and C in order to ﬁnd a singleton
ABox which together with T entails a subconcept of C .
Example 36. Assume T = {A ⊑ ∃r.D}, H = ∅, and

A∗ = {r(a, b), A(b)}. Let (A∗ , ∃r.∃r.D(a)) be the posi-

tive counterexample received at Line 3 of Algorithm 4. In the
next line it calls the function ‘ReduceCounterexample’ (Algo-
rithm 5), with (A∗ , ∃r.∃r.D(a)) and H as input. The func-
tion makes a recursive call with the positive counterexample

({r(a, b), A(b)}, ∃r.D(b)) and H as input. In the new func-

tion call, Algorithm 5 ﬁnds the singleton ABox {A(b)} which
satisﬁes the condition in Line 6 (i.e., (T , {A(b)}) |= ∃r.D(b)
and returns A ⊑ ∃r.D .

⊳

Algorithm 5: ReduceCounterexample
Input: Example (A, C (a)), TBox H
Output: CI A ⊑ D
1 Let D = ∃r.C ′ be a top-level conjunct of C such that

(T , A) |= ∃r.C ′ (a) and (H, A) 6|= ∃r.C ′ (a)

2 if there is s(a, b) ∈ A such that H |= s ⊑ r and

(T , A) |= C ′ (b) then

3

A ⊑ D=ReduceCounterexample((A, C ′(b)),H)
4 end
5 else
Find a singleton {A(c)} ⊆ A such that

6

(T , {A(c)}) |= D(c)

7 end
8 return A ⊑ D

We ﬁrst argue that Algorithm 5 is implementable. That is,
in Line 1, one can indeed assume the existence of a top-level
conjunct D = ∃r.C ′ of C such that (T , A) |= ∃r.C ′ (a) and
(H, A) 6|= ∃r.C ′ (a). This follows from Lemma 37.
Lemma 37. Let T be an ELH TBox and A an ABox. If
i=1Di then there is a Di with

(T , A) 6|= C (a) with C = ⊓n
i ∈ {1, · · · , n} such that (T , A) 6|= Di (a).

Proof. If (T , A) |= Di (a) for all i ∈ {1 · · · n} means that
there is a homomorphism from hi : TDi → IT ,A mapping
ρDi to a ∈ ∆IT ,A . It trivially follows that there is a homo-
morphism h : TC → IT ,A obtained by merging all hi into a
unique function. By Lemma 25, we reach a contradiction be-
cause this would mean that (T , A) |= C (a).

Also, if there is no s(a, b) ∈ A such that H |= s ⊑ r
and (T , A) |= C ′ (b) (that is, the condition in Line 2 is not
satisﬁed) then one can indeed ﬁnd a singleton {A(c)} ⊆ A
such that (T , {A(c)}) |= D(c) in Line 6. This follows from
Lemma 40. To prove Lemma 40, we ﬁrst show the following
two technical lemmas. Let IC be an interpretation, the one-
neigbourhood NIC (a) of a ∈ ∆IC is the set of concept names
A with a ∈ AIC .
Lemma 38. Let T be an ELH terminology and let C and
D = ∃r.D ′ be concept expressions. Assume there is a homo-
morphism h : TD → IT ,C such that h(ρD ) = d ∈ ∆IC
and the image of the subtree TD′ of TD under h is included
in ∆IT ,C \ ∆IC . Then there exists A ∈ NIC (d) such that

T |= A ⊑ D .

Proof. Since T is an ELH terminology, it contains only CIs of
the form A ⊑ F or F ⊑ A with F an ELH concept expression
and A a concept name. In the construction of the canonical
model (Deﬁnition 20), the deﬁnition of In+1 is the result of
either

• adding a new element of ∆In to the extension AIn of a
concept name A (to satisfy a CI of the form F ⊑ A); or
• identifying the root of the tree interpretation TF of a concept
expression F with some element of ∆In in the extension
AIn of a concept name A (to satisfy a CI of the form A ⊑
F ).

Thus, if there is a homomorphism h : TD → IT ,C such that
h(ρD ) = d ∈ ∆IC and the image of the subtree TD′ of TD
under h is included in ∆IT ,C \ ∆IC this can only be if there
is A ∈ NIC (d) such that T |= A ⊑ D .

Lemma 39. If there is a homomorphism h : TC → IT ,A for
an arbitrary concept expression C , an ELH terminology T , an
ABox A, and a node ν in TC is mapped to a ∈ ∆IA , then all
ancestors of ν are mapped into ∆IA .

Proof. ELH does not allow inverse roles. So, if ν has a parent
ν ′ it must be in ∆IA because in the construction of canonical
model IT ,A only role successors are connected to the elements
of ∆IA .

Lemma 40. Let T be the target, H the hypothesis and A an
ABox. If (T , A) |= ∃r.C (a), there is no s(a, b) ∈ A such that
T |= s ⊑ r and (T , A) |= C (b), then there is a singleton

ABox A′ such that (T , A′ ) |= ∃r.C (a).

Proof. Let C ′ = ∃r.C , we know that there is a homomor-
phism h : TC ′ → IT ,A such that h(ρC ′ ) = a ∈ ∆IA . If we
show that all nodes in TC are mapped into ∆IT ,A \ ∆IA then
we are able to conclude that there is a concept name A such
that T |= A ⊑ C ′ by using Lemma 38.
Let ν a descendant of ρC . For a proof by contradiction
we assume that a node ν is mapped by h to an element in
∆IA . By Lemma 39, all its ancestors must be mapped into
∆IA by h. Remember that h(ρC ′ ) = a, this means that
exists an s(a, h(ρC )) ∈ A such that T |= s ⊑ r and
(T , A) |= C (h(ρC )), which contradicts our assumption.

So we have that Algorithm 5 is implementable. It is easy
to see that if the input is a positive counterexample then the
output is also a positive counterexample (for T and H). Each
line of Algorithm 5 can be computed using polynomially many
steps. Regarding the recursive calls, we point out that, each
time Algorithm 5 makes a recursive call, the example passed
as parameter to the function is strictly smaller, so the number
of recursive calls is bounded by the size of the counterexample
received in Line 3 of Algorithm 4.
Now we have that in Line 5 of Algorithm 4 we obtain a pos-
itive counterexample of the form ({A(a)}, C (a)) in polyno-
mial time. It follows from the proof of Lemma 2 in (Duarte,
Konev, and Ozaki 2018) that Line 6 can also be computed
in polynomial time, and moreover, the size of resulting CI is
polynomial in |T |. Indeed Lemma 35 is an easy consequence
of (Duarte, Konev, and Ozaki 2018, Lemma 2) and the only
difference in the setting of Lemma 2 and ours is that ELH al-
lows RIs. We observe that our notion of T -essential includes
role saturation (as in (Konev et al. 2018)). That is, a positive ex-
ample (A, C (a)) is T -essential if it is concept saturated, role
saturated, sibling merged and decomposed on the right for T .
This notion is also used for CIs. A CI A ⊑ C is T -essential if
this is the case for ({A(a)}, C (a)). Role saturation for T can
be implemented in polynomial time (Konev et al. 2018) and
the result of Lemma 2 in (Duarte, Konev, and Ozaki 2018) can
be easily extended to our case.
The fact that Line 8 is also implementable in polynomial
time follows from Lemma 41 below, which is an adaptation
of (Duarte, Konev, and Ozaki 2018, Lemma 7 used to show
Theorem 2) (see also (Konev et al. 2018, Lemma 30)).

Lemma 41. Let A ⊑ C1 and A ⊑ C2 be T -essential positive
examples. One can construct a T -essential A ⊑ C such that
∅ |= C ⊑ C1 ⊓ C2 in polynomial time in |C1 | + |C2 |.

Sketch. The main difference is that here the ontology language
is ELH, which also includes RIs. Since A ⊑ C1 and A ⊑ C2
are T -essential, these examples are role saturated. By assump-
tion, the target ontology does not entail non-trivial RIs (see
begin of paragraph ‘Learning ELH ontologies with IQ’ in Sec-
tion ). Thus, the presence of RIs does not affect the application
of sibling merging.

The rest of this subsection is devoted to show that the num-
ber of iterations is polynomial in the size of T . In each iteration
either a CI is replaced or it is added to the hypothesis. The num-
ber of times it is added to the hypothesis is bounded by |ΣT |.
Thus, it remains to show that the number of replacements is
also bounded polynomially in |T |.
To show this, we use Lemmas 42 and 43 below. Given the
tree representation TC of a concept C and an interpretation I ,
we say that a homomorphism h : TC → I is an isomorphic
embedding for T if it is injective, A ∈ l(ν ) if h(ν ) ∈ AI
for all concept names A, and for r = l(ν, ν ′ ) it holds that

T |= r ⊑ s for all (h(ν ), h(ν ′ )) ∈ sI .

Lemma 42 (Isomorphic Embedding). Let A ⊑ C be a T -
essential CI. If T |= A ⊑ D and T |= D ⊑ C then any
homomorphism h : TC → ID,T such that h(ρC ) = ρD is an
isomorphic embedding for T .

Sketch. The argument is as in (Konev et al. 2018, Lemma 31).
Non-injectivity would contradict that A ⊑ C is sibling merged
(which follows from the assumption that it is T -essential). The
remaining conditions for the notion of isomorphic embedding
for T follow from the fact that A ⊑ C is concept and role
saturated for T (which again follow from the assumption that
the example is T -essential).

By the Claim of Lemma 33 in (Konev et al. 2018) the fol-
lowing holds.
Lemma 43. If A ⊑ C is T -essential, T |= A ⊑ C ′ and
∅ |= C ′ ⊑ C and ∅ 6|= C ⊑ C ′ , then TC is obtained from TC ′
by removing at least one subtree.

We are now ready for Lemma 44, which bounds the number
of replacements.
Lemma 44. For every A ∈ ΣT , the number of replacements
of a CI in H in Algorithm 4 is bounded polynomially in |T |.

Proof. All CIs that are added or replace a CI in H are T -
essential and, therefore, their size is polynomially bounded by
|T | (Lemma 35). As already argued in (Konev et al. 2018,
Lemma 33), when A ⊑ C is replaced with A ⊑ C ′ , then
∅ |= C ′ ⊑ C and ∅ 6|= C ⊑ C ′ (otherwise the positive coun-
terexample returned by the oracle would be a consequence of
H). Moreover, both A ⊑ C and A ⊑ C ′ are consequences of
T . So the conditions of Lemma 43 are satisﬁed, and so, when-
ever a CI A ⊑ C is replaced by by some other CI A ⊑ C ′ , we
have that VC ′ > VC .
The presence of CIs of the form C ⊑ A in our setting does
not affect the argument in (Konev et al. 2018, Lemma 33) be-
cause the CIs we mention are T -essential, in particular, they
are concept saturated for T , and so, they always satisfy the
inclusions of the form C ⊑ A .

This concludes our proof of Theorem 6.

Learning ELH ontologies with CQr

We show that one can convert in polynomial time any q ∈ CQr
in a positive counterexample of the form (A∗ , q) into an IQ
q ′ such that (A∗ , q ′ ) is a positive counterexample. Then our
upper bound follows from Theorem 6. To transform the query
in a positive counterexample into an IQ, we use the following
three operations.
1. Given a positive counterexample (A∗ , q), individual satu-
ration for T consists of updating q = ∃~xϕ(~a, ~x) with the
result q ′ of choosing x ∈ ~x and a ∈ ind(A∗ ) and replacing
x by a if (A∗ , q ′ ) is still a positive counterexample.
2. Given a positive counterexample (A∗ , q), merging for T
consists of updating q = ∃~xϕ(~a, ~x) with the result q ′ of
choosing distinct x, x′ ∈ ~x and replacing all occurrences of
x by x′ if (A∗ , q ′ ) is still a positive counterexample.
3. Given a positive counterexample (A∗ , q), query role satu-
ration for T consists of updating q = ∃~xϕ(~a, ~x) with the
result q ′ of choosing an atom s(t, t′ ) and a role r ∈ ΣT
such that T |= r ⊑ s (under the assumption of not having
equivalent roles, as described above for learning with IQs)
and replacing s(t, t′ ) by r(t, t′ ) if (A∗ , q ′ ) is still a positive
counterexample.
We say that a positive counterexample (A∗ , q) is individual
saturated/ merged/ query role saturated for T if individual sat-
uration/ merging/ query role saturation for T has been exhaus-
tively applied. Given a query q ∈ CQr , we denote by Gx
q the
induced subgraph of Gq = (V , E ) that has as nodes x, where
x ∈ V , and nodes in V that are reachable from x via a directed
path. We say that Gx
q is tree shaped if there is a unique element
(the root), denoted by ρG , such that (i) for every node d there is
a directed path from ρG to d and (ii) for every distinct directed
paths p1 , p2 starting from ρG their last elements are distinct.
Lemma 45. Let T and H be ELH TBoxes and assume T and
H entail the same RIs. If a positive counterexample (A∗ , q)
(for T and H), with q ∈ CQr , is individual saturated/ merged
and query role saturated for T , then for all x occurring in
q , the graph Gx
q is tree shaped and only one individual name
reaches x with a path that visits only variables.

Sketch. Since (T , A∗ ) |= q , there is a homomorphism h from
q = ∃~xϕ(~a, ~x) to IT ,A∗ mapping every individual to itself.
Since individual saturation has been exhaustively applied to q ,
every x ∈ ~x is mapped by h into ∆IT ,A∗ \ ∆IA∗ . If this is not
the case a variable is mapped by h into ∆IA∗ and individual
saturation is not exhaustively applied, reaching a contradiction.
Suppose that Gx
q is not tree-shaped. Since T and H entail
the same RIs and query role saturation for T has been applied
it is not the case that for r, s ∈ ΣT there is a variable that
is both r-successor and s-successor of another variable. There-
fore, there is an undirected cycle in Gx
q with three or more
nodes. This means that for w, y , z ∈ ~x with w 6= y 6= z ,
atoms of the form r(w, y ), s(z , y ) are in q . We know that h(y )
is mapped into ∆IT ,A∗ \ ∆IA∗ , and by the construction of
the canonical model IT ,A∗ , it follows that h(y ) has only one
parent. Thus h(w) = h(z ). But this means that every occur-
rence of w can be replaced by z . This contradicts the fact that
(A∗ , q) has been merged for T . Therefore Gx
q is tree-shaped.

The fact that, for all x ∈ ~x, only one individual name reaches x
with a path that visits only variables follows from the structure
of the canonical model IT ,A∗ and the fact that q is individual
saturated for T .

Lemma 8. Let T and H be ELH TBoxes and assume T and H
entail the same RIs. Given a positive counterexample (A∗ , q)
(for T and H), with q ∈ CQr , one can contruct a positive
counterexample (A∗ , q ′ ) with q ′ ∈ IQ in polynomial time in

|(A∗ , q)||ΣT |.

Proof. We use the following claim.

Claim 1. Given a positive counterexample (A∗ , q) with q ∈
CQr . One can compute a positive counterexample (A∗ , q ′ )
that is individual saturated/ merged/ query role saturated for
T in polynomial time with respect to |(A∗ , q)| and |ΣT |.

We prove this claim by analysing the running time of individ-
ual saturation, merging and query role saturation for T . There
are at most |q | variables in q that can potentially be replaced
with individuals. Since the number of individuals is bounded
by |A∗ |, after at most |A∗ ||q | membership queries, (A∗ , q) is
individual saturated for T . There are at most |q | variables in q
that can be merged. Therefore, after at most |q |2 membership
queries (A∗ , q) is merged for T . We assume without loss of
generality that role names have a representative, so no equiva-
lent role name is in q . There are at most |q | atoms of the form
s(t, t′ ) with t, t′ ∈ ~a ∪ ~x in q and at most |ΣT | different role
names r such that T |= r ⊑ s. For every s(t, t′ ) in q , it
is checked in polynomial time if the query that results from
replacing s(t, t′ ) by r(t, t′ ) in q is still entailed by (T , A∗ )
(that is, after modifying q , whether (A∗ , q) is still a positive
counterexample). After at most |q ||ΣT | membership queries
(A∗ , q) is query role saturated for T . This ﬁnishes the proof of
this claim.
Given a positive counterexample (A∗ , q) with q ∈ CQr , let
(A∗ , q ′ ) be the result of exhaustively applying individual sat-
uration/ merging/ query role saturation for T . Then, for all x
occurring in q ′ , the graph Gx
q′ is tree shaped and only one in-
dividual name reaches x with a path that visits only variables.
If Gx
q′ is tree shaped, then one can translate the subquery of q ′
containing x and other variables reachable from x into a con-
cept expression, denoted C x
q′ . For every atom of the form A(a)
in q ′ we check whether (H, A∗ ) 6|= A(a) (atoms of the form
r(a, b) do not need to be checked since by assumption T and
H entail the same RIs). If this is the case for any such A(a) we
have that (A∗ , A(a)) is a positive counterexample and we are
done.
Otherwise we claim that there is r ∈ ΣT , a ∈ ind(A∗ ),
and a variable x in q ′ such that (A∗ , ∃r.C x
q′ (a)) is a positive
counterexample. Indeed, suppose to the contrary that for all
r ∈ ΣT , a ∈ ind(A∗ ), and x occurring in q ′ , (T , A∗ ) |=
q′ (a). Then there are ho-
momorphisms h∃r.C x
q′ (a) from all such T∃r.C x
into IH,A∗
mapping a to itself. By assumption, for every atom α of the
form A(a) or r(a, b) in q ′ , we have that (H, A∗ ) |= α. Thus,
one can construct a homomorphism from q ′ to IH,A∗ by tak-
ing the union h of all such h∃r.C x
q′ (a) and extending h by map-
ping all individual names occurring in q ′ into themselves. We

∃r.C x
q′ (a) implies (H, A∗ ) |= ∃r.C x

q′

thus have that (H, A∗ ) |= q ′ , which contradicts the fact that
(A∗ , q ′ ) is a positive counterexample.

Lemma 46. Let T and H be ELH TBoxes which entail the
same RIs and let A∗ be an ABox. If (T , A∗ ) ≡IQ (H, A∗ )

then (T , A∗ ) ≡CQr (H, A∗ ).

Sketch. Assume to the contrary that there is a query q ∈ CQr
such that (T , A∗ ) |= q but (H, A∗ ) 6|= q (or vice-versa). By
Lemma 8, one can contruct a positive counterexample (A∗ , q ′ )
with q ′ ∈ IQ in polynomial time in |(A∗ , q)||ΣT |. This con-
tradicts the assumption that (T , A∗ ) ≡IQ (H, A∗ ). Thus,

(T , A∗ ) ≡CQr (H, A∗ ).

Theorem 9. F(ELH, A∗ , CQr ) is in PT IM EL .

Proof. The target T is a terminology, therefore it contains CIs
of the form C ⊑ A or A ⊑ C . All needed CIs of the form
C ⊑ A can be learned without asking any inseparability query
according to Theorem 4. Moreover, all RIs r ⊑ s can be
learned in polynomial time using membership queries of the
form ({r(a, b)}, s(a, b)). It remains to learn CIs of the form
A ⊑ C after the learner receives a positive counterexample
(A∗ , q) with q ∈ CQr . By Lemma 8 we can ﬁnd a positive
counterexample of the form (A∗ , C (a)) from a positive coun-
terexample (A∗ , q), with q ∈ CQr , in polynomial time. There-
fore, by Theorem 6 we can learn a IQ-inseparable hypothesis
in PT IM EL. If ELH TBoxes entail the same RIs and are IQ-
inseparable then, by Lemma 46, they are CQr -inseparable as
well (w.r.t. some ABox A∗ ).

Proofs for Section “Data Updates”

Theorem 10. Let T and H be ELH terminologies entailing
the same RIs, and let A∗ and A be ABoxes. If, for all b ∈

ind(A), there is a ∈ ind(A∗ ) such that (IA∗ , a) ∼ (IA , b),

then (H, A∗ ) ≡IQ (T , A∗ ) implies (H, A) ≡IQ (T , A).

Proof. For all concept expressions C , it holds by Lemma 23
that (H, A) |= C (b) iff (H, A∗ ) |= C (a). Since we assumed

(T , A∗ ) ≡IQ (H, A∗ ), it holds that (H, A∗ ) |= C (a) iff
(T , A∗ ) |= C (a). But again by Lemma 23, (T , A∗ ) |= C (a)

iff (T , A) |= C (b). Since we assumed that T and H entail the
same RIs the statement holds.

Theorem 12. Let F be the learning framework that results
from adding all pairs of the form (A, q), with A ∈ gT (A∗ )

and q ∈ IQ, to the set S in F(ELH, A∗ , IQ) = (E , S , L, µ),

where T ∈ L. Assume ΣT ⊆ ΣA∗ . Then, F is in PT IM EL .

Sketch. We ﬁrst focus on CIs of the form C ⊑ A, with
A ∈ NC . Let H be a hypothesis with CIs computed with Al-
gorithm 1 (modiﬁed to ask only membership queries, cf. Theo-
rem 4) and then generalised. Clearly, H can be generalised for
T in polynomial time in |ΣT | and |H|.

Claim 1. For all A ∈ gT (A∗ ) and all α ∈ A, (H, A∗ ) |=
α. Moreover, if there is a homomorphism h : TC → IH,A∗
mapping ρC to some a ∈ ind(A∗ ), where C ⊑ B ∈ H, then
there is a homomorphism h : TC → IH,A mapping ρC to a.

By deﬁnition of gT (A∗ ), A is a subset of A∗ ∪ {α ∈ AQ |
(T , A∗ ) |= α}. Therefore, since (H, A∗ ) ≡IQ (T , A∗ ), for
every assertion α ∈ A, (H, A∗ ) |= α. The second statement
follows from the fact that H is generalised for T and the deﬁ-
nition of gT (A∗ ).
Let A ∈ gT (A∗ ). Assume (T , A) |= A(a). By deﬁni-

tion of A, (T , A∗ ) |= A(a). As (H, A∗ ) ≡AQ (T , A∗ ),
(H, A∗ ) |= A(a). If (H, A∗ ) |= A(a), with A ∈ NC , and

A(a) 6∈ A∗ then there is C ⊑ A ∈ H such that a ∈ C IH,A∗ .
By Claim 1 and Lemma 24, if A(a) 6∈ A∗ then a ∈ C IH,A .
Thus, by the ﬁrst statement of Claim 1, (H, A∗ ) |= A(a). As
T |= H (c.f. Lemma 2 and the deﬁnition of generalisation for

T ), if (H, A) |= A(a) then (T , A) |= A(a).

Thus, after computing a generalised H for T we obtain a
TBox that is not only AQ-inseparable from T w.r.t. A∗ but
also w.r.t. all A ∈ gT (A∗ ). CIs of the form A ⊑ D , with A ∈
NC , are not affected by the ABox updates since ΣT ⊆ ΣA∗
and we can use Algorithm 4 with counterexamples of the form
(A, C (a)) with A ∈ gT (A∗ ) in the same way as with A =
A∗ . All RIs can be easily learned with membership queries of

the form ({r(a, b)}, s(a, b)).

Proofs for Section “Learning from Data”

Theorem 13. Let F(ELH, A∗ , Q) = (E , S , L, µ) be an

OMQA learning framework, with Q ∈ {AQ, IQ, CQr }, and
let T ∈ L be such that ΣT ⊆ ΣA∗ . Let X ⊆ E be the set
of examples (A, q) such that there is an ABox homomorphism
from A to A∗ . Then, there is a batch B ⊆ X , polynomial in
|T |, and an algorithm such that it takes B as input, it eventually
halts, and returns H ∈ L such that µ(H)

nX

(1 − ǫ)mi ≤

nX

i=1

e−ǫmi ≤

nX

e−ǫ 1
ǫ (ln 1
δ +i ln 2) ≤

i=1
e−(ln 2i
δ ) ≤

nX

i=1

i=1

nX

i=1

nX

i=1

e−(ln 1
δ +i ln 2) ≤

eln δ

2i ≤

nX

i=1

δ
2i ≤ δ.

Since we assumed that the original algorithm learns F is
polynomial time, i is polynomial in |t| and |e|, where e is the
largest example in Smn . Therefore, F is polynomial time PAC
learnable with membership queries.

Theorem 15. There is a polynomial time PAC learnable
OMQA learning framework that is not in PQU ERYL.

Sketch. Consider
the
OMQA
learning
framework
F(L, A∗ , Q) = (E , S , L, µ) deﬁned in the main part
(Section “Learning from Data”). We have that L is exponential
in n, but ﬁnite. Given ǫ, δ ∈ (0, 1) and f : (0, 1)2 → N such
δ ⌉, and a target T ∈ L, let

that f (ǫ, δ) ≤ ⌈ 1

ǫ ln |L|

Sm = {(e1 , ℓT (e1 )), . . . , (em , ℓT (em ))}

be a sample generated by EXD
f (ǫ, δ). We can compute in polynomial time a hypothesis H
consistent with the m examples as follows.

F(L,{A(a)},Q),T of size m ≥

1. Set H = T0 .
2. If ∃σ .M (a) appears in a positive example of Sm , add A ⊑

∃σ .M to H.

By deﬁnition of L, at most one example of the form
({A(a)}, ∃σ .M (a), 1) can occur in the sample. One can ver-
ify that H is consistent with all the examples in Sm . Since L is
of exponential size, a sample of polynomial size sufﬁces (Vap-
nik 1995), and as we already argued, a hypothesis consis-
tent with any sample (generated by EXD
be constructed in polynomial time. Thus, the learning frame-
work is polynomial time PAC learnable. On the other hand,
F(L, A∗ , Q) is not in PQU ERYL (Konev, Ozaki, and Wolter
2016, proof of Lemma 8).

F(L,{A(a)},Q),T ) can

