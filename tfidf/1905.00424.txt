An ADMM Based Framework for AutoML Pipeline Conﬁguration

Sijia Liu,* Parikshit Ram,* Deepak Vijaykeerthy, Djallel Bouneffouf, Gregory Bramble,
Horst Samulowitz, Dakuo Wang, Andrew Conn, Alexander Gray

IBM Research AI

* Equal contributions

9
1
0
2

v
o

N

1
2

]

G

L

.

s

c

[

4
v
4
2
4
0
0

.

5
0
9
1

:

v

i

X

r

a

Abstract

We study the AutoML problem of automatically conﬁguring
machine learning pipelines by jointly selecting algorithms and
their appropriate hyper-parameters for all steps in supervised
learning pipelines. This black-box (gradient-free) optimization
with mixed integer & continuous variables is a challenging
problem. We propose a novel AutoML scheme by leveraging
the alternating direction method of multipliers (ADMM). The
proposed framework is able to (i) decompose the optimization
problem into easier sub-problems that have a reduced number
of variables and circumvent the challenge of mixed variable
categories, and (ii) incorporate black-box constraints along-
side the black-box optimization objective. We empirically
evaluate the ﬂexibility (in utilizing existing AutoML tech-
niques), effectiveness (against open source AutoML toolkits),
and unique capability (of executing AutoML with practically
motivated black-box constraints) of our proposed scheme on
a collection of binary classiﬁcation data sets from UCI ML
& OpenML repositories. We observe that on an average our
framework provides signiﬁcant gains in comparison to other
AutoML frameworks (Auto-sklearn & TPOT), highlighting
the practical advantages of this framework.

1

Introduction

Automated machine learning (AutoML) research has re-
ceived increasing attention. The focus has shifted from hyper-
parameter optimization (HPO) for the best conﬁguration of a
single machine learning (ML) algorithm (Snoek, Larochelle,
and Adams 2012), to conﬁguring multiple stages of a ML
pipeline (e.g., transformations, feature selection, predictive
modeling) (Feurer et al. 2015). Among the wide-range of
research challenges offered by AutoML, we focus on the
automatic pipeline conﬁguration problem (that is, joint algo-
rithm selection and HPO), and tackle it from the perspective
of mixed continuous-integer black-box nonlinear program-
ming. This problem has two main challenges: (i) the tight
coupling between the ML algorithm selection & HPO; and
(ii) the black-box nature of optimization objective lacking
any explicit functional form and gradients – optimization
feedback is only available in the form of function evalua-
tions. We propose a new AutoML framework to address these
challenges by leveraging the alternating direction method of
multipliers (ADMM). ADMM offers a two-block alternating
optimization procedure that splits an involved problem (with

Copyright c(cid:13) 2020, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

multiple variables & constraints) into simpler sub-problems
(Boyd et al. 2011)
Contributions. Starting with a combinatorially large set
of algorithm candidates and their collective set of hyper-
parameters, we utilize ADMM to decompose the AutoML
problem into three problems: (i) HPO with a small set of
only continuous variables & constraints, (ii) a closed-form
Euclidean projection onto an integer set, and (iii) a combi-
natorial problem of algorithm selection. Moreover, we ex-
ploit the ADMM framework to handle any black-box con-
straints alongside the black-box objective (loss) function –
the above decomposition seamlessly incorporates such con-
straints while retaining almost the same sub-problems.
Our contributions are: (i) We explicitly model the coupling
between hyper-parameters and available algorithms, and ex-
ploit the hidden structure in the AutoML problem (Section
3). (ii) We employ ADMM to decompose the problem into
a sequence of sub-problems (Section 4.1), which decouple
the difﬁculties in AutoML and can each be solved more efﬁ-
ciently and effectively, demonstrating over 10× speedup and
10% improvement in many cases. (iii) We present the ﬁrst
AutoML framework that explicitly handles general black-box
constraints (Section 4.2). (iv) We demonstrate the ﬂexibility
and effectiveness of the ADMM-based scheme empirically
against popular AutoML toolkits Auto-sklearn (Feurer et al.
2015) & TPOT (Olson and Moore 2016) (Section 5), per-
forming best on 50% of the datasets; Auto-sklearn performed
best on 27% and TPOT on 20%.

2 Related work

Black-box optimization in AutoML. Beyond grid-search

for HPO, random search is a very competitive baseline be-
cause of its simplicity and parallelizability (Bergstra and
Bengio 2012). Sequential model-based optimization (SMBO)
(Hutter, Hoos, and Leyton-Brown 2011) is a common tech-
nique with different ‘models’ such as Gaussian processes
(Snoek, Larochelle, and Adams 2012), random forests (Hut-
ter, Hoos, and Leyton-Brown 2011) and tree-parzen estima-
tors (Bergstra et al. 2011). However, black-box optimiza-
tion is a time consuming process because the expensive
black-box function evaluation involves model training and
scoring (on a held-out set). Efﬁcient multi-ﬁdelity approx-
imations of the black-box function based on some budget
(training samples/epochs) combined with bandit learning
can skip unpromising candidates early via successive halv-

 
 
 
 
 
 
ing (Jamieson and Talwalkar 2016; Sabharwal, Samulowitz,
and Tesauro 2016) and HyperBand (Li et al. 2018). How-
ever, these schemes essentially perform an efﬁcient random
search and are well suited for search over discrete spaces or
discretized continuous spaces. BOHB (Falkner, Klein, and
Hutter 2018) combines SMBO (with TPE) and HyperBand
for improved optimization. Meta-learning (Vanschoren 2018)
leverages past experiences in the optimization with search
space reﬁnements and promising starting points. The col-
laborative ﬁltering based methods (?) are examples of meta-
learning, where information from past evaluation on other
datasets is utilized to pick pipelines for any new datasets.
Compared to the recent works on iterative pipeline construc-
tion using tree search (Mohr, Wever, and Hüllermeier 2018;
Rakotoarison, Schoenauer, and Sebag 2019), we provide a
natural yet formal primal-dual decomposition of autoML
pipeline conﬁguration problems.
Toolkits. Auto-WEKA (Thornton et al. 2012; Kotthoff et al.
2017) and Auto-sklearn (Feurer et al. 2015) are the main
representatives of SBMO-based AutoML. Both apply the
general purpose framework SMAC (Sequential Model-based
Algorithm Conﬁguration) (Hutter, Hoos, and Leyton-Brown
2011) to ﬁnd optimal ML pipelines. Both consider a ﬁxed
shape of the pipeline with functional modules (preprocessing,
transforming, modeling) and automatically select a ML algo-
rithm and its hyper-parameters for each module. Auto-sklearn
improves upon Auto-WEKA with two innovations: (i) a meta-
learning based preprocessing step that uses ‘meta-features’
of the dataset to determine good initial pipeline candidates
based on past experience to warm start the optimization, (ii)
an greedy forward-selection ensembling (Caruana et al. 2004)
of the pipeline conﬁgurations found during the optimization
as an independent post-processing step. Hyperopt-sklearn
(Komer, Bergstra, and Eliasmith 2014) utilizes TPE as the
SMBO. TPOT (Olson and Moore 2016) and ML-Plan (Mohr,
Wever, and Hüllermeier 2018) use genetic algorithm and hi-
erarchical task networks planning respectively to optimize
over the pipeline shape and the algorithm choices, but require
discretization of the hyper-parameter space (which can be
inefﬁcient in practice as it leads performance degradation).
AlphaD3M (Drori, Krishnamurthy, and others 2018) inte-
grates reinforcement learning with Monte-Carlo tree search
(MCTS) for solving AutoML problems but without impos-
ing efﬁcient decomposition over hyperparameters and model
selection. AutoStacker (Chen, Wu, and others 2018) focuses
on ensembling and cascading to generate complex pipelines
and the actual algorithm selection and hyper-parameter opti-
mization happens via random search.

3 An Optimization Perspective to AutoML

We focus on the joint algorithm selection and HPO for a ﬁxed
pipeline – a ML pipeline with a ﬁxed sequence of functional
modules (preprocessing → missing/categorical handling →
transformations → feature selection → modeling) with a set
of algorithm choices in each module – termed asthe CASH
(combined algorithm selection and HPO) problem (Thornton
et al. 2012; Feurer et al. 2015) and solved with toolkits such
as Auto-WEKA and Auto-sklearn. We extend this formula-
tion by explicitly expressing the combinatorial nature of the
algorithm selection with Boolean variables and constraints.

j=1 zij = 1

ij ∈ Cij ⊂ Rmc

We will also brieﬂy discuss how this formulation facilities
extension to other ﬂexible pipelines.
in module i, with the constraint 1(cid:62)zi = (cid:80)Ki
Problem statement. For N functional modules (e.g., pre-
processor, transformer, estimator) with a choice of Ki algo-
rithms in each, let zi ∈ {0, 1}Ki denote the algorithm choice
module. Let z = {z1 , . . . , zN }. Assuming that categorical
ensuring that only a single algorithm is chosen from each
hyper-parameters can be encoded as integers (using standard
techniques), let θ ij be the hyper-parameters of algorithm j
in module i, with θc
ij as the continuous hyper-
parameters (constrained to the set Cij ) and θd
as the integer hyper-parameters (constrained to Dij ). Condi-
tional hyper-parameters can be handled with additional con-
straints θ ij ∈ Eij or by “ﬂattening” the hyper-parameter tree
and considering each leaf as a different algorithm. For sim-
plicity of exposition, we assume that the conditional hyper-
parameters are ﬂattened into additional algorithm choices.
for n ∈ N. Let f (z, θ ; A) represent some notion of loss
of a ML pipeline corresponding to the algorithm choices as
per z with the hyper-parameters θ on a learning task with
data A (such as the k-fold cross-validation or holdout valida-
tion loss). The optimization problem of automatic pipeline
conﬁguration is stated as:

Let θ = {θ ij , ∀i ∈ [N ], j ∈ [Ki ]}, where [n] = {1, . . . , n}

ij ∈ Dij ⊂ Zmd

ij

(cid:26) zi ∈ {0, 1}Ki , 1(cid:62) zi = 1, ∀i ∈ [N ],
f (z, θ ; A)
ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ].
θc

ij ∈ Cij , θd

min

z,θ

subject to

(1)

AutoML with black-box constraints. With the increas-

We highlight 2 key differences of problem (1) from the
conventional CASH formulation: (i) we use explicit Boolean
variables z to encode the algorithm selection, (ii) we differ-
entiate continuous variables/constraints from discrete ones
for a possible efﬁcient decomposition between continuous
optimization and integer programming. These features better
characterize the properties of the problem and thus enable
data A, the objective (loss) function f (z, θ ; A) is a black-
more effective joint optimization. For any given (z, θ) and
box function – it does not have an analytic form with respect
to (z, θ) (hence no derivatives). The actual evaluation of f
usually involves training, testing and scoring the ML pipeline
corresponding to (z, θ) on some split of the data A.
ing adoption of AutoML, the formulation (1) may not be
sufﬁcient. AutoML may need to ﬁnd ML pipelines with high
predictive performance (low loss) that also explicitly sat-
isfy application speciﬁc constraints. Deployment constraints
may require the pipeline to have prediction latency or size
in memory below some threshold (latency ≤ 10µs, mem-
ory ≤ 100MB). Business speciﬁc constraints may desire
pipelines with low overall classiﬁcation error and an explicit
upper bound on the false positive rate – in a loan default risk
application, false positives leads to loan denials to eligible
candidates, which may violate regulatory requirements. In
the quest for fair AI, regulators may explicitly require the
ML pipeline to be above some predeﬁned fairness threshold
(Friedler et al. 2019). Furthermore, many applications have
very domain speciﬁc metric(s) with corresponding constraints
– custom metrics are common in Kaggle competitions. We
incorporate such requirements by extending AutoML formu-
lation (1) to include M black-box constraints:

gi (z, θ ; A) ≤ i , i ∈ [M ].

(2)

These functions have no analytic form with respect to (z, θ),
in constrast to the analytic constraints in problem (1). One ap-
tive becomes f + (cid:80)
proach is to incorporate these constraints into the black-box
objective with a penalty function p, where the new objec-
i p(gi , i ). However,
these schemes are very sensitive to the choice of the penalty
function and do not guarantee feasible solutions.

i p(gi , i ) or f · (cid:81)

Generalization for more ﬂexible pipelines. We can ex-

tend the problem formulation (1) to enable optimization over
the ordering of the functional modules. For example, we can
choose between ‘preprocessor → transformer → feature se-
lector’ OR ‘feature selector → preprocessor → transformer’.
The ordering of T ≤ N modules can be optimized by in-
troducing T 2 Boolean variables o = {oik : i, k ∈ [T ]},
where oik = 1 indicates that module i is placed at po-
a single position, and (ii) (cid:80)
sition k . The following constraints are then needed: (i)
k∈[T ] oik = 1, ∀i ∈ [T ] indicates that module i is placed at
can be added to z in problem (1) (z = {z1 , . . . , zN , o}).
that only one module is placed at position k . These variables
The resulting formulation still obeys the generic form of (1),
which as will be evident later, can be efﬁciently solved by an
operator splitting framework like ADMM (Boyd et al. 2011).

(cid:80)

i∈[T ] oik = 1∀k ∈ [T ] enforces

4 ADMM-Based Joint Optimizer

ADMM provides a general effective optimization framework
to solve complex problems with mixed variables and multiple
constraints (Boyd et al. 2011; Liu et al. 2018). We utilize this
framework to decompose problem (1) without and with black-
box constraints (2) into easier sub-problems.

4.1 Efﬁcient operator splitting for AutoML

In what follows, we focus on solving problem (1) with an-
alytic constraints. The handling of black-box constraints
will be elaborated on in the next section. Denoting θc =
ij , ∀i ∈ [N ], j ∈ [Ki ]} as all the continuous hyper-
parameters and θd (deﬁned correspondingly) as all the integer
hyper-parameters, we re-write problem (1) as:

{θc

min

z,θ={θc ,θd }

θc , θd(cid:111)
(cid:26) zi ∈ {0, 1}Ki , 1(cid:62) zi = 1, ∀i ∈ [N ],
f
z,
ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ].
θc

(cid:16)

(cid:110)

; A(cid:17)

subject to

ij ∈ Cij , θd

(3)

Introduction of continuous surrogate loss. With (cid:101)Dij

as the continuous relaxation of the integer space Dij (if
Dij includes integers ranging from {l, . . . , u} ⊂ Z, then
(cid:101)Dij = [l, u] ⊂ R), and (cid:101)θ
θd with (cid:101)θ ij ∈ (cid:101)Dij (corresponding to θ ij ∈ Dij ), we utilize a
surrogate loss function (cid:101)f for problem (3) deﬁned solely over
d as the continuous surrogates for
the continuous domain with respect to θ :
where PD ((cid:101)θ
This projection is necessary since the black-box function
projection of the continuous surrogates onto the integer set.
is deﬁned (hence can only be evaluated) on the integer sets

(cid:101)f

(cid:16)

z,

(cid:110)

θc , (cid:101)θ

d(cid:111)

; A(cid:17)

:= f

(cid:16)

z,

(cid:110)

θc , PD

(cid:16)(cid:101)θ

d(cid:17)(cid:111)

; A(cid:17)

,

(4)

d

) = {PDij ((cid:101)θ

d

ij ), ∀i ∈ [N ], j ∈ [Ki ]} is the

Dij s. Ergo, problem (3) can be equivalently posed as

min

z,θc ,(cid:101)θ

d

,δ

(cid:101)f
(cid:16)


θc , (cid:101)θ
z,
zi ∈ {0, 1}Ki , 1(cid:62) zi = 1, ∀i ∈ [N ]
ij ∈ Cij , (cid:101)θ
ij ∈ (cid:101)Dij , ∀i ∈ [N ], j ∈ [Ki ]
θc
δ ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ]
ij = δ ij , ∀i ∈ [N ], j ∈ [Ki ],

(cid:110)

d(cid:111)

; A(cid:17)

subject to

d

(cid:101)θ

d

(5)

tablished by the equality constraint (cid:101)θ
where the equivalence between problems (3) & (5) is es-
plying PDij ((cid:101)θ
d }; A). The continuous surrogate loss (4) is key
in being able to perform theoretically grounded operator split-
ting (via ADMM) over mixed continuous/integer variables in
the AutoML problem (3).
IX (x) = 0 if x ∈ X else +∞, and deﬁning the sets Z =

d

ij ∈ Dij and (cid:101)f (z, {θc , (cid:101)θ
ij = δ ij ∈ Dij , im-
d }; A) =

d

ij ) = (cid:101)θ

d

f (z, {θc , (cid:101)θ

Operator splitting from ADMM. Using the notation that

{z : z = {zi }, zi ∈ {0, 1}Ki , 1(cid:62)zi = 1, ∀i ∈ [N ]}, C =
{δ : δ = {δ ij }, δ ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ]} and (cid:101)D =
{θc : θc = {θc
ij }, θc
ij ∈ Cij , ∀i ∈ [N ], j ∈ [Ki ]}, D =
: (cid:101)θ
ij }, (cid:101)θ
ij ∈ (cid:101)Dij , ∀i ∈ [N ], j ∈ [Ki ]}, we can

{(cid:101)θ

d

d

= {(cid:101)θ

d

d

re-write problem (5) as

min

z,θc ,(cid:101)θ

d

,δ

(cid:101)f

(cid:16)

z,

(cid:110)

θc , (cid:101)θ

d(cid:111)

; A(cid:17)

+ IZ (z) + IC (θc ) + I (cid:101)D ((cid:101)θ
= δ .

d

)

+ ID (δ); subject to (cid:101)θ

d

(6)

with the corresponding augmented Lagrangian function

L(z, θc , (cid:101)θ
+ I (cid:101)D ((cid:101)θ

d

, δ , λ) := (cid:101)f
) + ID (δ) + λ

(cid:16)

z,

(cid:110)
(cid:62) (cid:16)(cid:101)θ

θc , (cid:101)θ
d − δ

d(cid:111)

; A(cid:17)

+ IZ (z) + IC (θc )
d − δ

d

(cid:17)

+

ρ
2

(cid:13)(cid:13)(cid:13)(cid:101)θ

(cid:13)(cid:13)(cid:13)2

2

,

(7)

where λ is the Lagrangian multiplier, and ρ > 0 is a penalty
parameter for the augmented term.
ADMM (Boyd et al. 2011) alternatively minimizes the
augmented Lagrangian function (7) over two blocks of vari-
ables, leading to an efﬁcient operator splitting framework for
(1) by alternatively minimizing (7) over variables {θc , (cid:101)θ
nonlinear programs with nonsmooth objective function and
equality constraints. Speciﬁcally, ADMM solves problem
d},
problems over variables {θc , (cid:101)θ
and {δ , z}. This can be equivalently converted into 3 sub-
d }, δ and z, respectively. We
refer readers to Algorithm 1 for simpliﬁed sub-problems and
Appendix 11 for detailed derivation.
The rationale behind the advantage of ADMM is that it
decomposes the AutoML problem into sub-problems with
smaller number of variables: This is crucial in black-box op-
timization where convergence is strongly dependent on the
number of variables. For example, the number of black-box
evaluations needed for critical point convergence is typically
O(n ∼ n3 ) for n variables (Larson, Menickelly, and Wild
2019). In what follows, we show that the easier sub-problems
in Algorithm 1 yield great interpretation of the AutoML prob-
lem (1) and suggest efﬁcient solvers in terms of continuous
hyper-parameter optimization, integer projection operation,
and combinatorial algorithm selection.

1Appendices are at https://arxiv.org/pdf/1905.00424.pdf

Algorithm 1 Operator splitting from ADMM to solve problem (5)

(cid:110)

θc (t+1) , (cid:101)θ

d (t+1)(cid:111)

= arg min

θc ,(cid:101)θ

d

(cid:101)f
(cid:101)f

(cid:16)
(cid:16)

z(t) ,

(cid:110)

θc , (cid:101)θ
+ IC (θc ) + I (cid:101)D ((cid:101)θ
a := (cid:101)θ
ID (δ) + (ρ/2) (cid:107)a − δ(cid:107)2
2 ,
+ IZ (z),

d(cid:111)

; A(cid:17)

d

) + (ρ/2)

(cid:13)(cid:13)(cid:13)(cid:101)θ

d − b

(cid:13)(cid:13)(cid:13)2

2

, b := δ (t) − 1
ρ

λ(t) ,

(θ-min)

δ (t+1) = arg min

δ

d (t+1) + (1/ρ)λ(t) ,

(δ -min)

z(t+1) = arg min

z

z,

(cid:110)

θc (t+1) , (cid:101)θ

d (t+1)(cid:111)

; A(cid:17)

(z-min)

where (t) represents the iteration index, and the Lagrangian multipliers λ are updated as λ(t+1) = λ(t) + ρ((cid:101)θ
is a black-box integer program solved exactly with (cid:81)N
evaluations of (cid:101)f . However, this is generally not feasible.
Beyond random sampling, there are a few ways to lever-
age existing AutoML schemes: (i) Combinatorial multi-
armed bandits. – Problem (12) can be interpreted through
arms (in this case, algorithms) from (cid:80)N
combinatorial bandits as the selection of the optimal N
i=1 Ki arms based
on bandit feedback and can be efﬁciently solved with
Thompson sampling (Durand and Gagné 2014) (ii) Multi-
ﬁdelity approximation of black-box evaluations – Techniques
such as successive halving (Jamieson and Talwalkar 2016;
discrete set of (cid:81)N
Li et al. 2018) or incremental data allocation (Sabharwal,
Samulowitz, and Tesauro 2016) can efﬁciently search over a
i=1 Ki candidates. (iii) Genetic algorithms
– Genetic programming can perform this discrete black-box
optimization starting from a randomly generated population
and building the next generation based on the ‘ﬁtness’ of the
pipelines and random ‘mutations’ and ‘crossovers’.

d

(t+1) − δ (t+1) ).

Solving θ-min. Problem (θ-min) can be rewritten as

min

θc ,(cid:101)θ

d

(cid:101)f

(cid:16)

z(t) ,

(cid:110)
(cid:101)θ

θc , (cid:101)θ
(cid:26) θc
ij ∈ (cid:101)Dij ,

d(cid:111)

; A(cid:17)

+

ρ
2
∀i ∈ [N ], j ∈ [Ki ],

(cid:13)(cid:13)(cid:13)(cid:101)θ

d − b

(cid:13)(cid:13)(cid:13)2

2

subject to

ij ∈ Cij
d

(8)

where both θc and (cid:101)θ
d are continuous optimization vari-
this problem, (cid:101)f in problem (8) only depends on the hyper-
ables. Since the algorithm selection scheme z(t) is ﬁxed for
parameters of the chosen algorithms – the active set of con-
tinuous variables (θc
(t) = 1. This splits
problem reduces to the following for all i ∈ [N ], j ∈ [Ki ]
problem (8) even further into two problems. The inactive set
such that zij = 0:
which is solved by a Euclidean projection of bij onto (cid:101)Dij .
For the active set of variables S = {(θc

ij , (cid:101)θ

d

ij ) where zij

min(cid:101)θ

d
ij

ρ
2

(cid:107)(cid:101)θ

ij − bij (cid:107)2
d
2

subject to

(cid:101)θ

d

ij ∈ (cid:101)Dij ,

(9)

ij , (cid:101)θ
Cij , (cid:101)θ ij ∈ (cid:101)Dij , zij = 1, ∀i ∈ [N ], j ∈ [Ki ]}, problem (8)
ij ) : θc

d

ij ∈

reduces to the following black-box optimization with only
the small active set of continuous variables2

min

(θc ,(cid:101)θ

d

)∈S

(cid:101)f

(cid:16)

z(t) ,

(cid:110)

θc , (cid:101)θ

d(cid:111)

; A(cid:17)

+

ρ
2

(cid:13)(cid:13)(cid:13)(cid:101)θ

d − b

(cid:13)(cid:13)(cid:13)2

2

.

(10)

The above problem can be solved using Bayesian optimiza-
tion (Shahriari et al. 2016), direct search (Larson, Menickelly,
and Wild 2019), or trust-region based derivative-free opti-
mization (Conn, Scheinberg, and Vicente 2009).
Solving δ -min. According to the deﬁnition of D , problem
(δ -min) can be rewritten as
and solved in closed form by projecting a onto (cid:101)D and then
rounding to the nearest integer in D .
Solving z-min. Problem (z-min) rewritten as

min

δ

ρ
2

(cid:107)δ − a(cid:107)2

2

subject to δ ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ],

(11)

min
z,
subject to zi ∈ {0, 1}Ki , 1(cid:62) zi = 1, ∀i ∈ [N ]
ij | + |(cid:101)θ

z

(cid:101)f

(cid:16)

(cid:110)

θc (t+1) , (cid:101)θ

d (t+1)(cid:111)

; A(cid:17)

(12)

2For the AutoML problems we consider in our empirical evalu-
tations, |θ | = |θc
ij | ≈ 100 while the largest possible active
set S is less than 15 and typically less than 10.

d

i=1 Ki

4.2 ADMM with black-box constraints

We next consider problem (3) in the presence of black-box
constraints (2). Without loss of generality, we assume that
i ≥ 0 for i ∈ [M ]. By introducing scalars ui ∈ [0, i ], we
can reformulate the inequality constraint (2) as the equality
constraint together with a box constraint
(cid:101)gi for gi , ∀i ∈ [M ] in a similar manner to (cid:101)f given by (4).
We then introduce a continuous surrogate black-box functions
Following the reformulation of (3) that lends itself to the
application of ADMM, the version with black-box constraints
(13) can be equivalently transformed into

gi

(cid:16)

z,

(cid:110)

θc , θd(cid:111)

; A(cid:17) − i + ui , ui ∈ [0, i ], i ∈ [M ].

(13)

min

z,θc ,(cid:101)θ

d

,δ

(cid:101)f
(cid:16)


θc , (cid:101)θ
z,
zi ∈ {0, 1}Ki , 1(cid:62) zi = 1, ∀i ∈ [N ]
ij ∈ Cij , (cid:101)θ
ij ∈ (cid:101)Dij , ∀i ∈ [N ], j ∈ [Ki ]
δ ij ∈ Dij , ∀i ∈ [N ], j ∈ [Ki ]
θc
ij = δ ij , ∀i ∈ [N ], j ∈ [Ki ]
; A(cid:17) − i + ui = 0, ∀i ∈ [M ].
ui ∈ [0, i ], ∀i ∈ [M ]
(cid:101)gi
θc , (cid:101)θ
z,

(cid:110)

d(cid:111)

; A(cid:17)

subject to

d

(cid:101)θ

d

(cid:16)

(cid:110)

d(cid:111)

(14)

Compared to problem (5), the introduction of auxiliary vari-
ables {ui } enables ADMM to incorporate black-box equality
constraints as well as elementary white-box constraints. Sim-
ilar to Algorithm 1, the ADMM solution to problem (14) can
be achieved by solving three sub-problems of similar nature,
summarized in Algorithm 2 and derived in Appendix 2.

Algorithm 2 Operator splitting from ADMM to solve problem (14) (with black-box constraints)

(cid:110)

θc (t+1) , (cid:101)θ

d (t+1) , u(t+1)(cid:111)

= arg min

θc ,(cid:101)θ

d

,u

δ (t+1) = arg min

δ

z(t+1) = arg min

z

(cid:13)(cid:13)(cid:13)(cid:101)θ

d − b

(cid:101)f +
+ IC (θc ) + I (cid:101)D ((cid:101)θ
ρ
2
ρ
2 + ID (δ),
(cid:20)(cid:101)gi − i + ui
(cid:101)f + IZ (z) +
2

(cid:107)δ − a(cid:107)2

(cid:13)(cid:13)(cid:13)2
M(cid:88)

2

ρ
2

i=1

(t+1) +

d

) + IU (u) +

ρ
2

,

(cid:21)2

1
ρ

(t)

µi

(cid:20)(cid:101)gi + ui − i +

(cid:21)2

,

(t)

µi
ρ

M(cid:88)

i=1

where the arguments of ˜f and ˜gi are omitted for brevity, a and b have been deﬁned in Algorithm 1, U = {u : u = {ui},
and µi is the Lagrangian multiplier corresponding to the equality constraint ˜gi − i + ui = 0 in (14) and updated as

(t) + ρ((cid:101)gi (z(t+1) , {θc (t+1) , (cid:101)θ

µi

(t+1) = µi

d

(t+1) }; A) − i + ui

(t+1) ) for ∀i ∈ [M ].

4.3 Implementation and convergence

We highlight that our ADMM based scheme is not a single
AutoML algorithm but rather a framework that can be used
to mix and match different existing black-box solvers. This
is especially useful since this enables the end-user to plug-
in efﬁcient solvers tailored for the sub-problems (HPO &
algorithm selection in our case). In addition to the above,
the ADMM decomposition allows us to solve simpler sub-
problems with a smaller number of optimization variables
(a signiﬁcantly reduced search space since (θ-min) only re-
quires optimization over the active set of continuous vari-
ables). Unless speciﬁed otherwise, we adopt Bayesian opti-
mization (BO) to solve the HPO (θ-min), e.g., (10). We use
customized Thompson sampling to solve the combinatorial
multi-armed bandit problem, namely, the (z-min) for algo-
rithm selection. We refer readers to Appendix 3 and 4 for
more derivation and implementation details. In Appendix 5,
we demonstrate the generalizability of ADMM to different
solvers for (θ-min) and (z-min).The theoretical convergence
guarantees of ADMM have been established under certain
assumptions, e.g., convexity or smoothness (Boyd et al. 2011;
Hong and Luo 2017; Liu et al. 2018). Unfortunately, the Au-
toML problem violates these restricted assumptions. Even for
non-ADMM based AutoML pipeline search, there is no the-
oretical convergence established in the existing baselines to
the best of our knowledge. Empirically, we will demonstrate
the improved convergence of the proposed scheme against
baselines in the following section.

5 Empirical Evaluations

In this evaluation of our proposed framework, we demon-
strate three important characteristics: (i) the empirical per-
formance against existing AutoML toolkits, highlighting the
empirical competitiveness of the theoretical formalism, (ii)
the systematic capability to handle black-box constraints,
enabling AutoML to address real-world ML tasks, and (iii)
the ﬂexibility to incorporate various learning procedures and
solvers for the sub-problems, highlighting that our proposed
scheme is not a single algorithm but a complete framework
for AutoML pipeline conﬁguration.

Data and black-box objective function. We consider 30 bi-

nary classiﬁcation3 datasets from the UCI ML (Asuncion and

Newman 2007) & OpenML repositories (Bischl et al. 2017),
and Kaggle. We consider a subset of OpenML100 limited to
binary classiﬁcation and small enough to allow for meaning-
ful amount of optimization for all baselines in the allotted 1
hour to ensure that we are evaluating the optimizers and not
the initialization heuristics. Dataset details are in Appendix
6. We consider (1 − AUROC) (area under the ROC curve)
as the black-box objective and evaluate it on a 80-20% train-
validation split for all baselines. We consider AUROC since
it is a meaningful predictive performance metric regardless
of the class imbalance (as opposed to classiﬁcation error).

Comparing ADMM to AutoML baselines. Here we eval-

uate the proposed ADMM framework against widely used
AutoML systems Auto-sklearn (Feurer et al. 2015) and TPOT
(Olson and Moore 2016). This comparison is limited to black-
box optimization with analytic constraints only given by (1)
since existing AutoML toolkits cannot handle black-box con-
straints explicitly. We consider SMAC based vanilla Auto-
sklearn ASKL4 (disabling ensembles and meta-learning),
random search RND, and TPOT with a population of 50
(instead of the default 100) to ensure that TPOT is able to
process multiple generations of the genetic algorithm in the
allotted time on all data sets. For ADMM, we utilize BO for
(θ-min) and CMAB for (z-min) – ADMM(BO,Ba)5 .
For all optimizers, we use scikit-learn algorithms
(Pedregosa, Varoquaux, and others 2011). The functional
modules and the algorithms (with their hyper-parameters)
are presented in Table A3 in Appendix 7. We maintain par-
ity6 across the various AutoML baselines by searching over
the same set of algorithms
(see Appendix 7). For each

3 Our scheme applies to multiclass classiﬁcation & regression.
4 Meta-learning and ensembling in ASKL are preprocessing and
postprocessing steps respectively to the actual black-box optimiza-
tion and can be applied to any optimizer. We demonstrate this for
ADMM in Appendix 8. So we skip these aspects of ASKL here.
5 In this setup, ADMM has 2 parameters: (i) the penalty ρ on
the augmented term, (ii) the loss upper-bound ˆf in the CMAB
algorithm (Appendix 4). We evaluate the sensitivity of ADMM on
these parameters in Appendix 9. The results indicate that ADMM is
fairly robust to these parameters, and hence set ρ = 1 and ˆf = 0.7
throughout. We start the ADMM optimization with λ(0) = 0.
6ASKL and ADMM search over the same search space of ﬁxed
pipeline shape & order. TPOT also searches over different pipeline

(a) All methods

(a) Varying tp , dI = 0.07

(b) Varying dI , tp = 10µs

Figure 2: Best objective achieved by any constraint satisfying
pipeline from running the optimization for 1 hour seconds with
varying thresholds for the two constraints – lower is better (please
view in color). Note the log-scale on the vertical axis.

(b) ASKL vs. ADMM

(c) TPOT50 vs. ADMM

Figure 1: Average rank (across 30 datasets) of mean performance
across 10 trials – lower rank is better.

scheme, the algorithm hyper-parameter ranges are set us-
ing Auto-sklearn as the reference7 . We optimize for 1 hour
& generate time vs. incumbent black-box objective curves
aggregated over 10 trials. Details on the complete setup are
in Appendix 10. The optimization convergence for all 30
datasets are in Appendix 11. At completion, ASKL achieves
the lowest mean objective (across trials) in 6/30 datasets,
TPOT50 in 8/30, RND in 3/30 and ADMM(BO,Ba) in 15/30,
showcasing ADMM’s effectiveness.
Figure 1 presents the overall performance of the different
AutoML schemes versus optimization time. Here we consider
the relative rank of each scheme (with respect to the mean
objective over 10 trials) for every timestamp, and average
this rank across 30 data sets similar to the comparison in
Feurer et al. (2015). With enough time, all schemes outper-
form random search RND. TPOT50 performs worst in the
beginning because of the initial start-up time involved in the
genetic algorithm. ASKL and ADMM(BO,Ba) have compa-
rable performance initially. As the optimization continues,
ADMM(BO,Ba) signiﬁcantly outperforms all other baselines.
We present the pairwise performance of ADMM with ASKL
(ﬁgure 1b) & TPOT50 (ﬁgure 1c).

AutoML with black-box constraints. To demonstrate the

capability of the ADMM framework to incorporate real-world
black-box constraints, we consider the recent Home Credit
Default Risk Kaggle challenge8 with the black-box objec-
tive of (1 − AUROC), and 2 black-box constraints: (i) (de-
ployment) Prediction latency tp enforcing real-time predic-
tions, (ii) (fairness) Maximum pairwise disparate impact
dI (Calders and Verwer 2010) across all loan applicant age
groups enforcing fairness across groups (see Appendix 12).

We run a set of experiments for each of the constraints:
(i) ﬁxing dI = 0.7, we optimize for each of the thresholds

tp = {1, 5, 10, 15, 20} (in µs), and (ii) ﬁxing tp = 10µs and
we optimize for each of dI = {0.05, 0.075, 0.1, 0.125, 0.15}.

Note that the constraints get less restrictive as the thresholds
increase. We apply ADMM to the unconstrained problem
(UCST) and post-hoc ﬁlter constraint satisfying pipelines to
demonstrate that these constraints are not trivially satisﬁed.
Then we execute ADMM with these constraints (CST). Using
BO for (θ-min) & CMAB for (z-min), we get two variants –
UCST(BO,Ba) & CST(BO,Ba). This results in (5 + 5) × 2 =
20 ADMM executions, each repeated 10×.
Figure 2 presents the objective achieved by the optimizer
when limited only to constraint satisfying pipelines. Figure
2a presents the effect of relaxing the constraint on tp while
Figure 2b presents the same for the constraint on dI . As
expected, the objective improves as the constraints relax. In
both cases, CST outperforms UCST, with UCST approaching
CST as the constraints relax. Figure 3 presents the constraint
satisfying capability of the optimizer by considering the frac-
tion of constraint-satisfying pipelines found (Figure 3a & 3b
for varying tp & dI respectively). CST again signiﬁcantly out-
performs UCST, indicating that the constraints are non-trivial
to satisfy, and that ADMM is able to effectively incorporate
the constraints for improved performance.

Flexibility & beneﬁts from ADMM operator splitting. It

is common in ADMM to solve the sub-problems to higher
approximation in the initial iterations and to an increasingly

(a) Varying tp , dI = 0.07

(b) Varying dI , tp = 10µs

shapes & orderings because of the nature of its genetic algorithm.

7 github.com/automl/auto- sklearn/tree/master/autosklearn/pipeline/components
8www.kaggle.com/c/home- credit- default- risk

Figure 3: Fraction of pipelines found satisfying constraints with
optimization for 1 hour with varying thresholds for the 2 constraints
– higher is better. Note the log-scale on the vertical axis.

Figure 4: Optimization time (in seconds) vs. median validation
performance with the inter-quartile range over 10 trials on fri-c2
dataset – lower is better (please view in color). Note the log scale
on both axes. See Appendix 13 for additional results.

Figure 5: Optimization time vs. median validation performance with
the inter-quartile range over 10 trials on fri-c2 dataset – lower is
better (please view in color). Note the log scale on both axes. See
Appendix 14 for additional results.

lower approximation as ADMM progresses (instead of the
same approximation throughout) (Boyd et al. 2011). We
demonstrate (empirically) that this adaptive ADMM produces
expected gains in the AutoML problem. Moreover, we show
the empirical gains of ADMM from (i) splitting the AutoML
problem (1) into smaller sub-problems which are solved in
an alternating fashion, & (ii) using different solvers for the
differently structured (θ-min) and (z-min).
First we use BO for both (θ-min) and (z-min). For
ADMM with a ﬁxed approximation level (ﬁxed ADMM),
we solve the sub-problems with BO to a ﬁxed number
I = 16, 32, 64, 128 iterations, denoted by ADMMI (BO,BO)
(e.g., ADMM16(BO,BO)). For adaptive ADMM, we start
with 16 BO iterations for the sub-problems and progres-
sively increase it with an additive factor F = 8 & 16 with
every ADMM iteration until 128 denoted by AdADMM-
F8(BO,BO) & AdADMM-F16(BO,BO) respectively. We op-
timize for 1 hour and aggregate over 10 trials.
Figure 4 presents optimization convergence for 1 dataset
(fri-c2). We see the expected behavior – ﬁxed ADMM with
small I dominate for small time scales but saturate soon;
large I require signiﬁcant start-up time but dominate for
larger time scales. Adaptive ADMM (F = 8 & 16) is able
to match the performance of the best ﬁxed ADMM at every
time scale.Please refer to Appendix 13 for additional results.
Next, we illustrate the advantage of ADMM on operator
splitting. We consider 2 variants, AdADMM-F16(BO,BO)
and AdADMM-F16(BO,Ba), where the latter uses CMAB
for (z-min). For comparison, we solve the complete joint
problem (1) with BO, leading to a Gaussian Process with a
large number of variables, denoted as JOPT(BO).
Figure 5 shows the optimization convergence for 1 dataset
(fri-c2). The results indicate that the operator splitting in
ADMM provides signiﬁcant improvements over JOPT(BO),
with ADMM reaching the ﬁnal objective achieved by JOPT
with signiﬁcant speedup, and then further improving upon
that ﬁnal objective signiﬁcantly. These improvements of
ADMM over JPOT on 8 datasets are summarized in Table 1,
indicating signiﬁcant speedup (over 10× in most cases) and
further improvement (over 10% in many cases).
Let us use SBa and SBO to represent the temporal speedup
achieved by AdADMM(BO,Ba) and AdADMM(BO,BO)

Dataset
Bank8FM
CPU small
fri-c2
PC4
Pollen
Puma8NH
Sylvine
Wind

SBa SBO

IBa

IBO

4×

10×
0%
5%
153× 25× 56% 64%
0%
5%
42×
8% 13%
25×
4%
3%
11×
1%
1%
9% 26%
40×
0%
5%

2×
5×
5×
7×
4×
2×
5×

9×

Table 1: Comparing ADMM schemes to JOPT(BO), we list
the speedup SBa & SBO achieved by AdADMM(BO,Ba) &
AdADMM(BO,BO) respectively to reach the best objective of JOPT,
and the ﬁnal objective improvement IBa & IBO (respectively) over
the JOPT objective. These numbers are generated using the aggre-
gate performance of JOPT and AdADMM over 10 trials.

(eliding “-F16”) respectively to reach the best objective of
JOPT, and similarly use IBa and IBO to represent the objec-
tive improvement at the ﬁnal converged point. Table 1 shows
that between AdADMM(BO,BO) and AdADMM(BO,Ba),
the latter provides signiﬁcantly higher speedups, but the for-
mer provides higher additional improvement in the ﬁnal ob-
jective. This demonstrates ADMM’s ﬂexibility, for example,
allowing choice between faster or more improved solution.

6 Conclusions

Posing the problem of joint algorithm selection and HPO
for automatic pipeline conﬁguration in AutoML as a formal
mixed continuous-integer nonlinear program, we leverage
the ADMM optimization framework to decompose this prob-
lem into 2 easier sub-problems: (i) black-box optimization
with a small set of continuous variables, and (ii) a combinato-
rial optimization problem involving only Boolean variables.
These sub-problems can be effectively addressed by existing
AutoML techniques, allowing ADMM to solve the overall
problem effectively. This scheme also seamlessly incorpo-
rates black-box constraints alongside the black-box objective.
We empirically demonstrate the ﬂexibility of the proposed
ADMM framework to leverage existing AutoML techniques
and its effectiveness against open-source baselines.

References

[Agrawal and Goyal 2012] Agrawal, S., and Goyal, N. 2012.
Analysis of thompson sampling for the multi-armed bandit
problem. In Conference on Learning Theory, 39–1.
[Asuncion and Newman 2007] Asuncion, A., and Newman,
D. 2007. UCI ML Repository.
[Bergstra and Bengio 2012] Bergstra, J., and Bengio, Y. 2012.
Random search for hyper-parameter optimization. JMLR
13(Feb):281–305.
[Bergstra et al. 2011] Bergstra, J. S.; Bardenet, R.; Bengio,
Y.; and Kégl, B. 2011. Algorithms for hyper-parameter
optimization. In NeurIPS.
[Bischl et al. 2017] Bischl, B.; Casalicchio, G.; Feurer, M.;
Hutter, F.; Lang, M.; Mantovani, R. G.; van Rijn, J. N.; and
Vanschoren, J. 2017. OpenML benchmarking suites and the
OpenML100. arXiv:1708.03731.
[Boyd et al. 2011] Boyd, S.; Parikh, N.; Chu, E.; Peleato, B.;
Eckstein, J.; et al. 2011. Distributed optimization and sta-
tistical learning via the alternating direction method of mul-
tipliers. Foundations and Trends R(cid:13) in Machine Learning
3(1):1–122.
[Calders and Verwer 2010] Calders, T., and Verwer, S. 2010.
Three naive bayes approaches for discrimination-free classi-
ﬁcation. Data Mining and Knowledge Discovery 21(2):277–
292.
[Caruana et al. 2004] Caruana, R.; Niculescu-Mizil, A.; Crew,
G.; and Ksikes, A. 2004. Ensemble selection from libraries
of models. In ICML.
[Chen, Wu, and others 2018] Chen, B.; Wu, H.; et al. 2018.
Autostacker: A compositional evolutionary learning system.
In Proceedings of the Genetic and Evolutionary Computation
Conference, 402–409. ACM.
[Conn, Scheinberg, and Vicente 2009] Conn, A. R.; Schein-
berg, K.; and Vicente, L. N. 2009. Introduction to derivative-
free optimization. SIAM.
[Costa and Nannicini 2018] Costa, A., and Nannicini, G.
2018. Rbfopt: an open-source library for black-box opti-
mization with costly function evaluations. Mathematical
Programming Computation 10(4).
[Drori, Krishnamurthy, and others 2018] Drori, I.; Krishna-
murthy, Y.; et al. 2018. Alphad3m: Machine learning pipeline
synthesis. In AutoML Workshop at ICML.
[Durand and Gagné 2014] Durand, A., and Gagné, C. 2014.
Thompson sampling for combinatorial bandits and its appli-
cation to online feature selection. In AAAI Workshops.
[Falkner, Klein, and Hutter 2018] Falkner, S.; Klein, A.; and
Hutter, F. 2018. BOHB: Robust and efﬁcient hyperparameter
optimization at scale. In ICML.
[Feurer et al. 2015] Feurer, M.; Klein, A.; Eggensperger, K.;
Springenberg, J.; Blum, M.; and Hutter, F. 2015. Efﬁcient
and robust automated machine learning. In NeurIPS.
[Friedler et al. 2019] Friedler, S. A.; Scheidegger, C.;
Venkatasubramanian, S.; Choudhary, S.; Hamilton, E. P.; and
Roth, D. 2019. A comparative study of fairness-enhancing
interventions in machine learning.
In Proceedings of the
Conference on Fairness, Accountability, and Transparency,
329–338. ACM.

[Hong and Luo 2017] Hong, M., and Luo, Z.-Q. 2017. On
the linear convergence of the alternating direction method of
multipliers. Mathematical Programming 162(1):165–199.
[Hutter, Hoos, and Leyton-Brown 2011] Hutter, F.; Hoos,
H. H.; and Leyton-Brown, K. 2011. Sequential Model-
based Optimization for General Algorithm Conﬁguration. In
International Conference on Learning and Intelligent Opti-
mization. Springer-Verlag.
[Jamieson and Talwalkar 2016] Jamieson, K., and Talwalkar,
A. 2016. Non-stochastic best arm identiﬁcation and hyperpa-
rameter optimization. In AISTATS.
[Komer, Bergstra, and Eliasmith 2014] Komer, B.; Bergstra,
J.; and Eliasmith, C. 2014. Hyperopt-sklearn: automatic
hyperparameter conﬁguration for scikit-learn. In ICML work-
shop on AutoML.
[Kotthoff et al. 2017] Kotthoff, L.; Thornton, C.; Hoos, H. H.;
Hutter, F.; and Leyton-Brown, K. 2017. Auto-weka 2.0:
Automatic model selection and hyperparameter optimization
in weka. JMLR.
[Larson, Menickelly, and Wild 2019] Larson, J.; Menickelly,
M.; and Wild, S. M. 2019. Derivative-free optimization
methods. Acta Numerica 28:287–404.
[Li et al. 2018] Li, L.; Jamieson, K.; DeSalvo, G.; Ros-
tamizadeh, A.; and Talwalkar, A. 2018. Hyperband: A
novel bandit-based approach to hyperparameter optimization.
JMLR 18(185):1–52.
[Liu et al. 2018] Liu, S.; Kailkhura, B.; Chen, P.-Y.; Ting, P.;
Chang, S.; and Amini, L. 2018. Zeroth-order stochastic
variance reduction for nonconvex optimization. In NeurIPS.
[Mohr, Wever, and Hüllermeier 2018] Mohr, F.; Wever, M.;
and Hüllermeier, E. 2018. ML-Plan: Automated machine
learning via hierarchical planning. Machine Learning 107(8-
10):1495–1515.
[Olson and Moore 2016] Olson, R. S., and Moore, J. H. 2016.
TPOT: A tree-based pipeline optimization tool for automating
machine learning. In Workshop on AutoML.
[Pedregosa, Varoquaux, and others 2011] Pedregosa,
F.;
Varoquaux, G.; et al. 2011. Scikit-learn: Machine learning in
Python. JMLR.
[Rakotoarison, Schoenauer, and Sebag 2019] Rakotoarison,
H.; Schoenauer, M.; and Sebag, M. 2019. Automated
Machine Learning with Monte-Carlo Tree Search. In IJCAI.
[Sabharwal, Samulowitz, and Tesauro 2016] Sabharwal, A.;
Samulowitz, H.; and Tesauro, G. 2016. Selecting near-
optimal learners via incremental data allocation. In AAAI.
[Shahriari et al. 2016] Shahriari, B.; Swersky, K.; Wang, Z.;
Adams, R. P.; and De Freitas, N. 2016. Taking the human out
of the loop: A review of bayesian optimization. Proceedings
of the IEEE.
[Snoek, Larochelle, and Adams 2012] Snoek, J.; Larochelle,
H.; and Adams, R. P. 2012. Practical bayesian optimization
of machine learning algorithms. In NeurIPS.
[Thornton et al. 2012] Thornton, C.; Hoos, H. H.; Hutter, F.;
and Leyton-Brown, K. 2012. Auto-weka: Automated se-
lection and hyper-parameter optimization of classiﬁcation
algorithms. arXiv:1208.3719.

[Vanschoren 2018] Vanschoren, J. 2018. Meta-learning: A
survey. arXiv:1810.03548.
[Williams and Rasmussen 2006] Williams, C. K., and Ras-
mussen, C. E. 2006. Gaussian processes for machine learn-
ing. MIT Press Cambridge, MA.
[Zhu et al. 1997] Zhu, C.; Byrd, R. H.; Lu, P.; and Nocedal,
J. 1997. Algorithm 778: L-bfgs-b: Fortran subroutines for
large-scale bound-constrained optimization. ACM TOMS
23(4):550–560.

Appendices of ‘An ADMM Based Framework for AutoML Pipeline Conﬁgurations’
1 Derivation of ADMM sub-problems in Table 1

ADMM decomposes the optimization variables into two blocks and alternatively minimizes the augmented Lagrangian function
(7) in the following manner at any ADMM iteration t

(cid:110)

θc (t+1) , (cid:101)θ
d (t+1)(cid:111)
δ (t+1) , z(t+1)(cid:111)
d (t+1)(cid:111)
λ(t+1) = λ(t) + ρ

= arg min

θc ,(cid:101)θ

d

L (cid:16)
L (cid:16)
(cid:16)(cid:101)θ
d(cid:111)

z(t) , θc , (cid:101)θ
z, θc (t+1) , (cid:101)θ

, δ (t) , λ(t)(cid:17)
d
d (t+1) , δ , λ(t)(cid:17)
d (t+1) − δ (t+1)(cid:17)

(A15)

(cid:110)

= arg min

δ ,z

(A16)

.
+ IC (θc ) + I (cid:101)D ((cid:101)θ
d − δ (t)(cid:13)(cid:13)(cid:13)2
ρ
+
+ IC (θc ) + I (cid:101)D ((cid:101)θ
2

(A17)

Problem (A15) can be simpliﬁed by removing constant terms to get

(cid:110)

θc (t+1) , (cid:101)θ

= arg min

θc ,(cid:101)θ

d

(cid:101)f

(cid:16)

z(t) ,

(cid:110)

θc , (cid:101)θ
+ λ(t)(cid:62) (cid:16)(cid:101)θ
θc , (cid:101)θ
where b = δ (t) − 1
ρ
+ ID (δ) + λ(t)(cid:62) (cid:16)(cid:101)θ
z,
z,

; A(cid:17)
; A(cid:17)

d

)

(A18)

d − δ (t)(cid:17)

(cid:13)(cid:13)(cid:13)(cid:101)θ

2

,

= arg min

θc ,(cid:101)θ

d

(cid:101)f

(cid:16)

z(t) ,

(cid:110)

d(cid:111)

d

) +

ρ
2

(cid:13)(cid:13)(cid:13)(cid:101)θ

d − b

(cid:13)(cid:13)(cid:13)2

2

(A19)

λ(t) .
d (t+1)(cid:111)
d (t+1)(cid:111)
d (t+1) − δ

A similar treatment to problem (A16) gives us

(cid:110)

δ (t+1) , z(t+1)(cid:111)

= arg min

δ ,z

(cid:101)f
(cid:101)f

(cid:16)
(cid:16)

(cid:110)
(cid:110)

θc (t+1) , (cid:101)θ
θc (t+1) , (cid:101)θ

; A(cid:17)
; A(cid:17)

+ IZ (z)

(A20)

(cid:17)

+

ρ
2
+ IZ (z)

(cid:13)(cid:13)(cid:13)(cid:101)θ

d (t+1) − δ

(cid:13)(cid:13)(cid:13)2

2

,

= arg min

δ ,z

(A21)

+ ID (δ) +

ρ
2

(cid:107)a − δ(cid:107)2

2 where a = (cid:101)θ
2 where a = (cid:101)θ
(A22)
This simpliﬁcation exposes the independence between z and δ , allowing us to solve problem (A16) independently for z and δ as:

d (t+1) +

1
ρ

λ(t) .

δ (t+1) = arg min

δ

ID (δ) +

ρ
2

(cid:107)a − δ(cid:107)2

d (t+1) +

1
ρ

λ(t) ,

(A23)

z(t+1) = arg min

z

(cid:101)f

(cid:16)

z,

(cid:110)

θc (t+1) , (cid:101)θ

d (t+1)(cid:111)

; A(cid:17)

+ IZ (z).

(A24)

So we are able to decompose problem (3) into problems (A19), (A23) and (A24) which can be solved iteratively along with the
λ(t) updates (see Table 1).

(cid:3)

2 Derivation of ADMM sub-problems in Table 2

Deﬁning U = {u : u = {ui ∈ [0, i ]∀i ∈ [M ]}}, we can go through the mechanics of ADMM to get the augmented Lagrangian
with λ and µi∀i ∈ [M ] as the Lagrangian multipliers and ρ > 0 as the penalty parameter as follows:

L (cid:16)

z, θc , (cid:101)θ

d

, δ , u, λ, µ

(cid:17)

= (cid:101)f
+ λ

(cid:16)

z,

(cid:110)
d(cid:111)
(cid:62) (cid:16)(cid:101)θ
M(cid:88)
M(cid:88)
(cid:16)(cid:101)gi

θc , (cid:101)θ
d − δ

; A(cid:17)

+ IZ (z) + IC (θc ) + I (cid:101)D ((cid:101)θ
ρ
d − δ
; A(cid:17) − i + ui
2
θc , (cid:101)θ
; A(cid:17) − i + ui

d

) + ID (δ)

(cid:17)
(cid:16)(cid:101)gi
(cid:110)

+

(cid:13)(cid:13)(cid:13)(cid:101)θ
(cid:110)
d(cid:111)

(cid:13)(cid:13)(cid:13)2
d(cid:111)

2

IU (u) +

i=1

µi

(cid:16)

z,
θc , (cid:101)θ

(cid:17)

+

ρ
2

i=1

(cid:16)

z,

(cid:17)2

.

(A25)

ADMM decomposes the optimization variables into two blocks for alternate minimization of the augmented Lagrangian in the
following manner at any ADMM iteration t

(cid:110)

θc (t+1) , (cid:101)θ

(cid:110)

= arg min

d (t+1) , u(t+1)(cid:111)
δ (t+1) , z(t+1)(cid:111)
λ(t+1) = λ(t) + ρ

= arg min

θc ,(cid:101)θ

δ ,z

,u

d

∀i ∈ [M ], µi

(t+1) = µi

(t) + ρ

L (cid:16)
L (cid:16)
(cid:16)(cid:101)θ

z(t) , θc , (cid:101)θ
, δ (t) , u, λ(t) , µ(t)(cid:17)
z, θc (t+1) , (cid:101)θ

d
d (t+1) , δ , u(t+1) , λ(t) , µ(t)(cid:17)
d (t+1) − δ (t+1)(cid:17)
(cid:16)(cid:101)gi (z(t+1) , {θc (t+1) , (cid:101)θ

d (t+1) }; A) − i + ui

(A26)

(A27)

(A28)

(A29)

(t+1)(cid:17)

.

Note that, unlike the unconstrained case, the update of the augmented Lagrangian multiplier µi requires the evaluation of the
black-box function for the constraint gi .
Simplifying problem (A26) gives us

min

θc ,(cid:101)θ

d

,u

(cid:16)

(cid:101)f

z(t) ,

+

subject to

d(cid:111)

; A(cid:17)

(cid:110)
(cid:34)(cid:13)(cid:13)(cid:13)(cid:101)θ
 θc
(cid:101)θ

θc , (cid:101)θ
d − b
+
ij ∈ (cid:101)Dij ∀i ∈ [N ], j ∈ [Ki ],
ij ∈ Cij ∀i ∈ [N ], j ∈ [Ki ],
ui ∈ [0, i ],

(cid:20)(cid:101)gi

M(cid:88)

(cid:13)(cid:13)(cid:13)2

(cid:16)

z(t) ,

ρ
2

i=1

d

2

(cid:110)

θc , (cid:101)θ

d(cid:111)

; A(cid:17) − i + ui +
where b = δ (t) − 1
ρ

λ(t) ,

(cid:21)2(cid:35)

1
ρ

(t)

µi

(A30)

which can be further split into active and inactive set of continuous variables based on the z(t) as in the solution of problem
(A19) (the θ-min problem). The main difference from the unconstrained case in problem (A19) (the θ-min problem) to note here
is that the black-box optimization with continuous variables now has M new variables ui (M is the total number of black-box
constraints) which are active in every ADMM iteration. This problem (A30) can be solved in the same manner as problem (A19)
(θ-min) using SMBO or TR-DFO techniques.
Simplifying and utilizing the independence of z and δ , we can split problem (A27) into the following problem for δ
subject to δ ij ∈ Dij ∀i ∈ [N ], j ∈ [Ki ] where a = (cid:101)θ
which remains the same as problem (A23) (the δ -min problem) in the unconstrained case, while the problem for z becomes

(cid:107)δ − a(cid:107)2

d (t+1) +

(A31)

λ(t) ,

min

1
ρ

ρ
2

δ

2

min

z

d (t+1)}; A)

(cid:101)f (z, {θc (t+1) , (cid:101)θ
(cid:20)(cid:101)gi (z, {θc (t+1) , (cid:101)θ
ρ
d (t+1) }; A) − i + ui
+
2
subject to zi ∈ {0, 1}Ki , 1(cid:62)zi = 1, ∀i ∈ [N ].

M(cid:88)

i=1

(cid:21)2

(t+1) +

1
ρ

(t)

µi

(A32)

The problem for z is still a black-box integer programming problem, but now with an updated black-box function and can
be handled with techniques proposed for the combinatorial problem (A24) in the absence of black-box constraints (the z-min
problem).

(cid:3)

3 Bayesian Optimization for solving the (θ-min) problem on the active set

Problem (10) ((θ-min) on the active set) is a HPO problem. This can be solved with Bayesian optimization (BO) (Shahriari
black-box objective function f (θ) deﬁned on continuous variables θ ∈ C , BO assumes a statistical model, usually a Gaussian
et al. 2016). BO has become a core component of various AutoML systems (Snoek, Larochelle, and Adams 2012). For any
process (GP), for f . Based on the observed function values y = [f (θ (0) ), . . . , f (θ (t) )](cid:62) , BO updates the GP and determines the
next query point θ (t+1) by maximizing the expected improvement (EI) over the posterior GP model. Speciﬁcally the objective
f (θ) is modeled as a GP with a prior distribution f (·) ∼ N (µ(·), κ(·, ·)), where κ(·, ·) is a positive deﬁnite kernel. Given the
observed function values y, the posterior probability of a new function evaluation f (θ) at iteration t + 1 is modeled as a Gaussian
distribution with mean µ(θ) and variance σ2 (θ) (Shahriari et al. 2016, Sec. III-A), where

µ(ˆθ) = κ(cid:62) [Γ + σ2
n I]−1y

σ2 (ˆθ) = κ(ˆθ , ˆθ) − κ(cid:62) [Γ + σ2
n I]−1κ,

κ(θ (i) , θ (j ) ), and σ2

and
where κ is a vector of covariance terms between θ and {θ (i) }t
i=0 , and Γ denotes the covariance of {θ (i)}t
i=0 , namely, Γij =
n is a small positive number to model the variance of the observation noise.
Remark 1 To determine the GP model (A33), we choose the kernel function κ(·, ·) as the ARD Matérn 5/2 kernel (Snoek,
Larochelle, and Adams 2012; Shahriari et al. 2016),
for two vectors x, x(cid:48) , where r2 = (cid:80)d
i , and {τi }d
i=0 are kernel parameters. We determine the GP hyper-parameters
n} by minimizing the negative log marginal likelihood log p(y|ψ) (Shahriari et al. 2016),
minimize

κ(x, x(cid:48) ) = τ 2
0 exp(−
i=1 (xi−x(cid:48)
i )2 /τ 2

ψ = {{τi }d

i=0 , σ2

(A33)

(A34)

(A35)

√

√

5
r2 )
5r)(1 +
5r +
3
n I) + y(cid:62) (cid:0)Γ + σ2
n I(cid:1)−1
log det(Γ + σ2
y.
EI(θ) := (cid:0)y+ − f (θ)(cid:1) I (f (θ) ≤ y+ )
(cid:18) y+ − µ
(cid:18) y+ − µ
(y+ − µ)Φ
+ σφ
σ
σ

(cid:19)

(cid:19)

,

ψ

θ (t+1) = arg max

{θ∈C}

= arg max

{θ∈C}
where y+ = mini∈[t] f (θ (i) ), namely, the minimum observed value, I (f (θ) ≤ y+ ) = 1 if f (θ) ≤ y+ , and 0 otherwise
(indicating that the desired next query point θ should yield a smaller loss than the observed minimum loss), and µ & σ2 are
deﬁned in (A33), Φ denotes the cumulative distribution function (CDF) of the standard normal distribution, and φ is its probability
distribution function (PDF). This is true because substituting (A33) into (A36) allows us to simplify the EI acquisition function
as follows:

With the posterior model (A33), the desired next query point θ (t+1) maximizes the EI acquisition function

(A36)

(A37)

(cid:20)

f (cid:48)= f (θ)−µ

σ=

Ef (cid:48)

EI(θ)

= (y+ − µ)Φ

= (y+ − µ)Φ

(cid:19)(cid:21)

(cid:18)
(cid:20)

(cid:19)(cid:21)

f (cid:48)I

(cid:18)

(cid:18) y+ − µ
(y+ − f (cid:48)σ − µ)I
(cid:18) y+ − µ
σ
(cid:18) y+ − µ
σ
σ

f (cid:48) ≤ y+ − µ
σ
f (cid:48) ≤ y+ − µ
− σEf (cid:48)
σ
(cid:18) y+ − µ
f (cid:48)φ(f (cid:48) )df (cid:48)
σ

(cid:90) y+−µ
σ

(cid:19)
(cid:19)
(cid:19)

(cid:19)

− σ

−∞
where the last equality holds since (cid:82) xφ(x)dx = −φ(x) + C for some constant C . Here we omitted the constant C since it does
not affect the solution to the EI maximization problem (A37). With the aid of (A37), EI can be maximized via projected gradient
ascent. In practice, a customized bound-constrained L-BFGS-B solver (Zhu et al. 1997) is often adopted.

= (y+ − µ)Φ

+ σφ

,

4 Combinatorial Multi-Armed Bandit (CMAB) for (z-min) (problem (A24))

Algorithm A1 Thompson Sampling for CMAB with probabilistic rewards
1: Input: Beta distribution priors α0 and δ0 , maximum iterations L, upper bound ˆf of loss f .
2: Set: nj (k) and rj (k) as the cumulative counts and rewards respectively of arm j pulls at bandit iteration k .
for all arms j ∈ [K ] do

3: for k ← 1, 2, . . . , L do
αj (k) ← α0 + rj (k), δj (k) ← δ0 + nj (k) − rj (k).
Sample ωj ∼ Beta(αj (k), δj (k)).

end for

Determine the arm selection scheme z(k) by solving

N(cid:88)

i=1

z

maximize
where ω = [(ω1 )(cid:62) , . . . , (ωN )(cid:62) ](cid:62) is the vector of {ωj }, and ω i is its subvector limited to module i.
Apply strategy z(k) and observe continuous reward (cid:101)r

(zi )(cid:62)ω i subject to zi ∈ {0, 1}Ki , 1(cid:62)zi = 1, i ∈ [N ],
(cid:26) f (k + 1)
ˆf

(cid:101)r = 1 − min

(cid:26)

(cid:27)

(cid:27)

, 0

, 1

max

(A38)

(A39)

4:
5:
6:
7:
8:

9:

10:
11:
12:
13:
14:

(cid:80)Ki

Observe binary reward r ∼ Bernoulli((cid:101)r).
where f (k + 1) is the loss value after applying z(k).
for all arms j ∈ [K ] do

Update nj (k + 1) ← nj (k) + zj (k).
Update rj (k + 1) ← rj (k) + zj (k)r .

end for
15: end for

As mentioned earlier, problem (A24) can be solved as an integer program, but has two issues: (i) (cid:81)N
i=1 Ki black-box function
queries would be needed in each ADMM iteration, and (ii) integer programming is difﬁcult with the equality constraints

j=1 zij = 1∀i ∈ [N ].

We propose a customized combinatorial multi-armed bandit (CMAB) algorithm as a query-efﬁcient alternative by interpreting
problem (A23) through combinatorial bandits: We are considering bandits due to the stochasticity in the algorithm selection
sampling. We wish to select the optimal N algorithms (arms) from K = (cid:80)N
arising from the fact that we train the algorithm in a subset of pipelines and not the complete combinatorially large set of all
pipelines – the basic idea is to project an optimistic upper bound on the accuracy of the full set of pipelines using Thompson
i=1 Ki algorithms based on bandit feedback
(‘reward’) r inversely proportional to the loss f . CMAB problems can be efﬁciently solved with Thompson sampling (TS)
(Durand and Gagné 2014). However, the conventional algorithm utilizes binary rewards, and hence is not directly applicable to
our case of continuous rewards (with r ∝ 1 − f where the loss f ∈ [0, 1] denotes the black-box objective). We address this issue
by using “probabilistic rewards” (Agrawal and Goyal 2012).
We present the customized CMAB algorithm in Algorithm A1. The closed-form solution of problem (A38) is given by z i
upper bound ˆf (assuming the lower bound is 0), and maps it to the continuous reward (cid:101)r within [0, 1]. Step 10 of Algorithm A1
j , and z i
j = 0 otherwise. Step 9 of Algorithm A1 normalizes the continuous loss f with respect to its
converts a probabilistic reward to a binary reward. Lastly, steps 11-12 of Algorithm A1 update the priors of TS for combinatorial
bandits (Durand and Gagné 2014). For our experiments, we set α0 = δ0 = 10. We study the effect of ˆf on the solution of the
(z-min) problem in Appendix 5.

for j = arg maxj∈[Ki ] ω i

j = 1

5 ADMM with different solvers for the sub-problems

We wish to demonstrate that our ADMM based scheme is not a single AutoML algorithm but rather a framework that can be
used to mix and match different existing (and future new) black-box solvers. First we demonstrate the ability to plug in different
solvers for the continuous black-box optimization involved in problem (10) (θ-min on the active set). We consider a search space
containing 39 scikit-learn (Pedregosa, Varoquaux, and others 2011) ML algorithms allowing for over 6000 algorithm
combinations. The 4 different modules and the algorithms (along with their number and types of hyper-parameters) in each
of those modules is listed in Table A2 in section 7 of the supplement. For the solvers, we consider random search (RND), an
off-the-shelf Gaussian process based Bayesian optimization (Williams and Rasmussen 2006) using scikit-optimize (BO),
our implementation of a Gaussian process based Bayesian optimization (BO*)(see section 3 in the supplement for details), and
RBFOpt (Costa and Nannicini 2018). We use a randomized algorithm selection scheme (z-min) – from each functional module,
we randomly select an algorithm from the set of choices, and return the best combination found. The penalty parameter ρ for the
augmented Lagrangian term in ADMM is set 1.0 throughout this evaluation.

(i) Oil spill

(ii) Sonar

(iii) Ionosphere

(iv) PC3

(v) PC4

Figure A1: Average performance (across 10 runs) of different solvers for the ADMM sub-problem (A19) (Please view in color).

(i) Oil spill

(ii) Sonar

(iii) Ionosphere

(iv) PC3

(v) PC4

Figure A2: Performance inter-quartile range of different solvers for the ADMM sub-problem (A19) (Please view in color).

We present results for 5 of the datasets in the form of convergence plots showing the incumbent objective (the best objective
value found till now) against the wall clock time. Here tmax = 2048, n = 128, R = 10. The results are presented in ﬁgures A1
& A2. The results indicate that the relative performance of the black-box solvers vary between data sets. However, our goal here
is not to say which is best, but rather to demonstrate that our proposed ADMM based scheme is capable of utilizing any solver
for the (θ-min) sub-problem to search over a large space pipeline conﬁgurations.
For the algorithm selection combinatorial problem (z-min), we compare random search to a Thompson sampling (Durand and
Gagné 2014) based combinatorial multi-armed bandit (CMAB) algorithm. We developed a customized Thompson sampling
scheme with probabilistic rewards. We detail this CMAB scheme in Appendix 4 (Algorithm A1) and believe that this might be of
independent interest. Our proposed CMAB scheme has two parameters: (i) the beta distribution priors α0 , δ0 (set to 10), and (ii)
the loss upper bound ˆf (which we vary as 0.3, 0.5, 0.7).

(i) Oil spill

(ii) Sonar

(iii) Ionosphere

(iv) PC3

(v) PC4

Figure A3: Average performance (across 10 runs) of different solvers for the ADMM sub-problem (A24) (please view in color).

We again consider results in the form of convergence plots showing the incumbent objective (the best objective value found
till now) against the number of pipeline combinations tried (number of “arms pulled”) in ﬁgures A3 & A4. The results indicate

(i) Oil spill

(ii) Sonar

(iii) Ionosphere

(iv) PC3

(v) PC4

Figure A4: Performance inter-quartile range of different solvers for the ADMM sub-problem (A24) (Please view in color).

for large number of pulls, all schemes perform the same. However, on 2/5 datasets, CMAB(0.7) (and other settings) outperforms
random search for small number of pulls by a signiﬁcant margin. Random search signiﬁcantly outperforms CMAB on the
Ionosphere dataset. The results indicate that no one method is best for all data sets, but ADMM is not tied to a single solver, and
is able to leverage different solvers for the (z-min) step.

6 Details on the data

We consider data sets corresponding to the binary classiﬁcation task from the UCI machine learning repository (Asuncion and
Newman 2007), OpenML and Kaggle. The names, sizes and sources of the data sets are presented in Table A1. There are couple
of points we would like to explicitly mention here:
• While we are focusing on binary classiﬁcation, the proposed ADMM based scheme is applicable to any problem (such as
multiclass & multi-label classiﬁcation, regression) since it is a black-box optimization scheme and can operate on any problem
speciﬁc objective.
• We consider a subset of OpenML100 limited to binary classiﬁcation and small enough to allow for meaningful amount of
optimization for all baselines in the allotted 1 hour to ensure that we are evaluating the optimizers and not the initialization
heuristics.
The HCDR data set from Kaggle is a subset of the data presented in the recent Home Credit Default Risk competition
(https://www.kaggle.com/c/home- credit-default- risk). We selected the subset of 10000 rows and 24 features using the following
steps:
• We only considered the public training set since that is only set with labels available
• We kept all columns with keyword matches to the terms “HOME”, “CREDIT”, “DEFAULT”, “RISK”, “AGE”, “INCOME”,
“DAYS”, “AMT”.
• In addition, we selected the top 10 columns most correlated to the labels column.
• For this set of features, we randomly selected 10000 rows with ≤ 4 missing values in each rows while maintaining the original
class ratio in the dataset.

Table A1: Details of the data sets used for the empirical evaluations. The ‘Class ratios’ column corresponds to the ratio of the two classes in the
data set, quantifying the class imbalance in the data.

Data
Sonar
Heart statlog
Ionosphere
Oil spill
fri-c2
PC3
PC4
Space-GA
Pollen
Ada-agnostic
Sylvine
Page-blocks
Optdigits
Wind
Delta-Ailerons
Ringnorm
Twonorm
Bank8FM
Puma8NH
CPU small
Delta-Elevators
Japanese Vowels
HCDR
Phishing websites
Mammography
EEG-eye-state
Elevators
Cal housing
MLSS 2017 CH#2
2D planes
Electricity

# rows
208
270
351
937
1000
1563
1458
3107
3848
4562
5124
5473
5620
6574
7129
7400
7400
8192
8192
8192
9517
9961
10000
11055
11183
14980
16598
20640
39948
40768
45312

# columns
61
14
35
50
11
38
38
7
6
48
21
11
64
15
6
21
21
9
9
13
7
13
24
31
7
15
19
9
12
11
9

Class ratio

1 : 0.87
1 : 0.8
1 : 1.79

Source
UCI
UCI
UCI
OpenML 1 : 0.05
OpenML 1 : 0.72
OpenML 1 : 0.11
OpenML 1 : 0.14
OpenML 1 : 0.98
OpenML 1 : 1
OpenML 1 : 0.33
OpenML 1 : 1
OpenML 1 : 8.77
UCI
OpenML 1 : 1.14
OpenML 1 : 1.13
OpenML 1 : 1.02
OpenML 1 : 1
OpenML 1 : 1.48
OpenML 1 : 1.01
OpenML 1 : 0.43
OpenML 1 : 0.99
OpenML 1 : 0.19
Kaggle
UCI
OpenML 1 : 0.02
OpenML 1 : 0.81
OpenML 1 : 2.24
OpenML 1 : 1.46
OpenML 1 : 0.2
OpenML 1 : 1
OpenML 1 : 0.74

1 : 0.11

1 : 0.07
1 : 1.26

7 Search space: Algorithm choices and hyper-parameters

In this section, we list the different search spaces we consider for the different empirical evaluations in section 5 of the paper.

Larger search space

For the empirical evaluation of black-box constraints (section 5 (ii)), ADMM ﬂexibity (section 5 (iii)) and Appendix 5, we
consider 5 functional modules – feature preprocessors, feature scalers, feature transformers, feature selectors, and ﬁnally
estimators. The missing handling and the categorical handling is always applied if needed. For the rest of the modules, there
are 8, 11, 7 and 11 algorithm choices respectively, allowing for 6776 possible pipeline combinations. We consider a total of 92
hyperparamters across all algorithms. The algorithm hyper-parameter ranges are set using Auto-sklearn as the reference ( see
https://github.com/automl/auto- sklearn/tree/master/autosklearn/pipeline/components).

Table A2: Overview of the scikit-learn feature preprocessors, feature transformers, feature selectors and estimators used in our empirical
evaluation. The preprocessing is always applied so there is no choice there. Barring that, we are searching over a total of 8 × 11 × 7 × 11 = 6776
possible pipeline compositions.

Module
Preprocessors

Scalers ×8

Transformer ×11

Selector ×7

Estimator ×11

∗None means no algorithm is selected and corresponds to a empty set of hyper-
parameters. † ‘d’ and ‘c’ represents discrete and continuous variables, respectively.

Algorithm
Imputer
OneHotEncoder
None∗
Normalizer
QuantileTransformer
MinMaxScaler
StandardScaler
RobustScaler
Binarizer
KBinsDiscretizer
None
SparseRandomProjection
GaussianRandomProjection
RBFSampler
Nystroem
TruncatedSVD
KernelPCA
FastICA
FactorAnalysis
PCA
PolynomialFeatures
None
SelectPercentile
SelectFpr
SelectFdr
SelectFwe
VarianceThreshold
GaussianNB
QuadraticDiscriminantAnalysis
GradientBoostingClassiﬁer
KNeighborsClassiﬁer
RandomForestClassiﬁer
ExtraTreesClassiﬁer
AdaBoostClassiﬁer
DecisionTreeClassiﬁer
GaussianProcessClassiﬁer
LogisticRegression
MLPClassiﬁer

# parameters
1d
none
none
none
2d†
none
none
2c† , 2d
2d
none
1c, 1d
1d
1c, 1d
2c, 3d
2d
2c, 4d
5d
3d
1c, 1d
3d
none
1d
1c
1c
1c
1c
none
1c
3c, 6d
3d
1c, 5d
1c, 5d
1c, 2d
3c, 3d
2d
2c, 3d
2c, 5d

Smaller search space for comparing to AutoML baselines

We choose a relatively smaller search space in order to keep an efﬁcient fair comparison across all baselines, auto-sklearn, TPOT
and ADMM, with the same set of operators, including all imputation and rescaling. However, there is a technical issue – many
of the operators in Auto-sklearn are custom preprocessors and estimators (kitchen sinks, extra trees classiﬁer preprocessor, linear
svc preprocessors, fastICA, KernelPCA, etc) or have some custom handling in there (see https://github.com/automl/auto- sklearn/
tree/master/autosklearn/pipeline/components). Inclusion of these operators makes it infeasible to have a fair comparison across
all methods. Hence, we consider a reduced search space, detailed in Table A3. It represents 4 functional modules with a choice of
6 × 3 × 6 = 108 possible method combinations (contrast to Table A2). For each scheme, the algorithm hyper-parameter ranges are
set using Auto-sklearn as the reference (see https://github.com/automl/auto- sklearn/tree/master/autosklearn/pipeline/components).

Table A3: Overview of the scikit-learn preprocessors, transformers, and estimators used in our empirical evaluation comparing ADMM,
auto-sklearn, TPOT. We consider a choice of 6 × 3 × 6 = 108 possible method combinations (see text for further details).

Module
Preprocessors

Scalers ×6

Transformer ×3

Estimator ×6

Algorithm
Imputer
OneHotEncoder
None∗
Normalizer
QuantileTransformer
MinMaxScaler
StandardScaler
RobustScaler
None
PCA
PolynomialFeatures
GaussianNB
QuadraticDiscriminantAnalysis
GradientBoostingClassiﬁer
KNeighborsClassiﬁer
RandomForestClassiﬁer
ExtraTreesClassiﬁer

# parameters
1d
none
none
none
2d†
none
none
2c† , 2d
2d
none
1c, 1d
1c, 2d
none
1c
3c, 6d
3d
1c, 5d
1c, 5d

∗None means no algorithm is selected and corresponds to a empty set of hyper-
parameters. † ‘d’ and ‘c’ represents discrete and continuous variables, respectively.

Note on parity between baselines. With a ﬁxed pipeline shape and order, ADMM & ASKL are optimizing over the same
search space by making a single selection from each of the functional modules to generate a pipeline. In contrast, TPOT can
use multiple methods from the same functional module within a single pipeline with stacking and chaining due to the nature
of the splicing/crossover schemes in its underlying genetic algorithm. This gives TPOT access to a larger search space of
more complex pipelines featuring longer as well as parallel compositions, rendering the comparison somewhat biased towards
TPOT. Notwithstanding this caveat, we consider TPOT as a baseline since it is a competitive open source AutoML alternative to
ASKL, and is representative of the genetic programming based schemes for AutoML. We provide some examples of the complex
pipelines found by TPOT in Appendix 16.

8 Learning ensembles with ADMM

We use the greedy selection based ensemble learning scheme proposed in Caruana et al. (2004) and used in Auto-sklearn as
a post-processing step (Feurer et al. 2015). We run ASKL and ADMM(BO, Ba) for tmax = 300 seconds and then utilize the
following procedure to compare the ensemble learning capabilities of Auto-sklearn and our proposed ADMM based optimizer:
• We consider different ensemble sizes e1 = 1 < e2 = 2 < e3 = 4 . . . < emax = 32.
• We perform library pruning on the pipelines found during the optimization run for a maximum search time tmax by picking
only the emax best models (best relative to their validation score found during the optimization phase).
• Starting with the pipeline with the best ˆs as the ﬁrst member of the ensemble, for each ensemble size ej , we greedily add the
pipeline (with replacement) which results in the best performing bagged ensemble (best relative to the performance ˆs(cid:48)
j on the
validation set Sv after being trained on the training set St ).
• Once the ensemble members (possibly with repetitions) are chosen for any ensemble size ej , the ensemble members are
retrained on the whole training set (the training + validation set) and the bagged ensemble is then evaluated on the unseen
held-out test set Sh to get s(cid:48)
j . We follow this procedure since the ensemble learning uses the validation set and hence cannot
be used to generate a fair estimate of the generalization performance of the ensemble.
• Plot the (ej , s(cid:48)
j ) pairs.
• The whole process is repeated R = 10 times for the same T and ej s to get error bars for s(cid:48)
j .
For ADMM(BO,Ba), we implement the Caruana et al. (2004) scheme ourselves. For ASKL:SMAC3, we use the post-processing
ensemble-learning based on the example presented in their documentation at https://automl.github.io/auto- sklearn/master/
examples/example_sequential.html.

(i) Bank8FM

(ii) CPU small

(iii) Delta Ailerons

(iv) Japanese Vowels

(v) Page blocks

(vi) Sylvine

(vii) Twonorm

(viii) Wind

Figure A5: Ensemble size vs. median performance on the test set and the inter-quartile range (please view in color). The Aquamarine and Blue
curves correspond to ADMM(BO,Ba) and ASKL respectively.

The inter-quartile range (over 10 trials) of the test performance of the post-processing ensemble learning for a subset of the
data sets in Table A1 is presented in Figure A5. The results indicate that the ensemble learning with ADMM is able to improve
the performance similar to the ensemble learning in Auto-sklearn. The overall performance is driven by the starting point (the
test error of the best single pipeline, corresponding to an ensemble of size 1) – if ADMM and Auto-sklearn have test objective
values that are close to each other (for example, in Page-blocks and Wind), their performance with increasing ensemble sizes are
very similar as well.

9 Parameter sensitivity check for ADMM

We investigate how sensitive our proposed approach is to the ADMM parameter ρ and CMAB parameter ˆf . For each parameter
combination of ρ ∈ {0.001, 0.01, 0.1, 1, 10} and ˆf ∈ {0.5, 0.6, 0.7, 0.8, 0.9}, in Figure A6 we present the validation error
(averaged over 10 trials) by running our approach on the HCDR dataset (see Appendix 6).

Figure A6: Validation error of our proposed ADMM-based approach against ADMM parameter ρ and CMAB parameter ˆf

For this experiment, the results indicate that a large ρ yields a slightly better performance. However, in general, our approach
is not very sensitive to the choice of ρ and ˆf – the range of the objectives achieved are in a very small range. Based on this
observation, we set ρ = 1 and ˆf = 0.7 in all our empirical evaluations of ADMM(BO,Ba) unless otherwise speciﬁed.

10 Details on the baselines and evaluation scheme

Evaluation scheme. The optimization is run for some maximum runtime T where each proposed conﬁguration is trained on a
set St and evaluated on Sv and the obtained score ˆs is the objective that is being minimized by the optimizer. We ensure that
all the optimizers use the same train-validation split. Once the search is over, the history of attempted conﬁgurations is used to
generate a search time vs. holdout performance curve in the following manner for N timestamps:
• For each timestamp ti , i = 1, . . . , N , tN = T , we pick the best validation score ˆsi obtained by any conﬁguration found by
time ti from the start of the optimization (the incumbent best objective).
• Then we plot the (ti , ˆsi ) pairs.
• The whole above process is repeated R times for the same T , N and ti s to get inter-quartile ranges for the curves.
For the presented results, T = 3600 seconds, N = 256 and R = 10.

Parity with baselines. First we ensure that the operations (such as model training) are done single-threaded (to the extent possi-
ble) to remove the effects of parallelism in the execution time. We set OPENBLAS_NUM_THREADS and OMP_NUM_THREADS
to 1 before the evaluation of ADMM and the other baselines. ADMM can take advantage of the parallel model-training much like
the other systems, but we want to demonstrate the optimization capability of the proposed scheme independent of the underlying
parallelization in model training. Beyond this, there are some details we note here regarding comparison of methods based on
their internal implementation:
• For any time ti , if no predictive performance score (the objective being minimized) is available, we give that method the worst
objective of 1.0 for ranking (and plotting purposes). After the ﬁrst score is available, all following time stamps report the best
incumbent objective. So comparing the different baselines at the beginning of the optimization does not really give a good
view of the relative optimization capabilities – it just illustrates the effect of different starting heuristics.
• For ADMM, the ﬁrst pipeline tried is Naive Bayes, which is why ADMM always has some reasonable solution even at the
earliest timestamp.
• The per conﬁguration run time and memory limits in Auto-sklearn are removed to allow Auto-sklearn to have access to the
same search space as the ADMM variants.
• The ensembling and meta-learning capabilities of Auto-sklearn are disabled. The ensembling capability of Auto-sklearn is
discussed further in Appendix 8.
• For ASKL, the ﬁrst pipeline tried appears to be a Random Forest with 100 trees, which takes a while to be run. For this reason,
there is no score (or an objective of 1.0) for ASKL until its objective suddenly drops to a more competitive level since Random
Forests are very competitive out of the box.
• For TPOT, the way the software is set up (to the best of our understanding and trials), scores are only available at the end
of any generation of the genetic algorithm. Hence, as with ASKL, TPOT do not report any scores until the ﬁrst generation
is complete (which implies worst-case objective of 1.0), and after that, the objective drops signiﬁcantly. For the time limit
considered (T = 3600 seconds), the default population size of 100 set in TPOT is unable to complete a multiple generations
on most of the datasets. So we reduce the population size to 50 to complete a reasonable number of generations within the set
time.
• As we have discussed earlier, TPOT has an advantage over ASKL and ADMM – TPOT is allowed to use multiple estimators,
transformers and preprocessors within a single pipeline via stacking and chaining due to the nature of the splicing and crossover
schemes in its underlying genetic algorithm. This gives TPOT access to a larger search space of more complex pipelines
featuring longer as well as parallel compositions; all the remaining baselines are allowed to only use a single estimator,
transformers and preprocessor. Hence the comparison is somewhat biased towards TPOT, allowing TPOT to potentially ﬁnd a
better objective in our experimental set up. If TPOT is able to execute a signiﬁcant number of generations, we have observed
in many cases that TPOT is able to take advantage of this larger search space and produce the best performance.
• Barring the number of generations (which is guided by the maximum run time) and the population size (which is set to 50
to give us TPOT50), the remaining parameters of mutation rate, crossover rate, subsample fraction and number of parallel
threads to the default values of 0.9, 0.1, 1.0 and 1 respectively.
Random search (RND) is implemented based on the Auto-sklearn example for random search at https://automl.github.io/auto-
sklearn/master/examples/example_random_search.html.

Compute machines. All evaluations were run single-threaded on a 8 core 8GB CentOS virtual machines.

11 Convergence plots for all data sets for all AutoML baselines.

(i) Sonar

(ii) Heart-Statlog

(iii) Ionosphere

(iv) Oil spill

(v) fri-c2

(vi) PC3

(vii) PC4

(viii) Space GA

(ix) Pollen

(x) Ada-agnostic

(xi) Sylvine

(xii) Page-blocks

(xiii) Optdigits

(xiv) Wind

(xv) Delta-Ailerons

(xvi) Ringnorm

(xvii) Twonorm

(xviii) Bank8FM

(xix) Puma8NH

(xx) CPU small

(xxi) Delta elevators

(xxii) Japanese Vowels

(xxiii) HCDR

(xxiv) Phishing websites

(xxv) Mammography

(xxvi) EEG-eye-state

(xxvii) Elevators

(xxviii) Cal housing

(xxix) MLSS2017#2

(xxx) Electricity

Figure A7: Search/optimization time vs. median validation performance with the inter-quartile range over 10 trials (please view in color). The
curves colored Aquamarine, Grey, Blue and Black correspond respectively to ADMM(BO,Ba), RND, ASKL and TPOT50.

12 Computing the group-disparity fairness metric with respect to classiﬁcation metric ε

Computing the black-box function. The black-box objective f (z, θ , A) is computed as follows for holdout-validation with
some metric ε (the metric ε can be anything such as zero-one loss or area under the ROC curve):
• Let m be the pipeline speciﬁed by (z, θ)
• Split data set A into training set At and validation set Av
• Train the pipeline m with training set At to get mAt
• Evaluate the trained pipeline mAt on the validation set Av as follows:

ε (At , Av ) = ε ({(y , mAt (x)) ∀(x, y) ∈ Av }) ,

(A40)

(A41)

(A42)

where mAt (x) is the prediction of the trained pipeline mAt on any test point x with label y and

f (z, θ , A) = ε (At , Av ) .

For k-fold cross-validation, using the above notation, the objective is computed as follows:
• Split data set A into training set Ati and validation set Avi for each of the i = 1, . . . , k folds
• For a pipeline m speciﬁed with (z, θ), the objective is computed as

f (z, θ , A) =

1
k

ε (Ati , Avi ) .

k(cid:88)

i=1

NOTE. The splitting of the data set A in training/validation pairs (At , Av ) should be the same across all evaluations of (z, θ).
Similarly, the k-fold splits should be the same across all evaluations of (z, θ).

Computing group disparate impact. Continuing with the notation deﬁned in the previous subsection, for any given
(test/validation) set Av , assume that we have a (probably user speciﬁed) “protected” feature d and a grouping Gd (Av ) =
{A1 , A2 , . . .} of the set Av based on this feature (generally, Aj

13 Benchmarking Adaptive ADMM

It is common in ADMM to solve the sub-problems to higher level of approximation in the initial ADMM iterations and to
an increasingly smaller levels of approximation as the ADMM progresses (instead of the same level of approximation for all
ADMM iterations). We make use of this same adaptive ADMM and demonstrate that, empirically, the adaptive scheme produces
expected gains in the AutoML problem as well.
In this empirical evaluation, we use BO for solving both the (θ-min) and the (z-min) problems. For ADMM with a ﬁxed level
of approximation (subsequently noted as ﬁxed ADMM), we solve the sub-problems to a ﬁxed number I of BO iterations with
I = 16, 32, 64, 128 (also 256 for the artiﬁcial objective described in Appendix 15)) denoted by ADMMI (BO,BO) (for example,
ADMM16(BO,BO)). For ADMM with varying level of approximation, we start with 16 BO iterations for the sub-problems and
progressively increase it with an additive factor F = 8 or 16 with every ADMM iteration until 128 (until 256 for the artiﬁcial
objective) denoted by AdADMM-F8(BO,BO) and AdADMM-F16(BO,BO) respectively. The optimization is run for 3600
seconds for all the data sets and for 1024 seconds for the artiﬁcial objective function. The convergence plots are presented in
Figure A8.

(i) Artiﬁcial black-box objective

(ii) Bank8FM

(iii) CPU small

(iv) fri-c2

(v) PC4

(vi) Pollen

(vii) Puma8NH

(viii) Sylvine

(ix) Wind

Figure A8: Search/optimization time (in seconds) vs. median validation performance with the inter-quartile range over 10 trials (please view in
color and note the log scale on both the horizontal and vertical axes).

The ﬁgures indicate the expected behavior – ﬁxed ADMM with small I dominate for small optimization time scale but saturate
soon while ﬁxed ADMM with large I require a signiﬁcant amount of startup time but then eventually lead to the best performance
for the larger time scales. Adaptive ADMM (for both values of F ) appears to somewhat match the performance of the best ﬁxed
ADMM for every time scale. This behavior is exempliﬁed with the artiﬁcial black-box objective (described in Appendix 15) but
is also present on the AutoML problem with real datasets.

14 Evaluating the beneﬁts of problem splitting in ADMM

In this empirical evaluation, we wish to demonstrate the gains from (i) splitting the AutoML problem (1) into smaller sub-
problems which are solved in an alternating fashion, and (ii) using different solvers for the differently structured (θ-min) and
(z-min) problems. First, we attempt to solve the complete joint optimization problem (1) with BO, leading to a Gaussian Process
with a large number of variables. We denote this as JOPT(BO). Then we utilize adaptive ADMM where we use BO for each
of the (θ-min) and (z-min) problems in each of the ADMM iteration, denoted as AdADMM-F16(BO,BO). Finally, we use
adaptive ADMM where we use BO for each of the (θ-min) problem and Combinatorial Multi-Armed Bandits (CMAB) for the
(z-min) problem, denoted as AdADMM-F16(BO,Ba). For the artiﬁcial black-box objective (described in Appendix 15), the
optimization is run for 1024 seconds. For the AutoML problem with the actual data sets, the optimization is run for 3600 seconds.
The convergence of the different optimizers are presented in Figure A9.

(i) Artiﬁcial black-box objective

(ii) Bank8FM

(iii) CPU small

(iv) fri-c2

(v) PC4

(vi) Pollen

(vii) Puma8NH

(viii) Sylvine

(ix) Wind

Figure A9: Search/optimization time vs. median validation performance with the inter-quartile range over 10 trials (please view in color and
note the log scale on both the horizontal and vertical axes).

The results for the artiﬁcial objective is a case where the black-box optimization dominates the optimization time (since
the black-box evaluation is cheap). In this case, both versions of the adaptive ADMM signiﬁcantly outperforms the single
BO (JOPT(BO)) for the whole problem 2 seconds onwards, demonstrating the advantage of the problem splitting in ADMM.
Between the two versions of the adaptive ADMM, AdADMM(BO,Ba) (Bandits for (z-min)) outperforms AdADMM(BO,BO)
(BO for (z-min)). This is potentially because BO is designed for continuous variables and is mostly suited for the (θ-min)
problem, whereas the Bandits interpretation is better suited for the (z-min) problem. By the end of the optimization time budget,
AdADMM(BO,Ba) improves the objective by around 31% over JOPT(BO) (5% over AdADMM(BO,BO)), and achieves the
objective reached by JOPT(BO) with a 108× speedup (AdADMM(BO,BO) with a 4× speedup).
On the AutoML problem with real data sets, the optimization time is mostly dominated by the black-box evaluation, but even
in this case, the problem splitting with ADMM demonstrates signiﬁcant gains over JOPT(BO). For example, on the fri-c2 dataset,

the results indicate that the operator splitting in ADMM allows it to reach the ﬁnal objective achieved by JOPT with over 150×
speedup, and then further improves upon that ﬁnal objective by over 50%. On the Pollen dataset, we observe a speedup of around
25× with a further improvement of 4%. Table A4 & A5 summarize the signiﬁcant gains from the problem splitting in ADMM.

Dataset
Artiﬁcial
Bank8FM
CPU small
fri-c2
PC4
Pollen
Puma8NH
Sylvine
Wind

Speedup

4×

108×
10×
153×
42×
25×
11×
40×

9×

Improvement

31%
0%
0%
56%
8%
4%
1%
9%
0%

Table A4: Comparing AdADMM(BO,Ba) to JOPT(BO), we list the speedup achieved by AdADMM(BO,Ba) to reach the best objective
of JOPT(BO), and any further improvement in the objective. These numbers are generated using the aggregate performance of JOPT and
AdADMM over 10 trials.

Dataset
Artiﬁcial
Bank8FM
CPU small
fri-c2
PC4
Pollen
Puma8NH
Sylvine
Wind

Speedup

39×

25×

2×
5×
5×
7×
4×
2×
5×

Improvement

27%
5%
5%
64%
13%
3%
1%
26%
5%

Table A5: Comparing AdADMM(BO,BO) to JOPT(BO), we list the speedup achieved by AdADMM(BO,BO) to reach the best objective
of JOPT(BO), and any further improvement in the objective. These numbers are generated using the aggregate performance of JOPT and
AdADMM over 10 trials.

15 Artiﬁcial black-box objective

We wanted to devise an artiﬁcial black-box objective to study the behaviour of the proposed scheme that matches the properties
of the AutoML problem (1) where
1. The same pipeline (the same algorithm choices z and the same hyperparameters θ always gets the same value.
2. The objective is not convex and possibly non-continuous.
3. The objective captures the conditional dependence between zi and θ ij – the objective is only dependent on the hyper-parameters
θ ij if the corresponding zij = 1.
4. Minor changes in the hyper-parameters θ ij can cause only small changes in the objective.
5. The output of module i is dependent on its input from module i − 1.

Novel artiﬁcial black-box objective. To this end, we propose the following novel black-box objective:
• For each (i, j ), i ∈ [N ], j ∈ [Ki ], we ﬁx a weight vector wij (each entry is a sample from N (0, 1)) and a seed sij .
• We set f0 = 0.
• For each module i, we generate a value

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) w(cid:62)

ij θ ij
1T θ ij

(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)

vi =

zij

(cid:88)

j

which only depends on the θ ij corresponding to the zij = 1, and the denominator ensures that the number (or range) of the
hyper-parameters does not bias the objective towards (or away from) any particular algorithm.
• We generate n samples {fi,1 , . . . , fi,n} ∼ N (fi−1 , vi ) with the ﬁxed seed sij , ensuring that the same value will be produced
for the same pipeline.

• fi = max

|fi,m |.

m=1,...,n

The basic idea behind this objective is that, for each operator, we create a random (but ﬁxed) weight vector wij and take a
weighted normalized sum of the hyper-parameters θ ij and use this sum as the scale to sample from a normal distribution (with
a ﬁxed seed sij ) and pick the maximum absolute of n (say 10) samples. For the ﬁrst module in the pipeline, the mean of the
distribution is f0 = 0.0. For the subsequent modules i in the pipeline, the mean fi−1 is the output of the previous module i − 1.
This function possesses all the aforementioned properties of the AutoML problem (1).
In black-box optimization with this objective, the black-box evaluations are very cheap in contrast to the actual AutoML
problem where the black-box evaluation requires a signiﬁcant computational effort (and hence time). However, we utilize
this artiﬁcial objective to evaluate ADMM (and other baselines) when the computational costs are just limited to the actual
derivative-free optimization.

16 TPOT pipelines: Variable length, order and non-sequential

The genetic algorithm in TPOT does stitches pipelines together to get longer length as well as non-sequential pipelines, using the
same module multiple times and in different ordering. Given the abilities to
i. have variable length and variable ordering of modules,
ii. reuse modules, and
iii. have non-sequential parallel pipelines,
TPOT does have access to a much larger search space than Auto-sklearn and ADMM. Here are some examples for our
experiments:

Sequential, length 3 with 2 estimators

Input --> PolynomialFeatures --> KNeighborsClassifier --> GaussianNB

GaussianNB(
KNeighborsClassifier(
PolynomialFeatures(
input_matrix,
PolynomialFeatures__degree=2,
PolynomialFeatures__include_bias=False,
PolynomialFeatures__interaction_only=False

),
KNeighborsClassifier__n_neighbors=7,
KNeighborsClassifier__p=1,
KNeighborsClassifier__weights=uniform

)

)

Sequential, length 4 with 3 estimators

Input
--> PolynomialFeatures
--> GaussianNB
--> KNeighborsClassifier
--> GaussianNB

GaussianNB(
KNeighborsClassifier(
GaussianNB(
PolynomialFeatures(
input_matrix,
PolynomialFeatures__degree=2,
PolynomialFeatures__include_bias=False,
PolynomialFeatures__interaction_only=False

)

),
KNeighborsClassifier__n_neighbors=7,
KNeighborsClassifier__p=1,
KNeighborsClassifier__weights=uniform

)

)

Sequential, length 5 with 4 estimators

Input
--> RandomForestClassifier
--> RandomForestClassifier
--> GaussianNB
--> RobustScaler
--> RandomForestClassifier

RandomForestClassifier(
RobustScaler(
GaussianNB(
RandomForestClassifier(
RandomForestClassifier(
input_matrix,
RandomForestClassifier__bootstrap=False,
RandomForestClassifier__criterion=gini,
RandomForestClassifier__max_features=0.68,
RandomForestClassifier__min_samples_leaf=16,
RandomForestClassifier__min_samples_split=13,
RandomForestClassifier__n_estimators=100
),
RandomForestClassifier__bootstrap=False,
RandomForestClassifier__criterion=entropy,
RandomForestClassifier__max_features=0.9500000000000001,
RandomForestClassifier__min_samples_leaf=2,
RandomForestClassifier__min_samples_split=18,
RandomForestClassifier__n_estimators=100

)

)
),
RandomForestClassifier__bootstrap=False,
RandomForestClassifier__criterion=entropy,
RandomForestClassifier__max_features=0.48,
RandomForestClassifier__min_samples_leaf=2,
RandomForestClassifier__min_samples_split=8,
RandomForestClassifier__n_estimators=100

)

Non-sequential

Combine[
Input,
Input --> GaussianNB --> PolynomialFeatures --> Normalizer
] --> RandomForestClassifier

RandomForestClassifier(
CombineDFs(
input_matrix,
Normalizer(
PolynomialFeatures(
GaussianNB(
input_matrix
),
PolynomialFeatures__degree=2,
PolynomialFeatures__include_bias=True,
PolynomialFeatures__interaction_only=False
),
Normalizer__copy=True,
Normalizer__norm=l2

)
),
RandomForestClassifier__bootstrap=False,
RandomForestClassifier__criterion=entropy,
RandomForestClassifier__max_features=0.14,
RandomForestClassifier__min_samples_leaf=7,
RandomForestClassifier__min_samples_split=8,
RandomForestClassifier__n_estimators=100

)

