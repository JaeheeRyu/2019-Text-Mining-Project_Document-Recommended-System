9
1
0
2

v
o

N

1
2

]

S

D

.

s

c

[

9
v
5
2
5
8
0

.

1
0
9
1

:

v

i

X

r

a

Is linear program equivalent to a quadratic size
homogeneous linear feasibility ?

Adrien CHAN-HON-TONG

November 22, 2019

Abstract

This paper claim to prove that if one is able to solve homogeneous lin-
ear feasibility ∃?v / Av > 0, then, it can solve linear program ∃?x / Ax > b
by transforming the linear program into a quadratic size homogeneous lin-
ear feasibility problem.
This statement is probably false, as, it would be a very important
result. It would be an even more important result, as, Chubanov recently
found a very interesting algorithm to solve homogeneous linear feasibility.
Hence, it would be interesting for the community to check this result.

1 Introduction

Linear programming is the very studied task of solving min

x / Ax≥b

cT x for given

A ∈ QM ×N a matrix, b ∈ QM and c ∈ QN some vectors.
Recently, [1] introduces an algorithm with good theoretical properties for
for deciding if ∃?x ∈ QI / H x =
homogeneous linear feasibility problems:
0, x > 0 given H ∈ QJ ×I a full rank matrix. And, [3] shows that the dual
problem family is just ∃?v ∈ QN / Av > 0 without constraint on the matrix

A ∈ QM ×N .

But, it was/is not known if one could take advantage of [1] for generic linear
programming. This paper claims (while being aware that this is probably wrong
as it is a very strong statement) that if one is able to solve homogeneous linear
feasibility ∃?v / Av > 0, then, it can solve linear program ∃?x / Ax > b
by transforming the linear program into a quadratic size homogeneous linear
feasibility problem.

Notations

Q is the set of rational numbers. For all integers i, j, I , J , QI is the set of I
dimensional vectors on Q, and, QI×J is the set of matrix with I rows and J
columns, with values in Q, and, .i designs the i component: a row for a matrix
and a rational for vector or a row. QI would be matched with QI×1 i.e. vectors

1

 
 
 
 
 
 
are seen as columns, and, row of a matrix are matched with Q1×J . For all
sets S ⊂ N, AS , bS is the submatrix or subvector obtained when keeping only
components indexed by s ∈ S . T is the transposition operation i.e. AT
0 and 1 are the 0 and 1 vector i.e. vector contains only 0 or only 1, and I is the
identity matrix.

j,i = Ai,j .

2 Massive homogeneous linear feasibility versus
linear programming

2.1 Pre processing

Let recall the classical primal dual trick to go from optimization linear program
into a decision linear program.
The goal of linear programming is to solve

max

cT

raw xraw .

Araw xraw ≤braw ,xraw≥0

Then, it is well known that the dual problem is

min

AT

raw yraw ≥craw ,yraw≥0

bT

raw yraw .

Abig =

raw

and bbig =

.

I
0
0

−Araw

Now, the primal dual is formed by combining all constraints: Araw xraw ≤ braw ,
and, xraw ≥ 0, and, AT
raw yraw ≥ craw , and craw xraw = braw yraw , and ﬁnally,
yraw ≥ 0. So, the raw problem can be folded into ∃?xbig / Abig xbig ≥ bbig with
0
0
AT
I

0
0
0
This primal dual problem has a solution i.f.f. the original polytope is nei-
ther empty or unbounded. So, any linear program solver can assume without
restricting the generality (as this pre processing is always possible) to want to
solve ∃?x ∈ QN / Ax ≥ b with A ∈ QM ×N and b ∈ QM .













craw
−craw

−braw
braw

−braw

0

craw

Currently, the oﬀered algorithm requires in addition that either
there is no x such that Ax ≥ b or that there exists x∗ such that Ax∗ > b.
This assumption clearly restrict the generality but it quite classical (for
example for the ellipsoid method [2]). Anyway, seeing the paper claim, this
restriction is not important at this point, and, will be discussed in appendix.

2.2 Algorithm

Let recall that the oﬀered algorithm assumes to have acces to a sub solver which
eﬃciently solves ∃?v / Av > 0. Typically, one may think to Chubanov algorithm
[1] or Roos extension [3].

2

Algorithm of the Chubanov quadratic equivalence:

Input: A ∈ QM ×N , b ∈ QM such that either Ax ≥ b is impossible, either there
is x∗ ∈ QN such that Ax∗ > b
Output: returns x such that Ax ≥ b or a certiﬁcate of impossibility
Algorithm:
F = {m ∈ {1, ..., M } / bm > 0}
E = {m ∈ {1, ..., M } / bm < 0}
G = {m ∈ {1, ..., M } / bm = 0}
Call Chubanov algorithm to ﬁnd if exists v such that:
AF v > 0, AG v > 0, and, ∀(f , e) ∈ F × E , (bf Ae − beAf )v > 0
If, no such v exists, return the certiﬁcate
Else, returns (cid:18)max

Af v (cid:19) v
bf

f ∈F

2.3 Proof

bf

f ∈F

bk

Ak v = λ and y = λv . Then,

If v exists, let λ = (cid:18)max
Af v (cid:19) with k such that
• ∀g ∈ G, Ag y = λAg v > 0 as Ag v > 0 (deﬁnition of v) and λ > 0 (if f ∈ F ,
bf > 0 and Af v > 0 so bf
Af v > 0 and so the max)
• ∀f ∈ F , Af y = (cid:18)max
Af v Af v = bf (because max is greater
than individual elements and Af v > 0 by deﬁnition of v)
• ∀e ∈ E , Ae y = bk
Ak v Ae v (by deﬁnition of k). But, by deﬁnition of v , ∀f ∈
F , (bf Ae − beAf )v > 0. This states a fortiori for for k : bkAe v − beAk v > 0.
Yet, it leads to be < bk
Ak v Ae v i.e. Ae y > be
So, if v exists, then v is the solution of the linear program.
Now, if there is x∗ ∈ QN such that Ax∗ > b, then,

Am v (cid:19) Af v ≥ bf
bm

m∈F

• AF x∗ > bF > 0

• AGx∗ > bG = 0

• ∀(e, f ) ∈ E × F , Af (0 × x∗ ) = 0 < bf but Af (1 × x∗ ) > bf (deﬁnition
of x∗ ), so there is 0 < lf < 1 such that Af (lf × x∗ ) = bf .
Inversely,
∀e ∈ E , Ae (0 × x∗ ) = 0 > be and Ae (1 × x∗ ) > be (deﬁnition of x∗ ). So,
∀0 < l < 1, Ae (l × x∗ ) > be . A fortiori for lf = bf
Af x∗ , one get Ae (lf × x∗ ) >
be . By expanding this expression, it stands that Ae ( bf
Af x∗ × x∗ ) > be ,
Af x∗ > be i.e. bf Aex∗ > beAf x∗ (because Af x∗ > 0). So, ﬁnally,
(bf Ae − beAf ) x∗ > 0.

Aex∗ bf

So, if x∗ exists, then Chubanov algorithm (or any homogeneous linear
feasibility solver) is expected to return a v leading to solve the linear
program.

3

Discussion

This paper invites to conclude that linear programming is polynomially equiva-
lent to homogeneous linear feasibility. This may imply that linear programming
can be solved in strongly polynomial time thank to Chubanov algorithm !
Seeing the importance of this conclusion, it seems that there is probably a
wrong statement in this paper. It could be interesting for the community to
check it.

References

[1] Sergei Chubanov. A polynomial pro jection algorithm for linear feasibility
problems. Mathematical Programming, 153(2):687–713, 2015.

[2] Leonid Khachiyan. A polynomial algorithm for linear programming. Doklady

Akademii Nauk SSSR, 1979.

[3] Kees Roos. An improved version of chubanov’s method for solving a homoge-
neous feasibility problem. Optimization Methods and Software, 33(1):26–44,
2018.

4

Appendix: Flat polytopes

Assuming that either Ax ≥ b is impossible or that there exists x∗ such that
Ax∗ > b is an important hypothesis.
Currently, from any linear program

cT
raw xraw one can
form the primal dual ∃?xbig / Abig xbig ≥ bbig . But, this problem may have
no solution. Yet,
min
z always has one, as the problem is bounded

Abig xbig ≤bbig ,z≥0

max

Araw xraw≤braw ,xraw≥0

(z ≥ 0 and with z ≫ 1 one can create an admissible point.
Now, let take the primal dual of this last one: ∃?xdouble / Adoublexdouble ≥
bdouble . As the
min
z is both bounded and not empty, then it means

Abig xbig ≤bbig ,z≥0

that this primal dual ∃?xdouble / Adoublexdouble ≥ bdouble has necessarily a solu-
tion
Now, let take ε ≪ 1, then there exists xdouble , z / Adoublex + z ≥ bdouble , 0 ≤
z ≤ ε has a solution (as ∃xdouble / Adoublexdouble ≥ bdouble ). But there is more:
it has a pure interior solution ! So the oﬀered algorithm can be applied.
Then, if one compute the solution of ∃?xdouble , z / Adoublexdouble + z ≥
bdouble , 0 ≤ z ≤ ε, and, if ε is small enough, a simple greedy descent (a
sliding move in arxiv.org/abs/1901.08525v7) will allow to restore a solution
of ∃?xdouble / Adoublex ≥ bdouble which will allow to restore a solution of
min
z which will ﬁnally give the solution to the original problem

Abig xbig ≤bbig ,z≥0

max

Araw xraw ≤braw ,xraw≥0

cT

raw xraw .

Araw xraw ≤braw ,xraw≥0

The unsatisfying point with this transformation is that if ǫ has
to be very very small, then the size required to write the problem
may become much larger than the size originally required to write
max
cT
raw xraw . So at this point, it is not totally clear that
it is a real polynomial equivalence. Yet, the oﬀered algorithm can probably
be updated to speciﬁcally with ﬂat polytope without requiring to compute all
these transformations. And, anyway, it is possible that such ε could be computed
using consideration on the integer size of the original input. So, this small
problem is not really relevant considering the (probably wrong) claim of this
paper !

5

