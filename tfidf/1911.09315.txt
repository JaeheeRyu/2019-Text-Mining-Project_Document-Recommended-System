9
1
0
2

v
o

N

1
2

]

G

L

.

s

c

[

1
v
5
1
3
9
0

.

1
1
9
1

:

v

i

X

r

a

Rule Extraction in Unsupervised Anomaly Detection for Model Explainability:
Application to OneClass SVM

Alberto Barbado1,2 , Oscar Corcho2

alberto.barbadogonzalez@telefonica.com, ocorcho@ﬁ.upm.es
1 Telef ´onica, 28050 Madrid, Spain
2 Universidad Polit ´ecnica de Madrid, Departamento de Inteligencia Artiﬁcial, 28660 Boadilla del Monte, Spain

Abstract

OneClass SVM is a popular method for unsupervised
anomaly detection. As many other methods, it suffers from
the black box problem: it is difﬁcult to justify, in an intu-
itive and simple manner, why the decision frontier is iden-
tifying data points as anomalous or non anomalous. Such
type of problem is being widely addressed for supervised
models. However, it is still an uncharted area for unsuper-
vised learning. In this paper, we describe a method to infer
rules that justify why a point is labelled as an anomaly, so as
to obtain intuitive explanations for models created using the
OneClass SVM algorithm. We evaluate our proposal with dif-
ferent datasets, including real-world data coming from indus-
try. With this, our proposal contributes to extend Explainable
AI techniques to unsupervised machine learning models.

Keywords XAI, OneClass SVM, unsupervised learning,
rule extraction

Introduction

Responsible Artiﬁcial Intelligence [1] is an emerging dis-
cipline that is gaining relevance both in academic and in-
dustrial research. An increasing number of organisations are
deﬁning policies and criteria for the usage of data and the de-
velopment of support decision systems using AI techniques.
For example, Telef ´onica has deﬁned its own AI principles
[2], which can be organised into the following categories:
• Detecting sensitive data in the datasets used to train Ma-
chine Learning (ML) models (for example, the use of gen-
der information to support the decision of giving a credit
score) or detecting whether there is a bias in the data,
what may have an unwanted effect in decision making.
Besides analysing directly the dataset, there are also meth-
ods to perform an evaluation on a trained model to check
whether there is any bias on its decisions. This is done
using a group of metrics known as fairness metrics [3, 4,
5].
• Explaining how an algorithm reaches a conclusion in a
way that is clear and intuitive for a human being. This
is crucial not only to avoid the fear of considering AI as

Copyright c(cid:13) 2019, Association for the Advancement of Artiﬁcial
Intelligence (www.aaai.org). All rights reserved.

black boxes that may suddenly take harmful decisions in
the future, but also to contribute to the democratisation of
AI and increase trust on these systems.
The ﬁrst group of challenges is being widely addressed
by researchers, with tools to audit datasets and trained mod-
els to detect risks, and at the same time provide solutions
to mitigate those biases [6, 7]. The second group is ad-
dressed through the use of Explainable AI (XAI) techniques,
which generate post-hoc explanations based on the informa-
tion provided by the black box model. In the literature, there
are many XAI proposals for supervised ML models. How-
ever, some of the most recent and thorough reviews on XAI
[8, 9, 1, 10] do not mention the application of such tech-
niques to unsupervised learning.
In this paper we focus on unsupervised ML models used
for anomaly detection. Our main contribution is a novel al-
gorithmic solution to generate explanations for the particular
case of anomaly detection using OneClass SVM (OCSVM)
algorithms. Such explanations will be obtained using rule
extraction techniques.
We perform an empirical validation of the results of our
proposal using open datasets as well as real data from
Telef ´onica. Our evaluation consists in analysing whether the
number of rules for the non-anomalous data points are in-
ferior to the ones obtained for the anomalous data points.
We also compare the rules extracted with our algorithm with
those extracted with a surrogate Decision Tree (DT) trained
over the features and outputs of the unsupervised anomaly
detection model.
The rest of the paper is organized as follows. First, we
describe some related work in the area of XAI and rule ex-
traction applied to SVM. After identifying research oppor-
tunities derived from those works, the paper introduces the
algorithm implementation for OCSVM. Following this, we
present an empirical evaluation of our algorithm with several
datasets. We then conclude, showing also potential future re-
search lines of work.

Related Work

This section reviews unsupervised ML models used for
anomaly detection, and reviews previous work on rule ex-
traction in SVM that is relevant for our proposal.

 
 
 
 
 
 
Hence the hyper-parameters that must be deﬁned in this
method are the rejection rate, ν , and the type of kernel used.

Rule Extraction in SVM

Several papers deal with the importance of XAI applied
to models such as SVM. In particular [14] aims to resolve
the black box problem in SVM for supervised classiﬁcation
tasks. It obtains a set of rules that explain in a simple man-
ner the boundaries that contain the values of the different
classes. Thanks to that, it is easier to understand what are
the conditions that will identify a data point as belonging to
one class or to another (in OCSVM it would be belonging to
class +1 - normal data - or class -1 - anomaly -). The chal-
lenge consists in discovering a way to map the algorithm
results to a particular set of rules. There are two general
ways to do it. One consists in inferring the rules directly
from the decision frontier, using a decompositional rule ex-
traction technique. The other (simpler) one uses a method
called pedagogical rule extraction technique that does not
care about the decision frontier itself and considers the al-
gorithm as a black box from where to extract those rules de-
pending on which class it uses to classify different relevant
data points used as an input.
The ﬁrst method is clearly more transparent, as it deals
directly with the inner structure of the model. However, it
is generally more difﬁcult to implement. One way to imple-
ment it is with a technique known as SVM+ Prototypes [15],
which consists in ﬁnding hypercubes using the centroids (or
prototypes) of data points of each class and using as vertices
the data points from that hyperspace area farther away from
that centroid (or use directly the support vectors themselves
if they are available). It will then infer a rule from the values
of the vertices of the hypercube that contain the limits of all
the points inside it, creating one rule for each hypercube.
For example, a dataset that contains two numerical fea-
tures X and Y will be deﬁned in a 2-dimensional space. The
algorithm will create a square that contains the data points
on each of the classes, as shown in Figure 1. The rule that
justiﬁes that a data point belongs to class 2 is:
• Rule 1: CLASS 2 IF X≥X1 ∧ Y≥Y1 ∧ X≤X2 ∧ Y≤Y2

Unsupervised ML for Anomaly Detection

Many algorithms for unsupervised anomaly detection exist.
Examples are IsolationForest [11], Local anomaly Factor
(LOF) [12] and OCSVM [13]. The latter has relevant ad-
vantages over the former ones, mainly in terms of compu-
tational performance. This is due to the fact that it creates a
decision frontier using only the support vectors (like general
supervised SVM) and that model training always leads to the
same solution because the optimization problem is a convex
one. However, SVM (hence OCSVM) algorithms are some
of the most difﬁcult ones to explain due to the mathemati-
cally complex method that obtains the decision frontier.
SVM for classiﬁcation theoretically maps the data points
available in the dataset to a higher dimensional space than
the one determined by their features, so that the separation
among classes may be done linearly. It uses a hyperplane
obtained from data points from all of the classes. These data
points, known as support vectors, are the ones that are closer
to each other and the only ones needed to determine the de-
cision frontier. However, it is not really necessary to map to
a higher dimension due to the fact that the equation that ap-
pears in the optimization of the algorithm uses a dot product
of those mapped points. Because of that, the only thing to
be calculated is such dot product, something that can be ac-
complished with the well-known kernel trick. Hence instead
of calculating explicitly the mapping to a higher dimension
the equation is solved using a kernel function.
In OCSVM there are no labels. Hence all data points are
considered to belong to a same class at the beginning. The
decision frontier is computed trying to separate the region
of the hyperspace with a higher number of data points close
to each other from another that has small density, consider-
ing those points as anomalies. To do so the algorithm tries to
deﬁne a decision frontier that maximizes the distance to the
origin of the hyperspace and that at the same time separates
from it the maximum number of data points. This compro-
mise between those factors leads to the optimization of the
algorithm and allows obtaining the optimal decision fron-
tier. Those data points that are separated are labeled as non-
anomalous (+1) and the others are labeled as anomalous (-1).
The optimization problem is reﬂected in the following
equations:

n(cid:88)

i=1

minw,ξi ,ρ =

||w||2 +

1
2

1
ν n

(ξi − ρ)

subject to:

(w, φ(xi )) ≥ ρ − ξi f or i = 1, ..., n
ξi ≥ 0 f or i = 1, ..., n

(1)

In that equation, ν is a hyper-parameter known as rejec-
tion rate, which needs to be selected by the user. It sets an
upper bound on the fraction of anomalies that can be consid-
ered, and also deﬁnes a lower bound on the fraction of sup-
port vectors that can be considered. Using Lagrange tech-
niques, the decision frontier obtained is the following one:

f (x) = sgn((w, φ(xi ) − ρ) ⇒
αiK (xi , x) − ρ)

n(cid:88)

f (x) = sgn(

i=i

(2)

Figure 1: SVM with linear kernel classifying data points of
two classes.

The generated hypercubes may wrongly include points
from the other class when the decision frontier is not linear
or spherical, as shown in Figure 2. In this case the algorithm
considers an additional number of clusters trying to include
the points into a smaller hypercube, as shown in Figure 3.

Figure 2: A hypercube generated using the farthest points
leads to the wrong inclusion of data from the another class.

Figure 3: Using more hypercubes avoids the aforementioned
problem. Now there is no wrong inclusion of data points
from another class.

A rule will be generated for each hypercube, considering
all those scenarios as independent, leading to this output:
• Group 1: CLASS 1 IF X...
• Group 2: CLASS 1 IF X...
There are some downsides of that method in supervised
classiﬁcation tasks, especially when the problem is not sim-
ply a binary classiﬁcation or when the algorithm is perform-
ing a regression. For instance, the number of rules may grow
immensely due to the fact that a set of rules will be generated
for each category and each set may contain a huge number
of rule groups, leading to an incomprehensible output.
However, in OCSVM these difﬁculties may be potentially
mitigated due to two reasons. On the one hand, the explana-
tions are reduced to rules that explain when a data point is
not an anomaly (so there would be no need to deﬁne rules

for the anomalies). On the other hand, the algorithm tries to
group all non-anomalous points together, setting them apart
from the outliers. Because of this, the chance to deﬁne a hy-
percube that does not contain a point from the another class
may be higher than in a standard classiﬁcation task. Both
the unbalanced inherent nature of data points in anomaly de-
tection (few anomalies vs. many more non-anomalous data
points) and the fact that non-anomalous points tend to be
closer to each other may help achieving good results with
this method.

Method

We ﬁrst describe the intuition behind our rule extraction
approach from an OCSVM model for anomaly detection.
Then, we describe in detail the algorithm implementation.

Algorithm Intuition

We propose using rule extraction techniques within OCSVM
models for anomaly detection, by generating hypercubes
that encapsulate the non-anomalous data points, and using
their vertices as rules that explain when a data point is con-
sidered non-anomalous. Our method has the following char-
acteristics, according to the taxonomy for XAI in [10]:
• Post-hoc: Explainability is achieved using external tech-
niques.
• Global and individual: Explanations serve to explain how
the whole model works, as well as why a speciﬁc data
point is considered anomalous or non-anomalous.
• Model-agnostic: As with other techniques for global ex-
planations [10], the only information needed to build the
explanations are the input features and the outcomes of
the system after ﬁtting the model.
• Counterfactual: The explanations for why a data point is
anomalous also include information on the changes that
should take place in the feature values in order to consider
that data point as non-anomalous.
Since explanations are based on hypercubes, the OCSVM
kernel to be used is the Radial Basis Function (RBF), illus-
trated in Figure 4.

Figure 4: With an RBF Kernel the correct hypercube will be
the one that encloses the points that are not anomalies, since
the OCSVM algorithm will try to enclose most of the points
inside the decision frontier and leave anomalies outside.

The dimensionality of the hyperspace will correspond to
the different numerical features used for ﬁtting the model.
However, a caveat to be considered is when some features
are categorical non ordinal variables. In that case the approx-
imation would be to extract a rule for each of the possible
combinations of categorical values among the data points
that are not considered anomalous. Considering again the
aforementioned 2-dimensional example, with variable X be-
ing binary categorical, a dataset may look like in Figure 5:

Figure 5: Rule extraction with a categorical variable.

In that case, two rules would be extracted, one for each of
the possible states of X:
• Rule 1: NOT OUTLIER IF X = 0 ∧ Y ≥ Y2 ∧ Y ≤ Y1
• Rule 2: NOT OUTLIER IF X = 1 ∧ Y ≥ Y4 ∧ Y ≤ Y3
Generally speaking, the algorithm logic can be sum-
marised as:
• Apply OCSVM to the dataset to create the model.
• Depending on the characteristics of variables, do:
– Case 1. Numerical only: Iteratively create clusters in
the non-anomalous data (starting with one cluster) and
create a hypercube using the centroid and the points
further away from it. Check whether the hypercube
contains any data point from the anomalous group; if
it does, repeat using one more cluster than before. End
when no anomalies are contained in the generated hy-
percubes. If there are anomalies and the data points in a
cluster are inferior to the number of vertices needed for
the hypercube, complete the missing vertices with arti-
ﬁcial datapoints and end when there are no anomalies
or when the convergence criterion is reached.
– Case 2. Categorical only: The rules will correspond di-
rectly to the different value states contained in the
dataset of non-anomalous points.
– Case 3. Both numerical and categorical.
This
case
would be analogous to Case 1, but data points will be
ﬁltered for each of the combinations of the categorical
variables states. For each combination, there will be a
set of rules for the numerical features.
• Use these vertices to obtain the boundaries of that hyper-
cube and directly extract rules from them.

Algorithm Description

Algorithm 1 contains the proposal for rule extraction for
an OCSVM model that may be applied over a dataset
with either categorical or numerical variables (or both).
ocsvm rule extractor is the main function of the algorithm.
Regarding input parameters, X is the input data frame with
the features, ln is a list with the numerical columns, lc is
a list with the categorical columns, d is a dictionary with
the hyperparameters for OCSVM (since it is an RBF ker-
nel, the hyperparameters are the values for the upper bound
on the fraction of training errors and a lower bound of the
fraction of support vectors, ν , and the kernel coefﬁcient, γ ).
This function starts with the feature scaling of the numer-
ical features (function featureScaling). After that, it ﬁts an
OCSVM model with all the data available and detects the
anomalies within it, generating two datasets, Xy with the
anomalous data points and Xn with the rest (function ﬁlterA-
nomalies). The next step is assessing that the number of data
points within the decision frontier are enough to build the
hypercubes. In order to check this, the dimension of the hy-
percube should be lower than the number of non-anomalous
data points for that categorical state. The dimension of that
hypercube is computed using the number of numerical fea-
tures for each combination of categorical states; for each cat-
egorical state it will be 2len(ln ) , where len(ln ) is the length
of a list containing all the numerical columns names.
Next,
the algorithm checks whether features are nu-
merical, categorical or both. In case of only numerical
columns, it calls function getRules, described in Algorithm
2. getRules receives as input a matrix with anomalous and
non-anomalous data points, Xy and Xn respectively, and
the number of vertices for each hypercube, nv , based on
the number of numerical features. It also receives the list
of names of those numerical features, ln . The main purpose
of this function is to cluster non-anomalous data points in
a set of hypercubes that do not contain any anomalous data
points. To do that, it iteratively increases the number of clus-
ters (hypercubes) until there are no anomalous points within
any hypercube. The function outPosition checks whether the
rules deﬁned based on the vertices of the hypercube do not
include any data point from the anomalous subset, Xy .
getRules calls function getVertices with a speciﬁc number
of clusters, ncl . This function then performs the clustering
over the non-anomalous data points, Xn , using the function
getClusters that returns the label of the cluster for each data
point, as well as the centroid position for each cluster us-
ing the K-means++ algorithm [16]. Then, it iterates through
each cluster and ﬁrst obtains the subset of data points for that
cluster Xnc with the function insideC luster . After that, if
there are enough data points in that cluster (more data points
than the vertices of the hypercube) it computes the distance
of each of them to the centroid with computeDistance and
uses the furthest nv as vertices.
If there are not enough data points in that cluster (less than
the number of vertices for the hypercube), all of them are
used limits and the missing vertices are artiﬁcially generated
to close the hypercube (leaving outside all anomalous data
points).

Algorithm 1 Rule Extractor algorithm for OneClassSVM -
Main

for c ∈ lc do
end for

1: procedure OC SVM RUL E EX TRAC TOR(X, ln , lc , d)
X [:, c] ← f eatureS caling(X [:, c])
model ← OneC lassSV M (d)
model.f it(X )
preds ← model.train(X )
distances ← model.decisionF unction(X )
Xy , Xn ← f ilterAnomalies(X, preds)
if (len(lc ) + 1) × nv > Xn .rows then

nv ← 2len(ln )

return N one
else

continue

end if

else

else if len(l2 ) = 0 then

if len(l1 ) = 0 then
rules ← getRules(Xn , Xy , X, nv , ln )
rules ← getU nique(Xn , lc )
categories ← getU nique(Xn , lc )
for c ∈ categories do
Xnf , Xyf ← f ilterC ategory(Xn , Xy , c)
rules.append(getRules(Xnf , Xny , nv , ln ))

rules empty list

end for
end if

rules ← f eatureU nscaling(rules, ln )
rules ← pruneRules(rules, ln , lc )

2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:

return rules
31: end procedure

If all the features are categorical, then the rules for non-
anomalous data points will simply be the unique combina-
tion of values for them. If there are both categorical and nu-
merical features, the algorithm obtains the hypercubes (as
mentioned for numerical features only) for the subset of data
points associated to each combination of categorical values.
After obtaining the rules, function f eatureU nscaling is
used to express rules in their original values (not the scaled
ones used for the ML models). And function pruneRules
checks whether there are rules that may be included inside
others; that is, for each rule it checkes whether there is an-
other with a bigger scope that will include it as a subset case.
There is a convergence criteria, applied in the scenario
where a cluster has less data points than the number of ver-
tices. In this case, if there are anomalies within the hyper-
cube, the algorithm checks the number of data points within
the cluster Xnc versus a threshold deﬁned by the number
of vertices ncl multiplied by a reference value e. If there
are less data points than this threshold, then that cluster
is discarded and not considered for rule generation. Since
the proposal aims to explain what makes data points non-
anomalous and what should have happened to label a data
point as non-anomalous, this approximation is feasible.

2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:
21:
22:
23:
24:
25:
26:
27:
28:
29:
30:
31:

34:
35:
36:
37:
38:
39:
40:
41:
42:
43:
44:
45:
46:
47:

Algorithm 2 Rule Extractor algorithm for OneClassSVM -
Additional functions

1: procedure G ETRU LE S(Xn , Xy , nv , ln )

rules empty list
e reference value

check ← T rue

nclusters ← 0

while check do

ncl ← ncl + 1
vI nf o ← getV ertices(Xn , X, nv , ln , ncl )
for iterV alue ∈ vI nf o do
rulescluster ← iterV alue[0]
Xnc ← iterV alue[1]
rules.append(rulescluster )
if len(rulescluster ) = len(Xn ) then
if Xnc > e × ncl then
check ← T rue
break
check ← F alse

else

end if
else

if ly = 0 then

ly ← outP osition(rulescluster , Xy )
check ← F alse
check ← T rue
break

else

end if
end if
end for
end while
return rules
32: end procedure

33: procedure G ETV ERT ICE S(Xn , nv , ln , ncl )

dbounds empty list
dpoints empty list

for c ∈ ncl do

labels, centroids ← getC lusters(Xn , ln , ncl )
Xnc ← insideC luster(labels, Xn )
if len(Xnc ) > nv then
vertices ← computeDist(Xnc , labels[c])
vertices ← Xn

else

end if

dbounds .append(vertices)
dpoints .append(Xnc )

end for

return dbounds , dpoints

48: end procedure

Evaluation

We use our algorithm over different datasets (both public
and from Telefonica’s real data), to evaluate the following
hypotheses:
• The OCSVM algorithm with an RBF decision fron-

tier groups non-anomalous points within a hypersphere.
Hence the number of rules extracted using non-anomalous
data will be fewer than using anomalous ones.
• Our algorithm yields a number of rules similar to other
proposals for global model-agnostic explanations, such as
Surrogate Trees.
In our experiments we will count the number of rules ex-
tracted in different scenarios, and check whether there are
signiﬁcative differences. Several experiments are conducted
over different datasets:
• Rule extraction over non-anomalous data points with our
algorithm.
• Rule extraction over anomalous data points with our al-
gorithm. In this scenario, there is no convergence criteria
since the number of anomalous data points will be very
low (many times lower than the number of vertices).
• Rule extraction over all the data points using a DT over-
ﬁtted in the dataset, using the features as input and the
anomalous/non-anomalous labels as target variable. This
yields two types of rules, the ones that explain the anoma-
lous data points, and the ones that explain the non-
anomalous ones.
The used datasets belong to different domains, have dif-
ferent sizes and different number of features (both categori-
cal and numerical). They are indicated in Table 1:
• Datasets 1 and 2 about seismic activity [17]. Dataset 1 is
bi-dimensional with only numerical features (’gdenergy’,
’gdpuls’). Dataset 2 has 2 categorical features (’hazard’,
’shift’) and 7 numerical (’seismoacoustic’, ’shift’, ’gen-
ergy’, ’gplus’, ’gdenergy’, ’gdpuls’, ’hazard’, ’bumps’,
’bumps2’).
• Dataset 3 from a call center at Telef ´onica. It is real data
that includes the total number of calls received in one
of its services during every hour. Using these data, some
features are extracted (weekday), and they are cyclically
transformed, so that each time feature turns into two fea-
tures for the sine and cosine components. The rules in this
case are also transformed back into the original features in
order to enhance rule comprehension.
• Dataset 4 about cardiovascular diseases [18]. There are
4 categorical features (’smoke’, ’alco’, ’active’, ’is man’)
and 7 numerical
(’age’,
’height’,
’weight’,
’ap hi’,
’ap lo’,’cholesterol’,’gluc’).
• Datasets 5 and 6 on the US census for year 1990
[19]. Dataset 5 has 2 categorical features (’dAncstry1 3’,
’dAncstry1 4’) and 4 numerical ones (’dAge’, ’iYearsch’,
’iYearkwrk’, ’dYrsserv’). Dataset 6 has the same numer-
ical features, but 18 categorical ones (dAncstry i j with i
that ranges fro 1 to 2, and j that ranges from 3 to 11 if i
equals 1, and 2 to 10 if i equals 2.)
We ran experiments with the following infrastructure: the
implementations of the OCSVM algorithm, the K-Means++
clustering and the DT algorithms are based on Scikit-Learn
[20]. The rest of the code described in Algorithms 1 and 2
were developed from scratch, and available in Github [21].

Dataset
1
2
3
4
5
6

Ref.
[17]
[17]
Telef ´onica
[18]
[19]
[19]

No Cat. No Num. No Rows
0
2
669
2
7
1705
0
5
2712
4
7
42000
2
4
100000
18
4
200000

Table 1: Description of each dataset, with their reference
(Ref.), categorical features (No Cat.), numerical features (No
Num) and number of rows.

OCSVM models use as hyperparameters: ν = 0.1, γ =

0.1, kernel = rbf . K-means++ models use max iter =
100, n init = 10, random state = 0. The DT hyperpa-

rameters are dynamically set for each dataset, using the Gini
criterion to ﬁnd the best splits, and using randoms tate =
42 as seed. For each dataset, the DT is as follows:
• 1: Depth = 11, Nodes = 53, Leaf nodes = 30
• 2: Depth = 17, Nodes = 129, Leaf nodes = 69
• 3: Depth = 13, Nodes = 159, Leaf nodes = 91
• 4: Depth = 27, Nodes = 2265, Leaf nodes = 1184
• 5: Depth = 17, Nodes = 353, Leaf nodes = 162
• 6: Depth = 30, Nodes = 1843, Leaf nodes = 1051
Results are detailed in Table 2. It shows the number of
rules extracted for all datasets with the different algorithms.

Dataset
1
2
3
4
5
6

Prop. [NA]
89
33
151
4754
249
762

Prop. [A] DT [NA] DT [A]
25
11
14
20
30
93
37
36
72
45
171
63
185
62
26
762
86
11

Table 2: Number of rules extracted using our algorithm
(Prop.) or the surrogate DT over anomalous (A) and non-
anomalous (NA) data points.

Hypothesis 1 is not validated. Table 2 shows that the num-
ber of rules for anomalous data points is always inferior to
those for non-anomalous ones. This may be due to the fact
that the pruning algorithm is not good enough yet for rule
reduction. For instance, one rule is removed if another wider
rule includes it. However, many times the rules are not in-
cluded within only one wider rule, but within many wider
rules all together. This can be visually seen using dataset 1.
Figures 6 and7 show the rules obtained before and after ap-
plying the pruning algorithm. Although the number of rules
is reduced, many rules may still be removed. This affects
more the rules obtained with non-anomalous data points
since they are closer than the ones obtained with anomalous
ones, as shown in Figure 8 (here, points without a visible hy-
percube are due to the fact that all the vertices are the same;
thus, it is the same point as the anomaly).

Figure 6: Hypercubes in a 2D space for non-anomalous data
(before pruning).

Figure 7: Hypercubes in a 2D space for non-anomalous data
(after pruning).

Figure 8: Hypercubes in a 2D space for anomalous data (af-
ter pruning).

Regarding hypothesis 2, in most of the cases DT generates
less rules than our algorithm (with the exception of anoma-
lous data points in dataset 4). However, results may be con-
sidered similar.
Figures 9 and 10 show a sample rule over the same dataset
for our algorithm and for the DT surrogate method, respec-
tively. The DT method uses symbols for equality and in-
equalities, while in our method all the extracted rules use
only ≥ and ≤, and not > or <.

Limitations of our Approach

Our method can only be used if there is a minimum number
of data points (at least one point per vertex for the hyper-
cube). This limitation may be avoided by generating artiﬁ-
cial vertices, as done for clusters with few data points.

Figure 9: A sample rule for non-anomalous data points for
dataset 4 using our proposal

Figure 10: A sample rule for non-anomalous data points for
dataset 4 using the DT surrogate method

Conclusion

We described a novel implementation of a rule extraction
technique for model-agnostic, both global and local, and
counterfactual explanations for unsupervised learning in the
scenario of anomaly detection, using the OCSVM algorithm.
We applied our algorithm to open and private datasets,
with anomalous and non-anomalous data, with the initially
unexpected result that using anomalous data points yields
less rules than using the non-anomalous ones. We also com-
pared the results of our algorithm with other surrogate meth-
ods such as using a DT model trained over the same fea-
tures and using as target variable the anomalous or non-
anomalous labels. In most scenarios both methods yielded
similar results, thus showing that our approach is a feasible
technique for XAI for anomaly detection.

Future Work

Our rule extraction method can be optimised by using dif-
ferent clustering algorithms, so as to analyse whether there
is a reduction in the number or rules that are extracted. It
will be interesting to compare cluster methods that consider
together both categorical non ordinal as well as numerical
features, instead of dividing the hyperspace according to the
categorical value combinations, as we did in our work. One
example of such algorithm is K-modes [22]. Besides, when
there are clusters with anomalies, instead of increasing the
number of clusters and apply it over the whole dataset, the
algorithm may separate data points that are already inside a
cluster without anomalies and apply a different clustering al-
gorithm to partition the subspace that had anomalies. It will
be interesting to compare the number of rules extracted with
this approach versus the one in this paper.
Rule extraction should also be designed to consider all
types of comparisons (≥, ≤, > and <), and more sophisti-
cated pruning techniques should be applied to improve rule
reduction, since a rule may be contained in two or more rules
together.

[14] David Martens et al. “Rule extraction from support
vector machines: an overview of issues and applica-
tion in credit scoring”. In: Rule extraction from sup-
port vector machines. Springer, 2008, pp. 33–63.
[15] Haydemar N ´u ˜nez, Cecilio Angulo, and Andreu
Catal `a. “Rule extraction from support vector ma-
chines”. In: Esann. 2002, pp. 107–112.
[16] David Arthur and Sergei Vassilvitskii. “k-means++:
The advantages of careful seeding”. In: Proceedings
of the eighteenth annual ACM-SIAM symposium on
Discrete algorithms. Society for Industrial and Ap-
plied Mathematics. 2007, pp. 1027–1035.
[17] Saket Sathe and Charu Aggarwal. “LODES: Local
density meets spectral outlier detection”. In: Proceed-
ings of the 2016 SIAM International Conference on
Data Mining. SIAM. 2016, pp. 171–179.
[18] Meghana Padmanabhan et al. “Physician-friendly
machine learning: A case study with cardiovascu-
lar disease risk prediction”. In: Journal of clinical
medicine 8.7 (2019), p. 1050.
[19] Catherine Blake. “UCI repository of machine learn-
ing databases”.
In: http://www.
ics. uci. edu/˜
mlearn/MLRepository. html (1998).
[20] F. Pedregosa et al. “Scikit-learn: Machine Learning in
Python”. In: Journal of Machine Learning Research
12 (2011), pp. 2825–2830.
[21] Alberto Barbado. Rule extraction in unsupervised
outlier detection for XAI. https : / / github . com /
AlbertoBarbado / unsupervised - outlier - transparency.
2019.
[22] Anil Chaturvedi, Paul E Green, and J Douglas Car-
oll. “K-modes clustering”. In: Journal of classiﬁca-
tion 18.1 (2001), pp. 35–55.

References

[1] Alejandro Barredo Arrieta et al. Explainable Artiﬁ-
cial Intelligence (XAI): Concepts, Taxonomies, Op-
portunities and Challenges toward Responsible AI.
2019. https://arxiv.org/abs/1910.10045. arXiv: 1910 .

10045 [cs.AI].

[2] Richard
Benjamins, Alberto
Barbado,
and
Daniel Sierra. Responsible AI by Design. 2019.
https://arxiv.org/abs/1909.12838. arXiv: 1909 . 12838

[cs.CY].

[3] Till Speicher et al. “A Uniﬁed Approach to Quan-
tifying Algorithmic Unfairness”. In: Proceedings of
the 24th ACM SIGKDD International Conference on
Knowledge Discovery and Data Mining - KDD ’18
(2018). DO I: 10 . 1145 / 3219819 . 3220046. URL: http :
//dx.doi.org/10.1145/3219819.3220046.
[4] Moritz Hardt, Eric Price, and Nathan Srebro. “Equal-
ity of Opportunity in Supervised Learning”. In: Pro-
ceedings of the 30th International Conference on
Neural Information Processing Systems. NIPS’16.
Barcelona, Spain: Curran Associates Inc., 2016,
pp. 3323–3331. I SBN: 978-1-5108-3881-9. UR L: http:
//dl.acm.org/citation.cfm?id=3157382.3157469.
[5] Brian Hu Zhang, Blake Lemoine, and Margaret
Mitchell. Mitigating Unwanted Biases with Adversar-
ial Learning. 2018. https://arxiv.org/abs/1801.07593.
arXiv: 1801.07593 [cs.LG].
[6] Rachel KE Bellamy et al. “AI fairness 360: An exten-
sible toolkit for detecting, understanding, and miti-
gating unwanted algorithmic bias”. In: arXiv preprint
arXiv:1810.01943 (2018).
[7] Pedro Saleiro et al. “Aequitas: A Bias and Fairness
Audit Toolkit”. In: arXiv preprint arXiv:1811.05577
(2018).
[8] Leilani H Gilpin et al. “Explaining explanations: An
overview of interpretability of machine learning”. In:
2018 IEEE 5th International Conference on data sci-
ence and advanced analytics (DSAA). IEEE. 2018,
pp. 80–89.
[9] Shane T Mueller et al. “Explanation in Human-AI
Systems: A Literature Meta-Review, Synopsis of Key
Ideas and Publications, and Bibliography for Ex-
plainable AI”. In: arXiv preprint arXiv:1902.01876
(2019).
[10] Christoph
Molnar.
Interpretable
ma-
chine
learning.
Lulu.com,
2019.
https://christophm.github.io/interpretable-ml-book/.
[11] Fei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou.
“Isolation forest”. In: 2008 Eighth IEEE Interna-
tional Conference on Data Mining. IEEE. 2008,
pp. 413–422.
[12] Markus M Breunig et al. “LOF: identifying density-
based local outliers”. In: ACM sigmod record. Vol. 29.
2. ACM. 2000, pp. 93–104.
[13] Bernhard Sch ¨olkopf et al. “Support vector method for
novelty detection”. In: Advances in neural informa-
tion processing systems. 2000, pp. 582–588.

