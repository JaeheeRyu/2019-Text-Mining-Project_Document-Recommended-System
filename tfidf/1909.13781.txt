Groups with ALOGTIME-hard word problems and
PSPACE-complete compressed word problems

Laurent Bartholdi

ENS Lyon, Unité de Mathématiques Pures et Appliquées, France
Universität Göttingen, Mathematisches Institut, Germany
laurent.bartholdi@gmail.com

Michael Figelius

Universität Siegen, Germany
ﬁgelius@eti.uni-siegen.de

Markus Lohrey

Universität Siegen, Germany
lohrey@eti.uni-siegen.de

Armin Wei\ 3

Universität Stuttgart, Institut für Formale Methoden der Informatik (FMI), Germany
armin.weiss@fmi.uni-stuttgart.de

Abstract

We give lower bounds on the complexity of the word problem of certain non-solvable groups: for a
large class of non-solvable inﬁnite groups, including in particular free groups, Grigorchuk’s group
and Thompson’s groups, we prove that their word problem is NC1 -hard. For some of these groups
(including Grigorchuk’s group and Thompson’s groups) we prove that the compressed word problem
(which is equivalent to the circuit evaluation problem) is PSPACE-complete.
2012 ACM Subject Classiﬁcation Theory of computation → Circuit complexity
Keywords and phrases NC1 -hardness, word problem, G-programs, straight-line programs, non-
solvable groups, self-similar groups, Thompson’s groups, Grigorchuk’s group

Funding Michael Figelius : Funded by DFG project LO 748/12-1.
Markus Lohrey : Funded by DFG project LO 748/12-1.
Armin Wei\377: Funded by DFG project DI 435/7-1.

Acknowledgements The authors are grateful to Schlo\377 Dagstuhl and the organizers of Seminar
19131 for the invitation, where this work began.

1

Introduction

The word problem of a ﬁnitely generated group G is the most fundamental algorithmic
problem in group theory: given a word over the generators of G, the question is whether this
word represents the identity of G. The original motivation for the word problem came from
topology and group theory [15], within Hilbert’s “Entscheidungsproblem”. Nevertheless, it
also played a role in early computer science when Novikov and Boone constructed ﬁnitely
presented groups with an undecidable word problem [10, 49]. Still, in many classes of groups
it is (eﬃciently) decidable, a prominent example being the class of linear groups: Lipton and
Zalcstein [41] (for linear groups over a ﬁeld of characteristic zero) and Simon [53] (for linear
groups over a ﬁeld of prime characteristic) showed that their word problem is in LOGSPACE.
The class NC1 consists of those languages that are accepted by families of boolean circuits
of logarithmic depth. When combined with certain uniformity conditions it yields the subclass
ALOGTIME which is is contained in LOGSPACE — so it is a very small complexity class of
problems eﬃciently solvable in parallel. A striking connection between the word problem for
groups and complexity theory was established by Barrington [4]: for every ﬁnite non-solvable

9
1
0
2

v
o

N

1
2

]

R

G

.

h

t

a

m

[

2
v
1
8
7
3
1

.

9
0
9
1

:

v

i

X

r

a

7
7
 
 
 
 
 
 
2

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

group G, the word problem of G is NC1 -complete. Moreover, the reduction is as simple
as it could be: every output bit depends on only one input bit. Thus, one can say that
NC1 is completely characterized via group theory. Moreover, this idea has been extended to
characterize ACC0 by solvable monoids [5]. On the other hand, the word problem of a ﬁnite
p-group is in ACC0 [p], so Smolensky’s lower bound [54] implies that it is strictly easier than
the word problem of a ﬁnite non-solvable group.
Barrington’s construction is based on the observation that an and-gate can be simulated
by a commutator. This explains the connection to non-solvability. In this light it seems
natural that the word problem of ﬁnite p-groups is not NC1 -hard: they are all nilpotent, so
iterated commutators eventually become trivial. For inﬁnite groups, a construction similar
to Barrington’s was used by Robinson [50] to show that the word problem of a non-abelian
free group is NC1 -hard. Since by [41] the word problem of a free group is in LOGSPACE, the
complexity is narrowed down quite precisely (although no completeness results has been
shown so far).
The ﬁrst contribution of this paper is to identify the essence of Barrington’s and Robinson’s
constructions. For this we introduce a strengthened condition of non-solvability, which we
call SENS (strongly eﬃciently non-solvable); see Deﬁnition 15. In a SENS group there are
balanced nested commutators of arbitrary depth and whose word length grows at most
exponentially. We also introduce uniformly SENS groups, where these balanced commutators
are eﬃciently computable in a certain sense. We then follow Barrington’s arguments and show
that every for every (uniformly) SENS group the word problem is hard for (uniform) NC1
(Theorems 31 and 32). That means that for every non-solvable group G, the word problem for
G is NC1 -hard, unless the word length of the G-elements witnessing the non-solvability grows
very fast (we also give in Example 25 a non-solvable group in which the latter happens).
Finite non-solvable groups and non-abelian free groups are easily seen to be uniformly
SENS. We go beyond these classes and present a general criterion that implies the uniform
SENS-condition. Using this criterion we show that Thompson’s groups [12] and weakly
branched self-similar groups [6, 48] are uniformly SENS. As a corollary we get:
(cid:73) Corollary A. The word problems for Thompson’s groups as wel l as al l weakly branched
self-similar groups are hard for uniform NC1 .

Thompson’s groups F < T < V (introduced in 1965) belong due to their unusual properties to
the most intensively studied inﬁnite groups. From a computational perspective it is interesting
to note that all three Thompson’s groups are co-context-free (i.e., the set of all non-trivial
words over any set of generators is a context-free language) [38]. This implies that the word
problems for Thompson’s groups are in LOGCFL. To the best of our knowledge no better
upper complexity bound is known. Weakly branched groups form an important subclass of
the self-similar groups [48], containing several celebrated groups like the Grigorchuk group
(the ﬁrst example of a group with intermediate word growth) and the Gupta-Sidki groups.
We also show that the word problem for contracting self-similar groups is in LOGSPACE.
This result is well-known, but to the best of our knowledge no proof appears in the literature.
The Grigorchuk group as well as the Gupta-Sidki groups are contracting.
Another corollary of Theorem 32 is the following dichotomy result for ﬁnitely generated
linear groups: for every ﬁnitely generated linear group the word problem is in DLOGTIME-
uniform TC0 or ALOGTIME-hard (Theorem 33). To prove this we use Tits alternative (every
ﬁnitely generated linear group either contains a free group of rank two or is virtually solvable)
[55] together with a result from [35] stating that the word problem for a ﬁnitely generated
solvable linear group is in DLOGTIME-uniform TC0 .

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

3

In the second part of the paper we study the compressed word problem [44]. This is a
succinct version of the word problem, where the input word is represented by a so-called
straight-line program. A straight-line program is a context-free grammar that produces
exactly one string. The length of this string can be exponentially larger than the size of
the straight-line program. The compressed word problem for a ﬁnitely generated group G
is equivalent to the circuit evaluation problem for G. In the latter the input is a circuit
where the input gates are labelled with generators of G and the internal gates compute the
product of their inputs. There is a distinguished output gate, and the question is whether
this output gate evaluates to the group identity. For ﬁnite groups (and also monoids), the
circuit evaluation problem has been studied in [8]. The circuit viewpoint also links the
compressed word problem to the famous polynomial identity testing problem (the question
whether an algebraic circuit over a polynomial ring evaluates to the zero-polynomial); see [52]
for a survey: it is shown in [44] that the compressed word problem for the group SL3 (Z) is
equivalent to polynomial identity testing problem with respect to polynomial time reductions
[44, Theorem 4.16].
From a group theoretic viewpoint, the compressed word problem is interesting not only
because group elements are naturally represented as straight line programs, but also because
several classical (uncompressed) word problems reduce to compressed word problems. For
instance, the word problem for a ﬁnitely generated subgroup of Aut(G) reduces to the
compressed word problem for G [44, Theorem 4.6]. Similar statements hold for certain group
extensions [44, Theorems 4.8 and 4.9]. This motivates the search for groups in which the
compressed word problem can be solved eﬃciently. For the following groups, the compressed
word problem can be solved in polynomial time: ﬁnitely generated nilpotent groups [35]
(for which the compressed word problem can be even solved in NC2 ), hyperbolic groups [30]
and virtually special groups [44]. The latter are deﬁned as ﬁnite extensions of subgroups
of right-angled Artin groups and form a very rich class of groups containing for instance
Coxeter groups [23], fully residually free groups [60] and fundamental groups of hyperbolic
3-manifolds [2]. Moreover, for ﬁnitely generated linear groups the compressed word problem
belongs to coRP (complement of randomized polynomial time).
In this paper, we are mainly interested in groups in which the compressed word problem
is hard or intractable. Indeed, it is known that the compressed word problem for non-solvable
ﬁnite groups and non-abelian free groups is P-complete [8, 42]. The proofs for these results
use again the above mentioned constructions of Barrington and Robinson. Starting from
this observation we introduce a variant of the uniform SENS-condition and show that every
group satisfying this condition has a P-hard compressed word problem. However, we go even
further: Recently, Wächter and the fourth author constructed an automaton group (a ﬁnitely
generated group of tree automorphism, where the action of generators is deﬁned by a Mealy
automaton) with a PSPACE-complete word problem and EXPSPACE-complete compressed
word problem [58] – thus, the compressed word problem is provably more diﬃcult than the
word problem. The group arises from a quite technical construction; in particular one cannot
call this group natural. Here, we exhibit several natural groups (that were intensively studied
in other parts of mathematics) with a PSPACE-complete compressed word problem and a
word problem in LOGSPACE:
(cid:73) Corollary B. The compressed word problem for the fol lowing groups is PSPACE-complete:
wreath products G o Z where G is ﬁnite non-solvable or free of rank at least two, Thompson’s
groups, the Grigorchuk group, and al l Gupta-Sidki groups.
The group theoretic essence in order to get PSPACE-hardness is a certain self-embedding
property: we need a group G such that a wreath product G o A embeds into G for some

4

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

A 6= 1. Thompson’s group F has this property for A = Z [21]. For a weakly branched group
G that satisﬁes an additional technical condition (the branching subgroup K of G is ﬁnitely
generated and has elements of ﬁnite order) we show that one can take A = Z/p for some
p ≥ 2. The above self-embedding property allows us to carry out a subtle reduction from the
leaf language class deﬁned by the group G to the compressed word problem for G.

2

General notations

For a, b ∈ Z we write [a..b] for the interval {z ∈ Z | a ≤ z ≤ b}. We use common notations
from formal language theory. In particular, we use Σ∗ to denote the set of words over an
alphabet Σ including the empty word ε. Let w = a0 · · · an−1 ∈ Σ∗ be a word over Σ (n ≥ 0,
a0 , . . . , an−1 ∈ Σ). The length of w is |w| = n. We write Σ≤d for {w ∈ Σ∗ | |w| ≤ d}
and Σ<d for {w ∈ Σ∗ | |w| < d}. For a letter a ∈ Σ let |w|a = |{i | a = ai }| be the
number of occurrences of a in w. For 0 ≤ i < n let w[i] = ai and for 0 ≤ i ≤ j < n let
w[i : j ] = aiai+1 · · · aj . Moreover w[: i] = w[0 : i]. Note that in the notations w[i] and w[i : j ]
we take 0 as the ﬁrst position in w. This will be convenient later.
The lexicographic order on N∗ is deﬁned as follows: a word u ∈ N∗ is lexicographically
smaller than a word v ∈ N∗ if either u is a preﬁx of v or there exist w, x, y ∈ N∗ and i, j ∈ N
such that u = wix, v = wj y , and i < j .
A ﬁnite order tree is a ﬁnite set T ⊆ N∗ such that for all w ∈ N∗ , i ∈ N: if wi ∈ T , then
w, wj ∈ T for every 0 ≤ j < i. The set of children of u ∈ T is uN

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

5

The word problem may be stated for any group whose elements may be written as words
over a ﬁnite alphabet. This applies to subquotients H/K of G (also if H is not ﬁnitely
generated): given a word w ∈ Σ∗ with the guarantee that it belongs to H , does it actually
belong to K ? Note that the decidability of this problem depends on the actual choice of H
and K , not just on the isomorphism type of H/K .
We will consider groups G that act on a set X on the left or right. For g ∈ G and
x ∈ X we write xg ∈ X (resp., gx) for the result of a right (resp., left) action. A particularly
important case arises when G = Sym(X ) is the symmetric group on a set X , which acts on
X on the right.

3.1 Wreath products

A fundamental group construction that we shall use is the wreath product : given groups G
and H acting on the right on sets X and Y respectively, their wreath product G o H is a
group acting on X × Y . We start with the restricted direct product G(Y ) (the base group) of
all mappings f : Y → G having ﬁnite support supp(f ) = {y | f (y) 6= 1} with the operation
of pointwise multiplication. The group H has a natural left action on G(Y ) : for f ∈ G(Y )
and h ∈ H , we deﬁne hf ∈ G(Y ) by (hf )(y) = f (yh ). The corresponding semidirect product
G(Y ) (cid:111) H is the wreath product G o H . In other words:
Elements of G o H are pairs (f , h) ∈ G(Y ) × H and we simply write f h for this pair.
The multiplication in G o H is deﬁned as follows: Let f1h1 , f2h2 ∈ G o H . Then f1h1 f2h2 =
f1 h1f2h1h2 , where the product f1 h1f2 : y 7→ f1 (y)f2 (yh1 ) is the pointwise product.
The wreath product G o H acts on X × Y by (x, y)f h = (xf (y) , yh ). The wreath product
deﬁned above is also called the (restricted) permutational wreath product. There is also the
variant where G = X and H = Y and both groups act on themselves by right-multiplication,
which is called the (restricted) regular wreath product (or standard wreath product). A subtle
point is that the permutational wreath product is an associative operation whereas the
regular wreath product is in general not. The term “restricted” refers to the fact that the
base group is G(Y ) , i.e., only ﬁnitely supported mappings are taken into account. If G(Y ) is
replaced by GY (i.e., the set of all mappings from Y to G with pointwise multiplication), then
one speaks of an unrestricted wreath product. For Y ﬁnite this makes of course no diﬀerence.
There will be only two situations (Examples 25 and 26) where we need an unrestricted wreath
product. The action of G on X is usually not important for us, but it is nice to have an
associative operation. For the right group H , we will only make use of the following cases:
H = Sym(Y ) acting on Y .
H a (ﬁnite or inﬁnite) cyclic group acting on itself.
Note that if G is generated by Σ and H is generated by Γ then G o H is generated by Σ ∪ Γ.

3.2 Richard Thompson’s groups

In 1965 Richard Thompson introduced three ﬁnitely presented groups F < T < V acting on
the unit-interval, the unit-circle and the Cantor set, respectively. Of these three groups, F
received most attention (the reader should not confuse F with a free group). This is mainly
due to the still open conjecture that F is not amenable, which would imply that F is another
counterexample to a famous conjecture of von Neumann (a counterexample was found by
Ol’shanskii). A standard reference of Thompson’s groups is [12]. The group F consists of all
homeomorphisms of the unit interval that are piecewise aﬃne, with slopes a power of 2 and

6

ALOGTIME-hard word problems and PSPACE-complete compressed word problems



2t

t + 1
4
2 + 1
2

t

x0 (t) =

2 ,

dyadic breakpoints. Famously, F is generated by two elements x0 , x1 deﬁned by
if 0 ≤ t ≤ 1
if 1
if 1
2 ≤ t ≤ 1,
The pattern repeats with xn+1 acting trivially on the left subinterval and as xn on the right
subinterval. We have xk+1 = xxi
k for all i < k . In fact,

if 0 ≤ t ≤ 1
if 1
2 ≤ t ≤ 1.

t
2 + x0 (2t−1)
1
2

4 ,
4 ≤ t ≤ 1
2 ,

x1 (t) =

(

F = hx0 , x1 , x2 , . . . | xxi
k = xk+1 (i < k)i = hx0 , x1 | [x0x−1
1 , x−1
0 x1x0 ], [x0x−1
1 , x−2
0 x1x2

0 ]i. (1)
The group F is orderable (so in particular torsion-free), its derived subgroup [F , F ] is simple
and the center of F is trivial. Important for us is the following fact:
(cid:73) Lemma 1 ([21, Lemma 20]). The group F contains a subgroup isomorphic to F o Z.
Proof. The copy of Z is generated by x0 , and the copies of F in F (Z) are the conjugates of
1 i under powers of x0 .
(cid:74)
It follows, by iteration, that F contains arbitrarily iterated wreath products Z o · · · o Z, as
well as the limit ((· · · o Z) o Z) o Z.

hx1x2x−2
1 , x2
1x2x−3

3.3 Weakly branched groups

We continue our list of examples with an important class of groups acting on rooted trees.
For more details, the monographs [6, 48] serve as good references.
Let X be a ﬁnite set.1 The free monoid X ∗ serves as the vertex set of a regular rooted tree
with an edge between v and vx for all v ∈ X ∗ and all x ∈ X . The group W of automorphisms
of this tree naturally acts on the set X of level-1 vertices, and permutes the subtrees hanging
from them. Exploiting the bijection X + = X ∗ × X , we thus have an isomorphism
ϕ : W → W o Sym(X ) = W X (cid:111) Sym(X ),
(2)
mapping g ∈ W to elements f ∈ W X and π ∈ Sym(X ) as follows: π is the restriction of g to
X ⊆ X ∗ , and f is uniquely deﬁned by (xv)g = xπ vf (x) . We always write g@x for f (x) and
call it the state (or coordinate) of g at x. If X = [0..k ], we write g = hhg@0, . . . , g@kiiπ .
(cid:73) Deﬁnition 2. A subgroup G ≤ W is self-similar if ϕ(G) ≤ G o Sym(X ). In other words:
the actions on subtrees xX ∗ are given by elements of G itself. A self-similar group G is
weakly branched if there exists a non-trivial subgroup K ≤ G with ϕ(K ) ≥ K X . In other
words: for every k ∈ K and every x ∈ X the element acting as k on the subtree xX ∗ and
trivial ly elsewhere belongs to K . A subgroup K as above is cal led a branching subgroup.
Note that we are weakening the usual deﬁnition of “weakly branched”: indeed it is usually
additionally required that G act transitively on X n for all n ∈ N. This extra property is not
necessary for our purposes, so we elect to simply ignore it. In fact, all the results concerning
branched groups that we shall use will be proven directly from Deﬁnition 2.
Note also that the join hK1 ∪ K2 i of two branching subgroups K1 and K2 is again a
branching subgroup. Hence, there exists a maximal branching subgroup. It immediately

1 There will be one occasion (Proposition 27), where we will allow an inﬁnite X .

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

7

follows from the deﬁnition that, if G is weakly branched, then for every v ∈ X ∗ there is in G
a copy of its branching subgroup K whose action is concentrated on the subtree vX ∗ . We
denote this copy with v ∗ K . With v ∗ k (k ∈ K ) we denote the element of K acting as k on
the subtree vX ∗ and trivially elsewhere.
Our main focus is on ﬁnitely generated groups. We ﬁrst note that the group W itself
Πn+1 = ϕ−1 (Πn o Π). We clearly have Πn ≤ Πn+1 , and we set Π∞ = S
is weakly branched. Here are countable weakly branched subgroups of W : For a subgroup
Π of Sym(X ), deﬁne Π∞ ≤ W as follows: set Π0 = 1 ≤ W (the trivial subgroup) and
n≥0 Πn . In words, Πn
consists of permutations of X ∗ that may only modify the ﬁrst n symbols of strings, and Π∞
consists of permutations that may only modify a bounded-length preﬁx of strings. Clearly
Π∞ is countable and ϕ(Π∞ ) = Π∞ o Π.
Numerous properties are known to follow from the fact that a group is weakly branched.
For example, it satisﬁes no group identity [1]. In fact, if G is a weakly branched self-similar
group and its branching subgroup K contains an element of order p, then it K contains a
copy of (Z/p)∞ , see [6, Theorem 6.9].
There exist important examples of ﬁnitely generated self-similar weakly branched groups,
notably the Grigorchuk group G, see [19]. It may be described as a self-similar group in the
following manner: it is a group generated by {a, b, c, d}, and acts on the rooted tree X ∗ for
X = {0, 1}. The action, and therefore the whole group, are deﬁned by the restriction of ϕ to
G’s generators:
ϕ(a) = (0, 1), ϕ(b) = hha, cii, ϕ(c) = hha, dii, ϕ(d) = hh1, bii,

where we use the notation (0, 1) for the non-trivial element of Sym(X ) (that permutes 0 and
1) and hhw0 , w1 ii for a tuple in G{0,1} ∼= G × G. We record some classical facts:
(cid:73) Lemma 3. The Grigorchuk group G is inﬁnite, torsion, weakly branched, and al l its ﬁnite
subquotients are 2-groups (so in particular nilpotent). It has a branching subgroup K of ﬁnite
index, which is therefore ﬁnitely generated.

(Recall that every weakly branched group is inﬁnite and non-solvable, since it satisﬁes no
identity. There are also easy direct proofs of these facts.)
ϕ((cid:2)[b, a], d(cid:3)) = hh1, [b, a]ii so ϕ(K ) ≥ K × K and G is weakly branched; see also [6] for details.
Proof. That G is an inﬁnite torsion group is one of the raison d’être of G, see [19]. Let
K ≤ G be the normal closure of [b, a] in G. It is easy to see that it has index 16, and
It is known that every element of G has order a power of 2 [19], so the same holds for every
(cid:74)
subquotient of G.

Other examples of ﬁnitely generated self-similar weakly branched groups with a f.g. branching
subgroup include the Gupta-Sidki groups [22], the Hanoi tower groups [20], and all iterated
monodromy groups of degree-2 complex polynomials [7] except z 2 and z 2 − 2.

3.4 Contracting self-similar groups

Recall the notation g@x for the coordinates of ϕ(g). We iteratively deﬁne g@v = g@x1 · · · @xn
for any word v = x1 · · · xn ∈ X ∗ .
(cid:73) Deﬁnition 4 ([48, Deﬁnition 2.11.1]). A self-similar group G is cal led contracting if there
is a ﬁnite subset N ⊆ G such that, for al l g ∈ G, we have g@v ∈ N whenever v is long
enough (depending on g).

8

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

If G is a ﬁnitely generated contracting group with word norm k · k (i.e., for g ∈ G, kgk is the
length of a shortest word over a ﬁxed generating set of G that represents g), then a more
quantitative property holds: there are constants 0 < λ < 1, h ≥ 1 and k ≥ 0 such that for all
g ∈ G we have
kg@vk ≤ λkgk + k for all v ∈ X h ,
see e.g. [31, Proposition 9.3.11]. Then, for c = −h/ log λ and a possibly larger k we have
g@v ∈ N whenever |v | ≥ c log kgk + k . One of the cornerstones of Nekrashevych’s theory
of iterated monodromy groups is the construction of a contracting self-similar group that
encodes a given expanding self-covering of a compact metric space. It is well-known and easy
to check that the Grigorchuk group, the Gupta-Sidki groups and the Hanoi tower group for
three pegs are contracting. The following result has been quoted numerous times, but has
never appeared in print. A proof for the Grigorchuk group may be found in [17]:
(cid:73) Proposition 5. Let G be a ﬁnitely generated contracting self-similar group. Then WP(G)
can be solved in LOGSPACE (deterministic logarithmic space).
Proof. Fix a ﬁnite generating set Σ for G and assume that G is contracting with 0 < λ < 1,
h ≥ 1 and k ≥ 0 as above. We can assume that k ≥ 1. Let N be the nucleus of G. By replacing
the tree alphabet X by X h we get kg@xk ≤ λkgk + k for all x ∈ X . Hence, if kgk ≤ k/(1 − λ)
then also kg@xk ≤ k/(1 − λ) for all x ∈ X . We now replace Σ by the set of all g ∈ G with
kgk ≤ k/(1 − λ) (note that k/(1 − λ) ≥ 1) and get ϕ(Σ) ⊆ ΣX × Sym(X ). Furthermore,
there exists m such that every non-trivial element of N acts non-trivially on X m . Recall
that for c = −1/ log λ and a possibly larger k we have g@v ∈ N whenever |v | ≥ c log kgk + k .
Hence, if g is non-trivial then there must exist a v ∈ X ∗ with |v | = c log kgk + k + m such
that g does not ﬁx v .
The following algorithm solves WP(G): given g ∈ Σ∗ , enumerate all vertices in X d for
d = c log |g | + k + m, and return “true” precisely when they are all ﬁxed by g . The algorithm
is correct by the previous remarks, and it remains to show that it requires logarithmic space.
The vertices in X d are traversed by lexicographically enumerating them. They can be stored
explicitly since their length is bounded by O(log |g |). Now given a vertex v ∈ X d , we apply
the letters of g to it one after the other. Again, this is done by a simple loop requiring
O(log |g |) bits. Finally, to apply a generator to v , we use the property that all its states are
generators (ϕ(Σ) ⊆ ΣX × Sym(X )), and traverse v by performing |v | lookups in the table
(cid:74)
storing (ϕ(a))a∈Σ .

4

Complexity theory

We assume that the reader is familiar with the complexity classes LOGSPACE (deterministic
logarithmic space), P (deterministic polynomial time), and PSPACE (polynomial space); see
e.g. [3] for details. With polyL we denote that union of all classes NSPACE(logc n) for a
constant c. Since we also deal with sublinear time complexity classes, we use Turing machines
with random access (this has no inﬂuence on the deﬁnition of the above classes). Such a
machine has an additional index tape and some special query states. Whenever the Turing
machine enters a query state, the following transition depends on the input symbol at the
position which is currently written on the index tape in binary notation.
We use the abbreviations DTM (deterministic Turing machine), NTM (non-deterministic
Turing machine) and ATM (alternating Turing machine). An ATM is an NTM together with
a partition of the state set into existential and universal states. A conﬁguration is called

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

9

existential (resp., universal) if the current state in the conﬁguration is existential (resp.,
universal). An existential conﬁguration is accepting if there exists an accepting successor
conﬁguration, whereas a universal conﬁguration is accepting if all successor conﬁgurations are
accepting. Note that a universal conﬁguration which does not have a successor conﬁguration is
accepting, whereas an existential conﬁguration which does not have a successor conﬁguration
is non-accepting. Finally, an input word is accepted if the corresponding initial conﬁguration
is accepted. An ATM is in input normal form if its input alphabet is {0, 1} and on any
computation path it queries at most one input bit and halts immediately after returning the
value of the input bit or its negation (depending on the current state of the Turing machine).
We deﬁne the following complexity classes:
DLINTIME: the class of languages that can be accepted by a DTM in linear time.
DLOGTIME: the class of languages that can be accepted by a DTM in logarithmic time.
ALOGTIME: the class of languages that can be accepted by an ATM in logarithmic time.
APTIME: the class of languages that can be accepted by an ATM in polynomial time.
If X is one of the above classes we speak of an X -machine with the obvious meaning. It
is well known that APTIME = PSPACE. Moreover, every language in ALOGTIME can be
recognized by an ALOGTIME-machine in input normal form [56, Lemma 2.41].
A nand-machine is an NTM in which each conﬁguration has either zero or two successor
conﬁgurations and conﬁgurations are declared to be accepting, respectively non-accepting,
according to the following rules, where c is a conﬁguration:
If c has no successor conﬁgurations and the state of c is ﬁnal (resp., non-ﬁnal) then c is
accepting (resp., non-accepting).
If c has two successor conﬁgurations and both of them are accepting then c is not
accepting.
If c has two successor conﬁgurations and at least one them is non-accepting then c is
accepting.
Since the boolean functions and and or can be obtained with nand, it follows easily that
PSPACE (resp., ALOGTIME) coincides with the class of all languages that can be accepted
by a polynomially (resp., logarithmically) time-bounded nand-machine.
For a complexity class C we denote by ∀C the class of all languages L such that there exists
a polynomial p(n) and a language K ∈ C such that L = {u | ∀v ∈ {0, 1}p(|u|) : u#v ∈ K }.
We have for instance ∀P = coNP and ∀PSPACE = PSPACE. Likewise we deﬁne the class
L = (cid:8)u | |{v ∈ {0, 1}p(|u|) : u#v ∈ K }| 6≡ 0 mod m(cid:9).
ModmC by L ∈ ModmC if there exists a polynomial p(n) and a language K ∈ C such that

4.1 Eﬃciently computable functions

A function f : Γ∗ → Σ∗ is DLOGTIME-computable if there is some polynomial p with |f (x)| ≤
p(|x|) for all x ∈ Γ∗ and the set Lf = {(x, a, i) | x ∈ Γ∗ and the i-th letter of f (x) is a}
belongs to DLOGTIME. Here i is a binary coded integer. Note that a DLOGTIME-machine
for Lf can ﬁrst (using binary search) compute the binary coding of |x| in time O(log |x|).
Assume that the length of this binary coding is ‘. If i has more than ‘ bits, the machine can
reject immediately. As a consequence of this (and since |Σ| is a constant), the running time of
a DLOGTIME-machine for Lf on input (x, a, i) can be bounded by O(log |x|) (independently
of the actual bit length of i). We can also assume that the DLOGTIME-machine outputs
the letter a on input of x and i. In case i > |x| we can assume that the machine outputs
a distinguished letter. A DLOGTIME-reduction is a DLOGTIME-computable many-one
reduction. We say that a DLOGTIME-machine strongly computes a function f : Σ∗ → Γ∗
with |f (x)| ≤ C log(|x|) for all x ∈ Σ∗ and for some constant C if it computes the function

10

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

value by writing it sequentially on a separate output tape (be aware of the subtle diﬀerence
and that strong DLOGTIME-computability is not a standard terminology, but is coincides
with FDLOGTIME in [13].)
A PSPACE-transducer is a deterministic Turing-machine with a read-only input tape,
a write-only output tape and a work tape, whose length is polynomially bounded in the
input length n. The output is written sequentially on the output tape. Moreover, we assume
that the transducer terminates for every input. This implies that a PSPACE-transducer
computes a mapping f : Σ∗ → Γ∗ , where |f (x)| is bounded by 2|x|O(1) . We call this mapping
PSPACE-computable. We need the following simple lemma, see [45]:
(cid:73) Lemma 6. Assume that the mapping f : Σ∗ → Γ∗ is PSPACE-computable and let L ⊆ Γ∗
be a language in polyL. Then f −1 (L) belongs to PSPACE.

4.2 Leaf languages

In the following, we introduce basic concepts related to leaf languages, more details can
be found in [11, 26, 28, 29, 33]. An NTM M with input alphabet Γ is adequate, if (i) for
every input x ∈ Γ∗ , M does not have an inﬁnite computation on input x, (ii) the ﬁnite set of
transition tuples of M is linearly ordered, and (iii) when terminating M prints a symbol α(q)
from a ﬁnite alphabet Σ, where q is the current state of M . For an input x ∈ Γ∗ , we deﬁne
the computation tree by unfolding the conﬁguration graph of M from the initial conﬁguration.
By condition (i) and (ii), the computation tree can be identiﬁed with a ﬁnite ordered tree
T (x) ⊆ N∗ . For u ∈ T (x) let q(u) be the M -state of the conﬁguration that is associated with
the tree node u. Then, the leaf string leaf (M , x) is the string α(q(v1 )) · · · α(q(vk )) ∈ Σ+ ,
where v1 , . . . , vk are all leaves of T (x) listed in lexicographic order.
An adequate NTM M is called balanced, if for every input x ∈ Γ∗ , T (x) is a complete
binary tree. With a language K ⊆ Σ∗ we associate the language
LEAF(M , K ) = {x ∈ Γ∗ | leaf (M , x) ∈ K }.
Finally, we associate two complexity classes with K ⊆ Σ∗ :
LEAF(K ) = {LEAF(M , K ) | M is an adequate polynomial time NTM}
bLEAF(K ) = {LEAF(M , K ) | M is a balanced polynomial time NTM}
These classes are closed under polynomial time reductions. We clearly have bLEAF(K ) ⊆
LEAF(K ). The following result was shown in [33] by padding computation trees to complete
binary trees.
(cid:73) Lemma 7. Assume that K ⊆ Σ∗ is a language such that Σ contains a symbol 1 with the
fol lowing property: if uv ∈ K for u, v ∈ Σ∗ then u1v ∈ K . Then LEAF(K ) = bLEAF(K ).
In particular, we obtain the following lemma:
(cid:73) Lemma 8. Let G be a ﬁnitely generated group and Σ a ﬁnite standard generating set for
G. Then LEAF(WP(G, Σ)) = bLEAF(WP(G, Σ)).

Moreover, we have:
(cid:73) Lemma 9. Let G be ﬁnitely generated group and Σ, Γ ﬁnite standard generating sets for
G. Then LEAF(WP(G, Σ)) = LEAF(WP(G, Γ)).

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

11

Proof. Consider a language L ∈ LEAF(WP(G, Σ)). Thus, there exists an adequate polyno-
mial time NTM M such that L = LEAF(M , WP(G, Σ)). We modify M as follows: If M
terminates and prints the symbol a ∈ Σ, it enters a small nondeterministic subcomputation
that produces the leaf string wa , where wa ∈ Γ∗ is a word that evaluates to the same group
element as a. Let M 0 be the resulting adequate polynomial time NTM. It follows that
LEAF(M , WP(G, Σ)) = LEAF(M 0 , WP(G, Γ)).
(cid:74)

Lemma 9 allows to omit the standard generating set Σ in the notations LEAF(WP(G, Σ))
and bLEAF(WP(G, Σ)). We will always do that. In [28] it was shown that PSPACE =
LEAF(WP(G)) for every ﬁnite non-solvable group.

4.3 Circuit complexity

We deﬁne a polynomial length projection (or just projection) as a function f : {0, 1}∗ → {0, 1}∗
such that there is a function d(n) ∈ O(log n) with |f (x)| = |f (y)| = 2d(n) for all x, y with |x| =
|y | = n and such that each output bit depends on at most one input bit in the following sense:
For every n ∈ N, there is a mapping qn : {0, 1}d(n) → {hj, a, bi | j ∈ [1..n], a, b, ∈ {0, 1}},
where qn (i) = hj, a, bi means that for all x ∈ {0, 1}n the i-th bit of f (x) is a if the j -th
bit of x is 1 and b if it is 0. Here, we identify i ∈ {0, 1}d(n) with a binary coded number
from [0..2d(n) − 1] (so the ﬁrst position in the output is zero). We also assume that the
input position j ∈ [1..n] is coded in binary, i.e., by a bit string of length O(log n). Note
that the output length 2d(n) is polynomial in n. Restricting the output length to a power
of two (instead of an arbitrary polynomial) is convenient for our purpose but in no way
crucial. Our deﬁnition of a projection is the same as in [13] except for our restriction on
the output length. Moreover, in [13] projections were deﬁned for arbitrary alphabets. Let
q : {1}∗ × {0, 1}∗ → {0, 1}∗ × {0, 1} × {0, 1} with q(1n , v) = qn (v). We assume that q(1n , v)
is a special dummy symbol if |v | 6= d(n). We call q the query mapping associated with
the projection f . The projection f is called uniform if (i) 1d(n) is strongly computable in
DLOGTIME from the string 1n , and (ii) q is strongly DLOGTIME-computable. Notice that if
a language K is reducible to L via a uniform projection, then K is also DLOGTIME-reducible
to L.
We are mainly interested in the circuit complexity class NC1 . A language L ⊆ {0, 1}∗ is
in NC1 if it can be recognized by a family of logarithmic depth boolean circuits of bounded
fan-in. More precisely, L ⊆ {0, 1}∗ belongs to NC1 if there exists a family (Cn )n≥0 of boolean
circuits which, apart from the input gates x1 , . . . , xn , are built up from not-, and- and or-gates.
In the following we also use nand-gates. All gates must have bounded fan-in, where the
fan-in of a gate is the number of incoming edges of the gate. Without loss of generality,
we assume that all and-, or- and nand-gates have fan-in two. The circuit Cn must accept
exactly the words from L

12

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

[56] (but we will not need the above deﬁnition of DLOGTIME-uniformity). For a language L
over a non-binary alphabet Σ, one ﬁrst has to ﬁx a binary encoding of the symbols in Σ. For
membership in NC1 the concrete encoding is irrelevant. However, we still assume that all
letters of Σ are encoded using the same number of bits.
The class AC0 is deﬁned as the class of languages (respectively functions) accepted
(respectively computed) by circuits of constant depth and polynomial size with not-gates and
unbounded fan-in and- and or-gates.
We will also work with a very restricted class of circuit families, where every circuit is a
complete binary tree of nand-gates. For such a circuit, all the information is given by the
labelling function for the input gates.
(cid:73) Deﬁnition 10. A family of balanced nand-tree-circuits of logarithmic depth (Cn )n∈N is given
by a mapping d(n) ∈ O(log n) and a query mapping q : {1}∗×{0, 1}∗ → {0, 1}∗×{0, 1}×{0, 1},
which deﬁnes a projection f mapping bit strings of length n to bit strings of length 2d(n) . The
corresponding circuit Cn for input length n is then obtained by taking {0, 1}≤d(n) as the set of
gates. Every gate v ∈ {0, 1}<d(n) computes the nand of v0 and v1. If x ∈ {0, 1}n is the input
string for Cn and f (x) = a1a2 · · · a2d(n) , then the i-th leaf v ∈ {0, 1}d(n) (in lexicographic
order) is set to ai .
(cid:73) Lemma 11. For every L in (non-uniform) NC1 there is a (non-uniform) family of balanced
nand-tree-circuits of logarithmic depth.
Proof. The proof is straightforward: clearly, or, and, and not gates can be simulated by
nand gates. Now take the circuit Cn for input length n. We ﬁrst unfold Cn into a tree by
duplicating gates with multiple outputs. Since Cn has constant fan-in and logarithmic depth,
the resulting tree has still polynomial size (and logarithmic depth). To transform this tree
into a complete binary tree, we replace leafs by complete binary subtrees. If we replace
a leaf labelled with xi by a subtree of even (resp. odd) height, then we label all leafs of
the subtree with hi, 1, 0i (resp., hi, 0, 1i). This labelling deﬁnes the query mapping q in the
natural way.
(cid:74)
(cid:73) Lemma 12. For every L in ALOGTIME there is a family C = (Cn )n≥0 of balanced nand-
tree-circuits of logarithmic depth such that the mapping 1n 7→ 1d(n) and the query mapping q
from Deﬁnition 10 can be strongly computed in DLOGTIME.
Proof sketch. We start with an ALOGTIME-machine M for L and construct a circuit family
with the required properties. We can assume that M works in two stages: ﬁrst it computes
the binary coding of the input length in DLOGTIME (using binary search). The second
stage performs the actual computation. We can assume that the second stage is in input
normal form [56, Lemma 2.41] meaning that each computation path queries exactly one
input position i and halts immediately after querying that position (returning a bit that is
determined by the i-th bit of the input). Furthermore, we can assume that the computation
tree of the second stage of M is a complete binary tree. For this we enforce all computation
paths to be of the same length. Note that the running time of the second stage of M can
be bounded by c · |u|, where c is a ﬁxed constant and u is the binary coding of the input
length which has been computed before. Hence, the the second stage of the machine makes
in parallel to the actual computation c runs over u. Finally, we also assume that there is
an alternation in every step (this can be ensured as in the transformation of an arbitrary
NC1 -circuit into a balanced nand-tree-circuit) and that the initial state is existential. The
computation tree gives a tree-shaped circuit in a natural way (for details see [56, Theorem
2.48]). The depth of this tree is d := c · |u| (whose unary encoding is strongly computable in

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

13

DLOGTIME by the above arguments). Since we start with an existential state and there is
an alternation in every step, the resulting circuit uses only nand-gates (recall that x nand y
= (not x) or (not y)). The fact that every computation path queries only one input position
yields the query function q from Deﬁnition 10. More precisely, let v ∈ {0, 1}d be an input
gate of the balanced nand-tree-circuit. Then v determines a unique computation path of M .
We simulate M in DLOGTIME along this path and output the triple hi, a, bi if M queries the
i-th position of the input string (note that the binary coding of i must be on the query tape
of M ) and outputs a (resp., b) if the i-th input bit is 1 (resp., 0).
(cid:74)

4.3.1 G-programs

For inﬁnite groups we have to adapt Barrington’s notion of a G-program slightly. Our
notation follows [56].

(cid:73) Deﬁnition 13. Let G be a group with the ﬁnite standard generating set Σ. Recal l our
assumption that 1 ∈ Σ. A (G, Σ)-program P of length m and input length n is a sequence
of instructions hij , bj , cj i for 0 ≤ j ≤ m − 1 where ij ∈ [1..n] and bj , cj ∈ Σ. On input of
a word x = a1 · · · an ∈ {0, 1}∗ , an instruction hij , bj , cj i evaluates to bj if aij = 1 and to cj
otherwise. The evaluation of a (G, Σ)-program is the product (in the speciﬁed order) of the
evaluations of its instructions, and is denoted with P [x] ∈ Σ∗ .
A family P = (Pn )n∈N of (G, Σ)-programs, where Pn has input length n, deﬁnes a function
fP : {0, 1}∗ → G: fP (x) is the group element represented by P|x| [x]. The language L accepted
by the family of (G, Σ)-programs is the set of words x ∈ {0, 1}∗ such that fP (x) = 1 in G.
For brevity, we also speak of a family of G-programs instead of (G, Σ)-programs with the
understanding that there is some ﬁnite standard generating set Σ which is shared by al l
programs of the family.

Notice two diﬀerences compared with the original deﬁnition: ﬁrstly, we ﬁx the ﬁnite alphabet
Σ, and secondly, for the accepted language we only take the preimage of 1 instead of a ﬁnite
set of ﬁnal states. The latter is more restrictive, but for the purpose of NC1 -hardness causes
no diﬀerence.
A family P = (Pn )n∈N of (G, Σ)-programs is called uniform if the length of Pn is 2d(n)
for some function d(n) ∈ O(log n), the mapping 1n 7→ 1d(n) is strongly computable in
DLOGTIME, and the mapping that assigns to 1n and j ∈ {0, 1}d(n) (the latter is interpreted
as a binary coded number) the instruction hij , bj , cj i of the n-input program Pn is strongly
computable in DLOGTIME. Notice that ij requires log n bits and bj , cj require only a
constant number of bits — thus, the tuple hij , bj , cj i can be written down in DLOGTIME.
Be aware that here we slightly diﬀer from [56, Deﬁnition 4.42].
(cid:73) Remark 14. If a language L is accepted by a family of polynomially length-bounded
(G, Σ)-programs (by padding one can enforce the length to be of the form 2d(n) ), then L is
reducible via projections to WP(G) – and, thus, also via AC0 -many-one reductions. This
can be seen as follows: encode every letter in Σ by a word over {0, 1} of some ﬁxed constant
length. Then the map assigning the evaluation of the (G, Σ)-program to an input word
is a uniform projection since the output at every position depends on only one input bit.
A similar statement holds in the uniform case (uniformity follows immediately from the
deﬁnition): if L is accepted by a uniform family of (G, Σ)-programs, then L is reducible via
uniform projections to WP(G).

14

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

5

Eﬃciently non-solvable groups

(b) gd,v = (cid:2)gd,v0 , gd,v1

We now deﬁne the central group theoretic property that allows us to carry out a Barrington
style construction:
(cid:73) Deﬁnition 15. We cal l a group G with the ﬁnite standard generating set Σ strongly
eﬃciently non-solvable (SENS) if for every d ∈ N there is a col lection of 2d+1 − 1 elements
gd,v ∈ Σ∗ for v ∈ {0, 1}≤d such that
(cid:3) for al l v ∈ {0, 1}<d (here we take the commutator of words),
(a) there is some constant µ ∈ N with |gd,v | = 2µd for al l v ∈ {0, 1}d ,
(c) gd,ε 6= 1 in G.
The group G is cal led uniformly strongly eﬃciently non-solvable if, moreover,
(d) given v ∈ {0, 1}d , a binary number i with µd bits, and a ∈ Σ one can decide in DLINTIME
whether the i-th letter of gd,v is a.
If Q = H/K is a subquotient of G, we cal l Q SENS in G if G satisﬁes the conditions of a
SENS group, al l gd,v evaluate to elements of H , and gd,ε 6∈ K . This deﬁnition is already
interesting for K = 1.
Here are some simple observations:
A strongly eﬃciently non-solvable group clearly cannot be solvable, so the above termi-
nology makes sense.
If one can ﬁnd suitable gd,v of length at most 2µd , then these words can always be padded
to length 2µd thanks to the padding letter 1.
It suﬃces to specify gd,v for v ∈ {0, 1}d ; the other gd,v are then deﬁned by Condition (b).
We have |gd,v | = 2µd+2(d−|v |) for all v ∈ {0, 1}≤d . Thus, all gd,v have length 2O(d) .
Equivalently to Condition (d), we can require that given v ∈ {0, 1}d and a binary number
i with µd bits, one can compute the i-th letter of gd,v in DLINTIME.
Henceforth, whenever d is clear, we simply write gv instead of gd,v .
We can formulate a weaker condition than being strongly eﬃciently non-solvable which is
suﬃcient for our purposes, but slightly more complicated to state:
(cid:73) Deﬁnition 16. We say G is eﬃciently non-solvable (ENS) if there is a constant l such
that for every d ∈ N, there is a col lection of (2l)d+1 − 1 elements (gd,v ,w )(v ,w)∈({0,1}×[1..l])≤d
such that
(a) |gd,v ,w | ∈ 2O(d) when |v | = d,
(c) gd,ε,ε 6= 1 in G.
Analogously to Deﬁnition 15, we deﬁne a group G to be uniformly eﬃciently non-solvable
if the letters of gd,v ,w for |v | = |w| = d can be computed in DLINTIME, and a subquotient
Q = H/K of G to be (uniformly) eﬃciently non-solvable in G if the gd,v ,w evaluate to
elements of H with gd,ε,ε 6∈ K .
We begin with simple observations. We only state the proofs for the case of (uniformly)
SENS. The analogous statements for (uniformly) ENS follow exactly the same way.
(cid:73) Lemma 17. The property of being (uniformly) (S)ENS is independent of the choice of the
standard generating set.
Proof. Let Σ0 be another standard generating set. Then, for some constant integer k , every
element of Σ may be written (thanks to the padding letter 1) as a word of length 2k in Σ0 . In
particular, if gd,v has length 2µd with respect to Σ, then it has length 2k+µd with respect to

(b) gd,v ,w = [gd,v0,w1 , gd,v1,w1 ] · · · [gd,v0,wl , gd,v1,wl ] when |v | < d,

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

15

given v , and i, it runs the DLINTIME-algorithm for Σ on input v and (cid:4)i/2k (cid:5), obtaining a
Σ0 . There is also a simple DLINTIME-algorithm for computing the i-th letter of gd,v ∈ (Σ0 )∗ :
letter σ ∈ Σ. Then, it looks up the length-2k representation of σ over Σ0 , and extracts the
(i mod 2k )-th letter of that representation.
(cid:74)

Later (Example 26) we will give an example of a f.g. non-ENS group H which is uniformly
SENS in a group G.
(cid:73) Lemma 18. If Q = H/K is a ﬁnitely generated subquotient of a ﬁnitely generated group
G and Q is (uniformly) (S)ENS, then G is also (uniformly) (S)ENS.
Proof. Let Γ be a standard generating set of Q and ﬁx for every a ∈ Γ an element ha ∈ H ≤ G
such that ha is mapped to a under the canonical projection π : H → Q = H/K . By Lemma 17
we can assume that all elements ha belong to the generating set of G. Let hd,v ∈ Γ∗ be the
words witnessing the fact that Q is (uniformly) (S)ENS (in Deﬁnition 15 they are denoted
with gd,v ). We then deﬁne words gd,v by replacing every letter a in hd,v by the letter ha .
Clearly, π(gd,v ) = hd,v holds. In particular, gd,ε is non-trivial, since hd,ε is non-trivial. (cid:74)
(cid:73) Lemma 19. If G is (uniformly) (S)ENS, then the commutator subgroup G0 is (uniformly)
(S)ENS in G.
Proof. Given d ∈ N, produce the words gd+1,v with |v | ≤ d + 1 witnessing the property for
G, and consider the same words with |v | ≤ d. They witness the same property for G0 . In
(cid:74)
eﬀect, we are truncating the leaves of a tree of commutators in G.

The following is a stronger version of Lemma 19:
(cid:73) Lemma 20. If G is (uniformly) (S)ENS and N a normal subgroup such that G/N is
solvable, then N is (uniformly) (S)ENS in G.

Proof. Assume that G/N is solvable of derived length δ . Hence, any δ -fold nested commutator
of elements in G is contained in N . We only prove the theorem for the case that G
is (uniformly) SENS; the same argument applies if G is (uniformly) ENS. Let hd,v be
the elements witnessing that G is (uniformly) SENS. Given d and v ∈ {0, 1}≤d deﬁne
gd,v = hd+δ,v . Then all these elements are δ -fold nested commutators and, hence, contained
(cid:74)
in N . Thus, the elements gd,v witness that N is (uniformly) SENS in G.
(cid:73) Lemma 21. If G is (S)ENS and N a solvable normal subgroup of G, then G/N is (S)ENS.
Be aware that we do not know whether there is a variant of Lemma 21 for uniformly (S)ENS.
The problem is to compute the word u in the proof below.

Proof. Again, we only prove the statement for the case that G is SENS. As in the proof
of Lemma 20, let hd,v for d ∈ N and v ∈ {0, 1}≤d denote the elements witnessing that G is
SENS. Let δ denote the derived length of N . Assume for contradiction that all the elements
hd+δ,v for v ∈ {0, 1}δ are in N . Then, hd+δ,ε would be trivial because it is a δ -fold nested
commutator of the hd+δ,v for v ∈ {0, 1}δ and the derived length of N is δ . Thus, there exists
some u ∈ {0, 1}δ such that hd+δ,u 6∈ N . We ﬁx this u and set gd,v = hd+δ,uv for v ∈ {0, 1}≤d .
Since gd,ε = hd+δ,u 6∈ N , this shows that G/N is SENS.
(cid:74)
(cid:73) Lemma 22. If G is (uniformly) (S)ENS, then G/Z (G) is (uniformly) (S)ENS.

16

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

Proof. As before, let hd,v for d ∈ N and v ∈ {0, 1}≤d denote the elements witnessing that G
is (uniformly) SENS. We set gd,v = hd+1,0v for v ∈ {0, 1}≤d . Then gd,ε = hd+1,0 cannot be
in Z (G) for otherwise hd+1,ε = [gd,ε , hd+1,1 ] would be trivial. This shows that G/Z (G) is
(uniformly) SENS.
(cid:74)
The following result is, for G = A5 , the heart of Barrington’s argument:
(cid:73) Lemma 23. If G is a ﬁnite non-solvable group, then G is uniformly SENS.
Proof. Let us ﬁrst show the statement for a non-abelian ﬁnite simple group G. By the proof
of Ore’s conjecture [39], every element of G is a commutator. This means that we may choose
gε 6= 1 at will, and given gv we deﬁne gv0 , gv1 by table lookup, having chosen once and for
all for each element of G a representation of it as a commutator. Computing gv requires |v |
steps and bounded memory.
If G is ﬁnite non-solvable, then any composition series of G contains a non-abelian simple
composition factor Gi /Gi+1 . Hence, we can apply Lemma 18.
(cid:74)
Notice that at the time of Barrington’s original proof [4], Ore’s conjecture was not known to
hold. Therefore, he could only use what we deﬁned as ENS in order to establish his result on
NC1 -hardness.
By Lemma 18 and Lemma 23, every group having a subgroup with a ﬁnite, non-solvable
quotient is uniformly SENS. Since every free group projects to any ﬁnite simple group, we
get:
(cid:73) Corollary 24. If Fn is a ﬁnitely generated free group of rank n ≥ 2, then Fn is uniformly
SENS.
This result was essentially shown by Robinson [50], who showed that the word problem of a
free group of rank two is NC1 -hard. He used a similar commutator approach as Barrington.
One can prove Corollary 24 also directly by exhibiting a free subgroup of inﬁnite rank whose
generators are easily computable. For example, in F2 = hx0 , x1 i take gv = x−v
v ∈ {0, 1}d viewing the string v as a binary number (the other gv for v ∈ {0, 1}<d are then
deﬁned by the commutator identity in Deﬁnition 15), and appropriately padding with 1’s. It
is even possible to take the gv of constant length: consider a free group F = hx0 , x1 , x2 i, and
the elements gv = xv mod 3 with v read as the binary representation of an integer. It is easy
to see that the nested commutator gε is non-trivial.
(cid:73) Example 25. Here is a ﬁnitely generated group that is not solvable, has decidable word
H0 ≤ H1 , which induces for all n an embedding Hn ≤ Hn+1 . We set H = S
problem, but is not ENS. The construction is inspired from [59].
Start with the trivial group H0 = 1 and set Hn+1 = Hn o Z. We have a natural embedding
and denote by x0 , x1 , . . . the generators of H , starting with Z = hx0 i.
In particular,
Hd := hx0 , . . . , xd i is solvable of class precisely d − 1 whereas H is non-solvable.
For an injective function τ : N → N to be speciﬁed later, consider in the unrestricted
wreath product H
Z (cid:111) Z the subgroup G generated by the following two elements:
the generator t of Z and
the function f : Z → H deﬁned by f (τ (n)) = xn and all other values being 1.
We make the assumption that τ has the following property: For every integer z ∈ Z \ {0}
there is at most one pair (m, i) ∈ N × N with z = τ (m) − τ (i). For instance, the mapping
τ (n) = 2n has this property.
Let us deﬁne the conjugated mapping fi = tτ (i) f t−τ (i) ∈ G. We have fi (0) = xi and
more generally fi (τ (m) − τ (i)) = xm (and f −1
(τ (m) − τ (i)) = x−1
m ) for all m. Consider now

0 x1xv0 for

n≥0 Hn ,

i

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

17

√

Z

g(z ) = xe

ik

ik

i1 · · · xαk

ik

jl

j1 · · · f βl

jl

i1 · · · xαk

ik

i1 · · · f αk

i1 · · · f αk

j1 · · · xβl
, xβ1

a product g = f α1
(α1 , . . . , αk ∈ {−1, 1}). We get g(0) = xα1
. For a position
z ∈ Z \ {0} which is not a diﬀerence of two diﬀerent τ -values we have g(z ) = 1. For all other
non-zero positions z there is a unique pair (m, i) such that z = τ (m) − τ (i), which yields
m , where e is the sum of those αj such that ij = i. Hence, the commutator [g , h] of
two mappings g = f α1
and h = f β1
satisﬁes [g , h](0) = [xα1
]
and [g , h](z ) = 0 for all z ∈ Z \ {0}. Hence, G contains the restricted wreath product
[H, H ] o Z, so in particular is inﬁnite and non-solvable; and G0 contains the restricted direct
product [H, H ](Z) .
We now assume that τ grows superexponentially (take for instance τ (n) = 2n2 ). Note
that if k ∈ Z is not of the form τ (i) − τ (j ) for some i, j ∈ N, then tk f t−k and f commute. It
follows that the intersection of G00 with the ball of radius R in G is contained in [Hd , Hd ]Z
for d growing sublogarithmically in R (more precisely as O(
log R)), and in particular does
not contain a nested non-trivial commutator of depth Ω(log R). This implies that G is not
Furthermore, if τ is computable, then WP(G) is decidable: given a word w ∈ (cid:8)t±1 , f ±1(cid:9)∗ ,
SENS (and in fact not ENS).
compute its exponent sum in the letters t±1 and f ±1 (which must both vanish if w =G 1)
and the coordinates −|w|, . . . , |w| of its image in H
Z . Each of these coordinates belongs to a
ﬁnitely iterated wreath product Z o · · · o Z, in which the word problem is decidable (again by
counting exponents and computing coordinates).
(cid:73) Example 26. Here is an example of a f.g. non-ENS group which is uniformly SENS in a
larger group. We continue on the notation of Example 25.
Consider the non-ENS group G = ht, f i from Example 25. The reason that G fails to be
uniformly SENS is the following: there are elements yi ∈ G (i ≥ 0) such that a non-trivial
depth-d nested commutator may uniformly be constructed using y0 , . . . , yd−1 , but the yi
have length growing superexponentially in i.
distorted subgroup in a ﬁnitely generated subgroup eG := ht, f , ˜t, ˜f i of the unrestricted wreath
Essentially by the same construction as in Example 25 one can embed G as a heavily
takes value yi at 2i . Then G is uniformly SENS in eG, since the [yi , yj ] are expressible as
product G
Z (cid:111) Z, thereby bringing the yi back to exponential length: the elements t, f are the
generators of G, seen as elements of G
Z supported at 0; ˜t is the generator of Z; and ˜f ∈ G
words of length 2O(i+j ) in ˜f , ˜t, and their inverses.
The following technical result will be used to prove that weakly branched groups and
Thompson’s group F are uniformly SENS.
(cid:73) Proposition 27. Let G be a ﬁnitely generated group with the standard generating set Σ.
Moreover, let hd (d ∈ N) be words over Σ with |hd | ∈ 2O(d) and such that given 1d and a
binary coded number i with O(d) bits one can compute in DLINTIME the i-th letter of hd .
Assume that H = hh0 , h1 , . . . i acts on a tree of words X ∗ (where X is not necessarily ﬁnite),
and that X contains pairwise distinct elements v−1 , v , v1 such that
hd ﬁxes al l of X ∗ \ vdX ∗ , and

(vd v−1 )hd = vd+1 and (vd+1 )hd = vd v1 .

Then H is uniformly SENS in G, so in particular G is uniformly SENS. Moreover, if H is
ﬁnitely generated and the hd are words over the generators of H , then H is uniformly SENS.
Proof. For non-negative integers d, q and s ∈ {−1, 1}, consider the following elements gd,s,q ,
deﬁned inductively:

g0,s,q = hq ,

gd,s,q = [gs

d−1,−1,0 , gd−1,1,q+1 ] if d > 0.

18

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

r

We claim that gd,1,0 6=G 1. This implies the proposition: By deﬁnition gd,1,0 is a d-fold
nested commutator of words of the form h±1
for various r ≤ d.
It is easy to see that
given v ∈ {0, 1}d , the index rv corresponding to the leaf of the commutator tree that is
indexed by v is computable in DLINTIME and by the hypothesis of the proposition hrv is
DLINTIME-computable.
Thus, it remains to show that gd,1,0 is non-trivial. Indeed, we claim that, for d > 0, the
element gd,s,q acts only on the subtrees below vd+q and vd−1 vs , and furthermore acts as
hd+q on the subtree below vd+q .
We prove this claim by induction on d. Recall that for g ∈ Aut(X ∗ ) and a node
w ∈ X ∗ we write w ∗ g for the element of Aut(X ∗ ) that acts as g on the subtree wX ∗ and
trivially elsewhere. Note that a conjugate (w ∗ g)h with h ∈ Aut(X ∗ ) can be written as
(w ∗ g)h = wh ∗ g 0 for some g 0 ∈ Aut(X ∗ ). With this notation, we may write hr = vr ∗ kr for
kr = hr@vr ∈ Aut(X ∗ ). Our claim becomes ((cid:3) represents an arbitrary element of Aut(X ∗ )
that is not important)

(cid:1)−1

For d = 1 we have

gd,s,q = (vd+q ∗ kd+q )(vd−1 vs ∗ (cid:3)).
0 , h1+q ] = (cid:0)hhs
h1+q = (cid:0)(v1+q ∗ k1+q )hs
0 (cid:1)−1 (v1+q ∗ k1+q ).
g1,s,q = [hs
1+q
g1,s,q = (vs ∗ (cid:3))−1 (v1+q ∗ k1+q ) = (v1+q ∗ k1+q )(vs ∗ (cid:3)).

Moreover, the conjugate (v1+q ∗ k1+q )hs
0 is of the form (v1+q )hs
0 ∗ (cid:3) = vs ∗ (cid:3) and we get
Consider now d > 1. By induction, gd−1,−1,0 = (vd−1 ∗kd−1 )(vd−2 v−1 ∗(cid:3)) and gd−1,1,q+1 =
f , g , h ∈ Aut(X ∗ ) since they act non-trivially on disjoint subtrees. We get

(vd+q ∗ kd+q )(vd−2 v1 ∗ (cid:3)). Now vd−2 v−1 ∗ f , vd−1 ∗ g , and vd−2 v1 ∗ h commute for all

0

gd,s,q = [gs

d−1,−1,0 , gd−1,1,q+1 ] = [vd−1 ∗ ks
d−1 , vd+q ∗ kd+q ] = (vd−1 vs ∗ (cid:3))(vd+q ∗ kd+q )

by x0 7→ x1x2x−2
1

using arguments as for the case d = 1.
(cid:74)
(cid:73) Corollary 28. Thompson’s groups are uniformly SENS.
groups), for which we set Σ = (cid:8)x±1
1 , 1(cid:9). Consider the endomorphism σ of F given
Proof. It suﬃces to prove the statement for F (the smallest of the three Thompson’s
and x1 7→ x2
1 . After writing x2 in terms of x0 , x1 and adding the
appropriate number of 1’s, we view σ as a substitution σ : Σ → Σ8 . We then deﬁne words
hd = σd (x0 ) for all d ∈ N, and note |hd | = 23d . From Lemma 1 we get hh0 , h1 , . . . i ∼= (· · ·oZ)oZ.
We then apply Proposition 27 with X = Z and (v−1 , v , v1 ) = (−1, 0, 1).
(cid:74)
One can also show Corollary 28 directly without using Proposition 27. Consider the inﬁnite
presentation (1). From the relations x−1
i xk xi = xk+1 (i < k) the reader can easily check
satisﬁes the identity

0 , x±1
1x2x−3

that g = x3x−1

2

g = [g , gx

−1

0 ]x1 = [gx1 , gx

−1

0 x1 ].

cv0 = x1 cv , and cv1 = x−1

Nesting this identity d times and pushing conjugations to the leaf level of the resulting
tree yields the words gd,v . More precisely, let us deﬁne words cv (v ∈ {0, 1}∗ ) by cε = ε,
0 x1 cv . We then deﬁne gd,v = g cv for v ∈ {0, 1}≤d and immediately
get gd,v = [gd,v0 , gd,v1 ] in F . Clearly, the word cv can be computed in DTIME(O(|v |)). Hence,
gd,v can be computed in DTIME(O(d)).

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

19

(cid:73) Corollary 29. Let G be a weakly branched self-similar group, and assume that it admits a
ﬁnitely generated branching subgroup K . Then K and hence G are uniformly SENS.
Proof. Let K be a ﬁnitely generated branching subgroup of G and let X ∗ be the tree on
which G acts. Let ϕ as in (2). First, we may ﬁnd an element k ∈ K and a vertex v ∈ X ∗
such that v , v−1 := vk−1 , and v1 := vk are pairwise distinct. Indeed K contains an element
k 6= 1. If k has order > 2 (possibly ∞), then there is a vertex v on which it acts as a cycle of
length > 2. If k2 = 1 then take a vertex v with vk 6= v . Then the orbit of vv under k · (v ∗ k)
has length four, so we only have to replace k by k · (v ∗ k) and v by vv . After replacing X by
X |v | , we can assume that v−1 , v , v1 ∈ X .
Since ϕ(K ) contains K X , there exists an endomorphism σ of K , given on generators
of K by σ(g) = ϕ−1 (1, . . . 1, g , 1, . . . , 1) with the unique g in position v . We ﬁx a standard
generating set Σ for K and express σ as a substitution σ : Σ → Σ∗ . By padding its images
with 1’s, we may assume that σ maps every generator to a word of length 2µ for some ﬁxed
µ. Also without loss of generality, we may assume that the k from the previous paragraph is
a generator. In particular, the words hd = σd (k) ∈ Σ∗ have length 2µd , and the letter at a
given position of hd can be computed in DTIME(O(d)). We then apply Proposition 27. (cid:74)
For the special case of the Grigorchuk group we give below an alternative proof for the
uniform SENS property. We show that there exist non-trivial nested commutators of arbitrary
depth with individual entries of bounded (and not merely exponentially-growing) length and
computable in DLINTIME:
(cid:73) Proposition 30. Consider in the Grigorchuk group G = ha, b, c, di the elements
Deﬁne recursively elements zv ∈ (cid:8)x, y , x−1 , y−1(cid:9) for al l v ∈ {0, 1}∗ as fol lows:
if zv is deﬁned, then we deﬁne zv0 and zv1 according to the fol lowing table:

and y = xb = babadabac.

x = (abad)2

zε = x;

zv
x
x−1
y
y−1

zv0
x−1
y−1
y
x

zv1
y−1
x−1
x
y

For every d ∈ N and v ∈ {0, 1}≤d let gd,v = zv for |v | = d and gd,v = [gv0 , gv1 ] if |v | < d. We
then have gd,ε 6= 1 in G. In particular, G is uniformly SENS.
Proof. That x 6= 1 6= y is easy to check by computing their action on the third level of the
[x, y ] = (cid:10)(cid:10)1, (cid:10)(cid:10)1, y−1 (cid:11)(cid:11)(cid:11)(cid:11),
tree. Now the following equations are easy to check in G:
[x−1 , y−1 ] = hh1, hh1, xiiii,
[y−1 , x−1 ] = (cid:10)(cid:10)1, (cid:10)(cid:10)1, x−1 (cid:11)(cid:11)(cid:11)(cid:11).
[y , x] = hh1, hh1, yiiii,
In other words: [zv0 , zv1 ] = hh1, hh1, zv iiii. The checks are tedious to compute by hand, but
easy in the GAP package FR (note that vertices are numbered from 1 in GAP and from 0
here):

20

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

gap> LoadPackage("fr");
gap> AssignGeneratorVariables(GrigorchukGroup);
gap> x := (a*b*a*d)^2; y := x^b;
gap> Assert(0,Comm(x,y) = VertexElement([2,2],y^-1));
gap> Assert(0,Comm(x^-1,y^-1) = VertexElement([2,2],x));
gap> Assert(0,Comm(y,x) = VertexElement([2,2],y));
gap> Assert(0,Comm(y^-1,x^-1) = VertexElement([2,2],x^-1));

We wish to prove that gd,ε 6= 1 in G. Now the equation [zv0 , zv1 ] = hh1, hh1, zv iiii immediately
implies that gd,v acts as zv on the subtree below vertex 12(d−|v |) and trivially elsewhere. In
particular, gd,ε acts as zε = x 6= 1 on the subtree below vertex 12d and is non-trivial.
with state set (cid:8)x±1 , y±1(cid:9).
With this deﬁnition, the gd,v satisfy the deﬁnition of a SENS group. Moreover, given some
v ∈ {0, 1}d , gd,v can be computed in time O(d) by a deterministic ﬁnite state automaton
(cid:74)

6

Eﬃciently non-solvable groups have NC1 -hard word problem

We are ready to state and prove our generalization of Barrington’s theorem, namely that
SENS groups have NC1 -hard word problems, both in the non-uniform and uniform setting.
We start with the non-uniform setting.
(cid:73) Theorem 31. Let G be (strongly) eﬃciently non-solvable and let Σ be a ﬁnite standard
generating set for G. Then every language in NC1 can be recognized by a family of (G, Σ)-
programs of polynomial length. In particular, WP(G) is hard for NC1 under projection
reductions as wel l as AC0 -many-one-reductions.
Note that for the second statement we need the padding letter 1 in the generating set for G;
otherwise, we get a TC0 -many-one reduction.
The proof of Theorem 31 essentially follows Barrington’s proof that the word problem of
ﬁnite non-solvable groups is NC1 -hard [4]. The crucial observation here is that it suﬃces to
construct for every gate v only one G-program (plus one for the inverse) which evaluates to
gd,v or to 1 depending on the truth value v evaluates to, where gd,v is from Deﬁnition 15.
Also note that Barrington uses conjugates of commutators in his proof and iterates this
process. However, since z−1 [x, y ]z = [z−1xz , z−1 yz ] in every group, the conjugating elements
can be pushed through to the inner-most level.
Proof. We only give the proof for G strongly eﬃciently non-solvable. The general case is
more technical, but follows exactly the same outline.
In particular, given a language L in NC1 , we start by constructing a family of G-programs
for L. For this let (Cn )n∈N be an NC1 circuit family for L. Let us ﬁx an input length n and
write C = Cn . Since NC1 is closed under complementation, we can assume that for every
input word x ∈ {0, 1}n , we have x ∈ L if and only if the output gate of the circuit C evaluates
to 0 on input x. By Lemma 11 we may assume that C is a balanced nand-tree-circuit of depth
d ∈ O(log n) with each leaf labelled by a possibly negated input variable or constant via the
input mapping qn : {0, 1}d → [1..n] × {0, 1} × {0, 1}. All non-leaf gates are nand-gates.
For each gate v ∈ {0, 1}≤d let gv = gd,v as in Deﬁnition 15. We construct two G-programs
(both of input length n) such that for every input x ∈ {0, 1}n (x is taken as the
input for C , Pv , and P −1
) we have
if v evaluates to 1,
if v evaluates to 0,

Pv and P −1

Pv [x] =G

(3)

v

v

(

gv

1

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

21

v

v

v

v

gv P −1

and P −1
[x] = Pv [x]−1 in G. Notice that we have gv P −1
[x] = gv if v evaluates to 0 and
[x] = 1, otherwise. Thus, gv P −1
is a G-program for the “negation” of Pv . Moreover,
by Equation (3), Pε evaluates to 1 on input x if and only if the output gate evaluates to 0
which by our assumption was the case if and only if x ∈ L.
The construction of the Pv and P −1
is straightforward: For an input gate v ∈ {0, 1}d
we simply assign gv or 1 to Pv (respectively g−1
or 1 to P −1
) depending on the value qn (v).
More precisely, write gv = a1 · · · am with ai ∈ Σ.
If qn (v) = hi, a, bi for i ∈ [1..n] and
m i and P −1
1 i.
For a nand-gate v with inputs from v0 and v1, we deﬁne

a, b ∈ {0, 1}, we set Pv = hi, aa1 , ab1 i · · · hi, aa
m , ab

v = hi, a−a
m , a−b

m i · · · hi, a−a

1 , a−b

v

v

v

Pv = gv [Pv1 , Pv0 ] = gv P −1
v1 P −1
v0 Pv1Pv0 ,
P −1
v = [Pv0 , Pv1 ]g−1
v = P −1
v0 P −1
v1 Pv1Pv1 g−1
v ,
gv = (cid:2)gv0 , gv1

where the gv and g−1
represent constant G-programs evaluating to gv and g−1
v , respectively,
(cid:3) for v ∈ {0, 1}<d in Deﬁnition 15.
irrespective of the actual input (such constant G-programs consist of triples of the form
h1, a, ai for a ∈ Σ). These constant G-programs are deﬁned via the commutator identities
Clearly, by induction we have Pv [x]−1 = P −1
[x] in G (for every input x). Let us show
that Equation (3) holds: For an input gate v ∈ {0, 1}d , Equation (3) holds by deﬁnition.
Now, let v ∈ {0, 1}<d . Then, by induction, we have the following equalities in G:

v

v

(
(

Pv [x] = gv [Pv1 [x], Pv0 [x]] =

=

gv
gv [gv1 , gv0 ]

if v0 or v1 evaluates to 0,
if v0 and v1 evaluate to 1,
if v evaluates to 1,
if v evaluates to 0.

gv

1

v

v

v

Note that [gv1 , gv0 ] = [gv0 , gv1 ]−1 = g−1

for the last equality. Thus, Pv satisﬁes Equation (3).
For P −1
the analogous statement can be shown with the same calculation. For a leaf
v ∈ {0, 1}d , we have |gv | ∈ 2O(d) = nO(1) by Condition (a) from Deﬁnition 15 (recall
that d ∈ O(log n)). Hence, P −1
and Pv have polynomial length in n. Finally, also Pε has
polynomial length in n (with the same argument as for gε ; see the remark after Deﬁnition 15).
The fact that WP(G) is NC1 -hard under projection reductions as well as AC0 -many-one-
reductions follows now form Remark 14.
(cid:74)
(cid:73) Theorem 32. Let G be uniformly (strongly) eﬃciently non-solvable and Σ be a ﬁnite
standard generating set of G. Then every language in ALOGTIME can be recognized by a
uniform family of polynomial length (G, Σ)-programs. In particular, WP(G) is hard for
ALOGTIME under uniform projection reductions (thus, also under DLOGTIME-reductions).
Notice that again for this theorem we need the padding letter 1 in Σ and that all letters of Σ
are encoded using the same number of bits; otherwise, we get a TC0 -many-one reduction.
The proof of Theorem 32 is conceptually simple, but the details are quite technical: We
know that ALOGTIME is the same as DLOGTIME-uniform NC1 , so we apply the construction
of Theorem 31. By a careful padding with trivial G-programs, we can ensure that from
the binary representation of some index i, we can read in DLOGTIME the input gate of
the NC1 -circuit on which the i-th instruction in the G-program depends (this is the main
technical part of the proof). Then the theorem follows easily from the requirements of being
uniformly SENS and from the special type of DLOGTIME-uniformity of the circuit shown in
Lemma 12.

22

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

Proof. By Theorem 31, we know that every language L in ALOGTIME can be recognized by
a family of polynomial length (G, Σ)-programs. It remains to show that the construction of
the G-programs is uniform. In order to do so, we reﬁne the construction of Theorem 31.
Fix a constant µ such that for all v ∈ {0, 1}d the word gv = gd,v has length 2µd . We
start with an ALOGTIME-machine M . By Lemma 12, we can assume that the balanced
nand-tree-circuit family (Cn )n∈N in the proof of Theorem 31 is DLOGTIME-uniform in the
sense that the depth function 1n 7→ 1d(n) as well as the input mapping q from Deﬁnition 10
can be strongly computed in DLOGTIME. Fix an input length n and let d = d(n) be the
depth of the circuit C = Cn . From 1n we can strongly compute 1d in DLOGTIME by the
above assumptions.
We now follow the recursive deﬁnition of the G-programs Pv and P −1
from the proof of
Theorem 31. In order to have a nicer presentation, we wish that all G-programs corresponding
to one layer of the circuit have the same length. To achieve this, we also deﬁne the
constant G-programs gv and g−1
v precisely (which evaluate to the recursive commutators
from Deﬁnition 15). Moreover, for each v ∈ {0, 1}≤d we introduce a new constant G-program
1v of the same length as gv which evaluates to 1 in G. For v ∈ {0, 1}d the program 1v is the
instruction h1, 1, 1i repeated 2µd times. The programs 1v are only there for padding reasons
and 1u and 1v are the same for |u| = |v |.
Now the G-programs Pv , P −1
v , and 1v corresponding to a gate v ∈ {0, 1}<d are
deﬁned as follows (note that each of these programs consists of 8 blocks):

, gv , g−1

v

v

v

= P −1

Pv = g−1
v0 g−1
v1 gv0 gv1P −1
v1 P −1
v0 Pv1Pv0
P −1
v0 P −1
v1 Pv0Pv1 g−1
v1 g−1
v0 gv1 gv0
gv = g−1
v0 g−1
v1 gv0 gv11v0 1v0 1v01v0
g−1
v1 g−1
v0 gv1 gv01v0 1v0 1v01v0
1v = 1v0 1v01v01v01v01v01v01v0 .

= g−1

v

(4)
(5)
(6)
(7)
(8)

v

Clearly, these G-programs all evaluate as described in the proof of Theorem 31 and all
programs corresponding to one layer have the same length. Moreover, for v ∈ {0, 1}<d with
|v | = c the length of the G-program gv is exactly 2µd+3(d−c) and, thus, also the length of Pv
and P −1
is exactly 2µd+3(d−c) .
For the G-program Pε (which has length 2(µ+3)d ) we can prove the uniformity condition:
Given the string 1n and a binary coded integer i ∈ [0..2(µ+3)d − 1] with (µ + 3)d ∈ O(log n)
bits, we want to compute in DLOGTIME the i-th instruction in Pε , where Pε is the G-program
assigned to the n-input circuit. Note that DLOGTIME means time O(log n) (due to the
input 1n ). Since we have computed 1d already in DLOGTIME, we can check in DLOGTIME
whether i has indeed (µ + 3)d bits.
Next, given i and 1n , the DLOGTIME-machine goes over the ﬁrst 3d bits of i and thereby
computes an input gate v ∈ {0, 1}d of C bit by bit together with one of the ﬁve symbols
σ ∈ {P∗ , P −1∗ , g∗ , g−1∗ , 1∗ }. The meaning of v and σ is that σ [∗ → v ] (which is obtained
by replacing ∗ by v ∈ {0, 1}d in σ) is the G-program to which the i-th instruction in Pε
belongs to. The approach is similar to [56, Theorem 4.52]. We basically run a deterministic
ﬁnite state transducer with states P∗ , P −1∗ , g∗ , g−1∗ , 1∗ that reads three bits of i and thereby
outputs one bit of v . We start with σ = P∗ . Note each of the G-programs Pv , P −1
v ,
1v for |v | < d consists of 8 = 23 blocks of equal length. The next three bits in i determine to
which block we have to descend. Moreover, the block determines the next bit of v and the
next state. Let us give an example: assume that the current state σ is P∗ and b ∈ {0, 1}3

, gv , g−1

v

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

23

, gv , g−1

v

v0 g−1
v1 gv0 gv1P −1
v1 P −1
v0 Pv1Pv0 for |v | < d. The

is the next 3-bit block of i. Recall that Pv = g−1
following operations are done:
If b = 000, then print 0 and set σ := g−1∗
(descend to block g−1
v0 ).
If b = 001, then print 1 and set σ := g−1∗
(descend to block g−1
v1 ).
If b = 010, then print 0 and set σ := g∗ (descend to block gv0 ).
If b = 011, then print 1 and set σ := g∗ (descend to block gv1 ).
If b = 100, then print 1 and set σ := P −1∗
(descend to block P −1
v1 ).
If b = 101, then print 0 and set σ := P −1∗
(descend to block P −1
v0 ).
If b = 110, then print 1 and set σ := P∗ (descend to block Pv1 ).
If b = 111, then print 0 and set σ := P∗ (descend to block Pv0 ).
For other values of σ the behavior of the machine is similar and implements the deﬁnitions
for P −1
v , and 1v in (5)–(8).
Assume now that the above DLOGTIME-machine has computed v ∈ {0, 1}d and σ ∈
{P∗ , P −1∗ , g∗ , g−1∗ , 1∗ }. If σ = 1∗ , then the i-th instruction of Pε is the padding instruction
h1, 1, 1i. If σ ∈ {P∗ , P −1∗ , g∗ , g−1∗ }, then the machine reads the last µd bits of the binary
encoding of i. These µd bits are interpreted as a binary coded position j in gd,v or g−1
Assume that σ ∈ {P∗ , g∗ }. The machine then computes the j -th symbol a ∈ Σ of gd,v in
DTIME(O(d)) according to Deﬁnition 15 (and, thus, in DLOGTIME as d ∈ O(log n) and 1n is
part of the input) and outputs the instruction h1, a, ai in case σ = g∗ . If σ = P∗ , then q(1n , v)
has to be computed, which can be done in DLOGTIME by Lemma 12. If q(1n , v) = hk , b, ci
with k ∈ [1..n] and b, c ∈ {0, 1}, the machine then outputs the instruction hk , ab , ac i. If
σ = {P −1∗ , g−1∗ }, then we proceed in a similar fashion. Instead of the j -th letter of gv we have
to compute the j -the letter of g−1
v , which is the inverse of the (2µd − j + 1)-th letter of gv .
The binary coding of 2µd − j + 1 can be computed in time O(log n) (and hence DLOGTIME)
since subtraction can be done in linear time. Thus, we have obtained a DLOGTIME-uniform
family of G-programs for L.
The second part of the theorem (that WP(G) is hard for ALOGTIME under uniform
(cid:74)
projection reductions) follows again from Remark 14.

d,v .

Corollary A from the introduction is a direct consequence of Corollaries 28 and 29 and
Theorem 32.
Here is another application of Theorem 32: in [35] it was shown that for every f.g. linear
solvable group the word problem belongs to DLOGTIME-uniform TC0 . It was also asked
whether for every f.g. linear group the word problem is in DLOGTIME-uniform TC0 or
ALOGTIME-hard (it might be the case that DLOGTIME-uniform TC0 = ALOGTIME). We
can conﬁrm this. Recall that a group G is called C1 -by-C2 for group classes C1 and C2 if G
has a normal subgroup K ∈ C1 such that G/K ∈ C2 .
(cid:73) Theorem 33. For every f.g. linear group the word problem is in DLOGTIME-uniform TC0
or ALOGTIME-hard. More precisely: let G be a f.g. linear group.
If G is ﬁnite solvable, then WP(G) belongs to DLOGTIME-uniform ACC0 .
If G is inﬁnite solvable, then WP(G) is complete for DLOGTIME-uniform TC0 (via
uniform AC0 Turing reductions).
If G is solvable-by-(ﬁnite non-solvable), then WP(G) is complete for ALOGTIME (via
DLOGTIME or uniform projection reductions).
In al l other cases, WP(G) is ALOGTIME-hard and in LOGSPACE.
Note that we can obtain a similar dichotomy for hyperbolic groups: they are either virtually
abelian or contain a non-abelian free subgroup. In the ﬁrst case, the word problem is in
DLOGTIME-uniform TC0 , in the second case it is ALOGTIME-hard.

24

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

Proof. Let G be f.g. linear. First of all, by [41, 53], WP(G) belongs to LOGSPACE. By Tits
alternative [55], G either contains a free subgroup of rank 2 or is virtually solvable. In the
former case, WP(G) is ALOGTIME-hard by Corollary 24 and Theorem 32. Let us now assume
that G is virtually solvable. Let K be a solvable subgroup of G of ﬁnite index. By taking the
intersection of all conjugates of K in G, we can assume that K is a normal subgroup of G.
If also G/K is solvable, then G is solvable. Hence, WP(G) is in DLOGTIME-uniform ACC0
(if G is ﬁnite) or, by [35], complete for DLOGTIME-uniform TC0 (if G is inﬁnite). Finally,
assume that the ﬁnite group G/K is non-solvable (thus, G is solvable-by-(ﬁnite non-solvable).
By Lemmas 18 and 23, G is uniformly SENS, and Theorem 32 implies that WP(G) is
ALOGTIME-hard. Moreover, by [50, Theorem 5.2], WP(G) is AC0 -reducible to WP(K ) and
WP(G/K ). The latter belongs to ALOGTIME and WP(K ) belongs to DLOGTIME-uniform
ACC0 if K is ﬁnite and to DLOGTIME-uniform TC0 if K is inﬁnite (note that K as a ﬁnite
(cid:74)
index subgroup of G is f.g. linear too). In all cases, WP(G) belongs to ALOGTIME.

7

Compressed words and the compressed word problem

In the rest of the paper we deal with the compressed word problem, which is a succinct
version of the word problem, where the input word is given in a compressed form by a
so-called straight-line program. In this section, we introduce straight-line programs and the
compressed word problem and state a few simple facts. For more details on the compressed
word problem see [44].
A straight-line program (SLP for short) over the alphabet Σ is a triple G = (V , ρ, S ),
where V is a ﬁnite set of variables such that V

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

25

Given G , compute the length |val(G )|.
Given G and a, compute the number |val(G )|a of occurrences of a.
Given G and p, compute the symbol val(G )[p] ∈ Σ (in case 0 ≤ p < |val(G )| does not hold,
the algorithm outputs a special symbol).
Given G and p, q , compute an SLP for the string val(G )[p : q ] (in case 0 ≤ p ≤ q < |val(G )|
does not hold, the algorithm outputs a special symbol).
(cid:73) Lemma 36 (c.f. [44, Lemma 3.12]). Given a symbols a0 ∈ Σ and a sequence of morphisms
ϕ1 , . . . , ϕn : Σ∗ → Σ∗ , where every ϕi is given by a list of the words ϕi (a) for a ∈ Σ, one
can compute in LOGSPACE an SLP for the word ϕ1 (ϕ2 (· · · ϕn (a0 ) · · · )).
The compressed word problem for a ﬁnitely generated group G with the ﬁnite standard
generating set Σ, CompressedWP(G, Σ) for short, is the following decision problem:
Input: an SLP G over the alphabet Σ.
Question: does val(G ) = 1 hold in G?
It is an easy observation that the computational complexity of the compressed word problem
for G does not depend on the chosen generating set Σ in the sense that if Σ0 is another
ﬁnite standard generating set for G, then CompressedWP(G, Σ) is LOGSPACE-reducible to
CompressedWP(G, Σ0 ) [44, Lemma 4.2]. Therefore we do not have to specify the generating
set and we just write CompressedWP(G).
The compressed word problem for G is equivalent to the problem whether a given circuit
over the group G evaluates to 1: Take an SLP G = (V , ρ, S ) in Chomsky normal form and
built a circuit by taking V is the set of gates. If ρ(A) = a ∈ Σ then A is an input gate that is
labelled with the group generator a. If ρ(A) = BC with B , C ∈ V then B is left input gate
for A and C is the right input gate for A. Such a circuit can be evaluated in the natural way
(every internal gate computes the product of its input values) and the circuit output is the
value at gate S .
From a given SLP G a PSPACE-transducer can compute the word val(G ). With Lemma 6
we get:
(cid:73) Lemma 37. If G is a ﬁnitely generated group such that WP(G) belongs to polyL, then
CompressedWP(G) belongs to PSPACE.
We also study a natural weaker variant of the compressed word problem, called the power
word problem:
Input: a tuple (w1 , z1 , w2 , z2 , . . . , wn , zn ) where every wi ∈ Σ∗ is a word over the group
generators and every zi is a binary encoded integer (such a tuple is called a power word).
Question: does wz1
n = 1 hold in G?
From a power word (w1 , z1 , w2 , z2 , . . . , wn , zn ) one can easily compute in LOGSPACE a
straight-line program for the word wz1
n . In this sense, the power word problem is
at most as diﬃcult as the compressed word problem.

2 · · · wzn
1 wz2

2 · · · wzn
1 wz2

8

Compressibly SENS groups

In this section, we present a variant of (uniformly) SENS property that allows to derive
P-hardness of the compressed word problem.
(cid:73) Deﬁnition 38. We cal l a group G generated by a ﬁnite standard generating set Σ com-
pressibly strongly eﬃciently non-solvable (compressibly SENS) if there is a polynomial p and
a col lection of words gd,i,j ∈ Σ∗ for d ∈ N, 0 ≤ i ≤ d, and 1 ≤ j ≤ p(d) such that
(a) for al l d ∈ N and 1 ≤ j ≤ p(d) there is an SLP of size at most p(d) evaluating to gd,d,j ,

26

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

(b) for al l d ∈ N, 0 ≤ i < d and 1 ≤ j ≤ p(d) there are k , ‘ ∈ [1..p(d)] such that

gd,i,j = (cid:2)gd,i+1,k , gd,i+1,‘

(cid:3),

(cid:3).

(c) gd,0,1 6= 1 in G.
G is cal led compressibly eﬃciently non-solvable (compressibly ENS) if instead of (b), we
only require
(b’) there is some constant M such that for al l d ∈ N , 0 ≤ i < d and 1 ≤ j ≤ p(d) there are

k1 , ‘1 , . . . , kM , ‘M such that gd,i,j = (cid:2)gd,i+1,k1 , gd,i+1,‘1

(cid:3) · · · (cid:2)gd,i+1,kM , gd,i+1,‘M

(cid:3).

If d is clear from the context, then we write gi,j for gd,i,j .
G is cal led L-uniformly compressibly SENS if, moreover,
(d) on input of the string 1d and a binary number j one can compute in LOGSPACE an SLP
the binary representations of k and ‘ such that gd,i,j = (cid:2)gd,i+1,k , gd,i+1,‘
for gd,d,j , and
(e) on input of the string 1d and binary numbers i and j one can compute in LOGSPACE
Analogously L-uniformly compressibly ENS is deﬁned.
(cid:73) Remark 39. Clearly, starting from the SLPs for gd,d,j and using the commutator identities
(b), we obtain SLPs of polynomial size for all gd,i,j . Moreover, in the L-uniform case, these
SLPs can be computed in LOGSPACE from 1d , i and j (the latter two given in binary
representation).
There is no evidence that a compressibly (S)ENS group is also (S)ENS. The point is that
the length of the words gd,d,j can be only bounded by 2O(p(d)) for the polynomial p from
Deﬁnition 38.
(cid:73) Lemma 40. The fol lowing properties of SENS also apply to (uniformly) compressibly
(S)ENS:
The property of being (uniformly) compressibly (S)ENS is independent of the choice of
the standard generating set.
If Q is a ﬁnitely generated subquotient of a group G and Q is (uniformly) compressibly
(S)ENS, then G is also (uniformly) compressibly (S)ENS.
If G is a ﬁnite non-solvable group, then G is uniformly compressibly SENS.
If Fn is a ﬁnitely generated free group of rank n ≥ 2, then Fn is uniformly compressibly
SENS.
The proof of Lemma 40 repeats verbatim the proofs of Lemmas 17, 18, 23, and Corollary 24.
Recall that P/poly (non-uniform polynomial time) is the class of languages that can be
accepted by a family (Cn )n∈N of boolean circuits such that for some polynomial s(n) the
number of gates of Cn is at most s(n).
(cid:73) Theorem 41. Let G be compressibly (S)ENS, then CompressedWP(G) is hard for P/poly
under projection reductions.

Proof. As before we only consider the case that G is compressibly SENS. Let (Cn )n∈N be a
family of polynomial size circuits. Fix an input length n and consider the circuit C = Cn .
For simplicity, we assume that all non-input gates of C are nand-gates (this is by no means
necessary for the proof, but that way we only need to deal with one type of gates). Input
gates are labelled with variables x1 , . . . , xn or negated variables ¬x1 , . . . , ¬xn . This allows
to assume that C is synchronous in the sense that for every gate g all paths from an input
gate to g have the same length. Let d be the depth of C . Notice that we do not require C to
be a tree (indeed, this would lead to an exponential blow up since d could be as large as the
number of gates of C ).

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

27

r,kAs,‘Ar,k

At,j → gi,j A−1
s,‘ A−1

Let gi,j = gd,i,j ∈ Σ∗ for 0 ≤ i ≤ d and 1 ≤ j ≤ p(d) be from Deﬁnition 38. We now con-
struct an SLP G that contains for each gate t of C at distance i from the output gate and each
1 ≤ j ≤ p(d) variables At,j , A−1
t,j over the terminal alphabet {hk , a, bi | k ∈ [1..n], a, b ∈ Σ} of
G-program instructions such that for any input word x ∈ {0, 1}n the following holds:
If gate t evaluates to 0 then the G-programs valG (At,j ) and valG (A−1
t,j ) evaluate to 1 in G.
If gate t evaluates to 1 then the G-programs valG (At,j ) and valG (A−1
t,j ) evaluate to gi,j
and g−1
i,j , respectively, in G.
This is exactly as Equation (3) in the proof of Theorem 31.
For an input gate t labelled with xi (respectively ¬xi ) this is straightforward using the
SLPs for gd,j for the diﬀerent j and replacing every terminal a in the SLPs by the G-program
instruction hi, a, 1i (respectively hi, 1, ai). For an inner gate t (which is a nand-gate by
assumption) at distance i from the output gate with inputs from gates r and s (both having
distance i + 1 from the output gate), we set
where k and ‘ are as in (b) from Deﬁnition 38 such that gi,j = (cid:2)gi+1,k , gi+1,‘
(cid:3). Here we write
(9)
gi,j as shorthand for the SLP with constant G-program instructions evaluating to gi,j as in
Remark 39. The correctness follows as in the proof of Theorem 31.
Thus, we have constructed an SLP of G-program instructions. The evaluation of the
instructions is the desired projection reduction.
(cid:74)
(cid:73) Theorem 42. Let G be uniformly compressibly SENS, then CompressedWP(G) is P-hard
under LOGSPACE reductions.
Proof. In [18, A.1.6] the following variant of the circuit value problem is shown to be
P-complete: the input circuit is synchronous, monotone (only and- and or-gates), and
alternating – meaning that within one level all gates are of the same type and adjacent levels
consist of gates of diﬀerent types.
Moreover, we can assume that the ﬁrst layer after the inputs consists of and-gates and that
the output gate is an or-gate (in particular, there is an even number of non-input layers). By
replacing each and- and or-gate by a nand-gate, we obtain a synchronous circuit computing
the same function using only nand-gates.
Hence, we can apply the construction from the proof of Theorem 41 and then evaluate the
G-program instructions in the resulting SLP. The latter can clearly be done in LOGSPACE.
Moreover, the construction of the SLP can also be done in LOGSPACE: For input gates the
corresponding SLP can be computed in LOGSPACE by assumption (d). For an inner gate t,
one needs to compute the rules from Equation (9). The indices k and ‘ can be computed in
LOGSPACE by assumption (e). Notice here that k and ‘ only need a logarithmic number
of bits, so we can think of this computation as an oracle call with a logspace oracle. Since
LOGSPACELOGSPACE = LOGSPACE, the whole computation is LOGSPACE even though we
(cid:74)
compute a non-constant number of SLP rules.

Theorem 42 implies that the compressed word for ﬁnite non-solvable groups and ﬁnitely
generated free groups of rank at least 2 is P-complete. This has been also shown in [8] (for
ﬁnite non-solvable groups) and [42] (for ﬁnitely generated free groups of rank at least 2).
(cid:73) Remark 43. Consider the situation of Proposition 27, but now assume that for each hd
there is an SLP of size p(d) for some ﬁxed polynomial p. Moreover, assume that the SLP for
hd is computable from the string 1d in LOGSPACE. Then the arguments from the proof of
Proposition 27 show that G is uniformly compressibly SENS.

28

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

(cid:73) Corollary 44. The compressed word problem for every weakly branched group is P-hard.
Proof. By Remark 43, we need to verify that we can compute SLPs for the hd as in
Proposition 27 in LOGSPACE. However, this is straightforward because the hd in the proof
of Corollary 29 where deﬁned by iterated application of some endomorphism. This yields the
desired SLPs by Lemma 36.
(cid:74)
In the same way it can be also shown that the compressed word problem for Thompson’s
group F is P-hard. But in the rest of the paper, we will show that the compressed word
problem for Thompson’s group F (as well as a large class of weakly branched groups) is in
fact PSPACE-complete.

9

Compressed word problems for wreath products

In this section we consider regular wreath products of the form G o Z. The following result
was shown in [44] (for G non-abelian) and [36] (for G abelian).
(cid:73) Theorem 45 (c.f. [36, 44]). If G is a ﬁnitely generated group, then
CompressedWP(G o Z) is coNP-hard if G is non-abelian and
CompressedWP(G o Z) belongs to coRP (complement of randomized polynomial time)
if G is abelian.
In this section, we proof the following result, which improves the ﬁrst statement of Theorem 45
for groups with a trivial center.
(cid:73) Theorem 46. Let G be a ﬁnitely generated non-trivial group.
CompressedWP(G o Z) belongs to ∀LEAF(WP(G)).
CompressedWP(G o Z) is hard for the class ∀LEAF(WP(G/Z (G))).
In particular, if Z (G) = 1, then CompressedWP(G o Z) is complete for ∀LEAF(WP(G)).
Be aware that in the case that G is abelian, WP(G/Z (G)) is the set of all words over the
generators, and so ∀LEAF(WP(G/Z (G))) consists of only the universal language. Therefore,
for abelian G, the hardness statement in Theorem 46 is trivial.
The proof of the lower bound uses some of the techniques from the paper [43], where
a connection between leaf strings and SLPs was established. In Sections 9.1–9.3 we will
introduce these techniques. The proof of Theorem 46 will be given in Section 9.4.
(cid:73) Remark 47. Let G be a ﬁnite solvable group with composition series 1 = G0 ≤ G1 ≤
· · · ≤ Gr = G meaning that Gi−1 is normal in Gi and Gi /Gi−1 is cyclic of prime or-
der pi for i ∈ {1, . . . , r}.
In this case, [25, Satz 4.32] implies that LEAF(WP(G)) ⊆
Modp1 · · · Modpr P. Thus, using Theorem 46 we obtain that CompressedWP(G o Z) be-
hard for ∀coModmP. Moreover, by [24, Theorem 2.6], coModmP = coModk P for k = Q
longs to ∀Modp1 · · · Modpr P. On the other hand, [27, Theorem 2.2] states that coModmP ⊆
LEAF(WP(G/Z (G))) for m = |G/Z (G)|; thus, it follows that CompressedWP(G o Z) is
where the product runs over all prime divisors of m. As the next examples show there are
the extreme cases that CompressedWP(G o Z) actually belongs to ∀coModmP and also that
it is hard for ∀Modp1 · · · Modpr P (at least, we give an example for r = 2):
If G is a ﬁnite, non-abelian p-group (i. e., pi = p for all i), then
LEAF(WP(G)) ⊆ Modp · · · ModpP = ModpP ⊆ LEAF(WP(G))
by [9, Theorem 6.7] and likewise LEAF(WP(G/Z (G))) = ModpP. Hence, in this case
CompressedWP(G o Z) is complete for ∀ModpP. More generally, for a ﬁnite non-abelian

p|m p

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

29

nilpotent group G (i. e., a direct product of p-groups) and m = |G/Z (G)|, it follows that
a language L is in coModmP if and only if it can be written as an intersection T
CompressedWP(G o Z) is complete for ∀coModmP. This is because by [24, Lemma 2.4]
for languages Lp ∈ ModpP for p|m.
Finally, consider the symmetric group on three elements S3 . By [27, Example 2.5] we have
LEAF(WP(S3 )) = Mod3Mod2P (also written as Mod3⊕P). Since S3 has trivial center, it
follows that CompressedWP(S3 o Z) is complete for ∀Mod3⊕P.
will write α · s = Pn
In the following, we will identify a bit string α = a1a2 · · · an (a1 , . . . , an ∈ {0, 1}) with
i=1 ai · si for the scalar product. Moreover, we write P s for the sum
the vector (a1 , a2 , . . . , an ). In particular, for another vector s = (s1 , s2 , . . . , sn ) ∈ Nn we
s1 + s2 + · · · + sn .

p|m Lp

9.1 Subsetsum problems

A sequence (s1 , . . . , sn ) of natural numbers is super-decreasing if si > si+1 + · · · + sn for all
i ∈ [1..n]. For example, (s1 , . . . , sn ) with si = 2n−i is super-decreasing. An instance of the
subsetsum problem is a tuple (t, s1 , . . . , sk ) of binary coded natural numbers. It is a positive
instance if there are a1 , . . . , ak ∈ {0, 1} such that t = a1 s1 + · · · + ak sk . Subsetsum is a
classical NP-complete problem, see e.g. [16]. The super-decreasing subsetsum problem is the
restriction of subsetsum to instances (t, s1 , . . . , sk ), where (s1 , . . . , sk ) is super-decreasing.
In [34] it was shown that super-decreasing subsetsum is P-complete.2 We need a slightly
generalized version of the construction showing P-hardness that we discuss in Section 9.2.

9.2 From boolean circuits to super-decreasing subsetsum

For this section, we have to ﬁx some more details on boolean circuits. Let us consider a
boolean circuit C with input gates x1 , . . . , xm and output gates y0 , . . . , yn−1 .3 We view C
as a directed acyclic graph with multi-edges (there can be two edges between two nodes);
the nodes are the gates of the circuit. The number of incoming edges of a gate is called
its fan-in and the number of outgoing edges is the fan-out. Every input gate xi has fan-in
zero and every output gate yi has fan-out zero. Besides the input gates there are two more
gates c0 and c1 of fan-in zero, where ci carries the constant truth value i ∈ {0, 1}. Besides
x1 , . . . , xm , c0 , c1 every other gate has fan-in two and computes the nand of its two input
gates. Moreover, we assume that every output gate yi is a nand-gate. For a bit string
α = b1 · · · bm (b1 , . . . , bm ∈ {0, 1}) and 0 ≤ i ≤ n − 1 we denote with C (α)i the value of the
output gate yi when every input gate xj (1 ≤ j ≤ m) is set to bj . Thus, C deﬁnes a map
{0, 1}m → {0, 1}n .
We assume now that C is a boolean circuit as above with the following additional
property that will be satisﬁed later: For all input bit strings α ∈ {0, 1}m there is exactly
one i ∈ [0..n − 1] such that C (α)i = 1. Using a reﬁnement of the construction from [34] we
compute in LOGSPACE q0 , . . . , qn−1 ∈ N and two super-decreasing sequences r = (r1 , . . . rm )
and s = (s1 , . . . , sk ) for some k (all numbers are represented in binary notation) with the
following properties:
The r1 , . . . , rm are pairwise distinct powers of 4.

2 In fact, [34] deals with the super-increasing subsetsum problem. But this is only a nonessential detail.
For our purpose, super-decreasing sequences are more convenient.
3 It will be convenient for us to number the input gates from 1 and the output gates from 0.

30

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

For all 0 ≤ i ≤ n − 1 and all α ∈ {0, 1}m : C (α)i = 1 if and only if there exists δ ∈ {0, 1}k
such that δ · s = qi + α · r .
Let us ﬁrst add for every input gate xi two new nand-gates ¯xi and ¯¯xi , where ¯¯xi has the same
outgoing edges as xi . Moreover we remove the old outgoing edges of xi and replace them by
the edges (xi , ¯xi ), (c1 , ¯xi ) and two edges from ¯xi to ¯¯xi . This has the eﬀect that every input
gate xi has a unique outgoing edge. Clearly, the new circuit computes the same boolean
function (basically, we introduce two negation gates for every input gate). Let g1 , . . . , gp
be the nand-gates of the circuit enumerated in reverse topological order, i.e., if there is an
edge from gate gi to gate gj then i > j . We denote the two edges entering gate gi with
e2i+n−2 and e2i+n−1 . Moreover, we write ei (0 ≤ i ≤ n − 1) for an imaginary edge that leaves
the output gate yi and whose target gate is unspeciﬁed. Thus, the edges of the circuit are

e0 , . . . , e2p+n−1 . We now deﬁne the natural numbers q0 , . . . , qn−1 , r1 , . . . rm , s1 , . . . , sk with

k = 3p:
Let I = {j | ej is an outgoing edge of the constant gate c1 or a nand-gate}. For 0 ≤ i ≤
n − 1 we deﬁne the number qi as
qi = X
Recall that ei is the unique outgoing edge of the output gate yi .
If ej is the unique outgoing edge of the input gate xi then we set ri = 4j . We can choose
the reverse topological sorting of the nand-gates in such a way that r1 > r2 > · · · > rm
(we only have to ensure that the target gates x1 , . . . , xm of the input gates appear in the
order xm , . . . , x1 in the reverse topological sorting of the nand-gates).
To deﬁne the numbers s1 , . . . , sk we ﬁrst deﬁne for every nand-gate gi three numbers t3i ,
t3i−1 and t3i−2 as follows, where Ii = {j | ej is an outgoing edge of gate gi }:
4j

j∈I \{i}

4j .

t3i = 42i+n−1 + 42i+n−2 + X
t3i−1 = 42i+n−1 − 42i+n−2 = 3 · 42i+n−2
t3i−2 = 42i+n−2

j∈Ii

Then, the tuple (s1 , . . . , sk ) is (t3p , t3p−1 , t3p−2 , . . . , t3 , t2 , t1 ), which is indeed super-
decreasing (see also [34]). In fact, we have si − (si+1 + · · · + sk ) ≥ 4n−1 for all i ∈ [1..k ].
To see this, note that the sets Ii+1 , . . . , Ik are pairwise disjoint. This implies that the
n − 1 low-order digits in the base-4 expansion of si+1 + · · · + sk are zero or one.
In order to understand this construction, one should think of the edges of the circuit carrying
truth values. Recall that there are 2p + n edges in the circuit (including the imaginary
outgoing edges of the output gates y0 , . . . , yn−1 ). A number in base-4 representation with
2p + n digits that are either 0 or 1 represents a truth assignment to the 2p + n edges, where
a 1-digit represents the truth value 1 and a 0-digit represents the truth value 0. Consider an
input string α = b1 · · · bm ∈ {0, 1}m and consider an output gate yi , i ∈ [0..n − 1]. Then the
number N := 4i + qi + b1 r1 + · · · + bm rm encodes the truth assignment for the circuit edges,
where:
all outgoing edges of the constant gate c1 carry the truth value 1,
all outgoing edges of the constant gate c0 carry the truth value 0,
the unique outgoing edge of an input gate xi carries the truth value bi ,
all outgoing edges of nand-gates carry the truth value 1.
We have to show that C (α)i = 1 if and only if there exists δ ∈ {0, 1}k such that δ · s =
N − 4i . For this we apply the canonical algorithm for super-decreasing subsetsum with
input (N , s1 , . . . , sk ). This algorithm initializes a counter A to N and then goes over the

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

31

sequence s1 , . . . , sk in that order. In the j -th step (1 ≤ j ≤ k) we set A to A − sj if A ≥ sj .
If A < sj then we do not modify A. After that we proceed with sj+1 . The point is that this
process simulates the evaluation of the circuit on the input values b1 , . . . , bm . Thereby the
nand-gates are evaluated in the topological order gp , gp−1 , . . . , g1 . Assume that gj is the gate
that we want to evaluate next. In the above algorithm for super-decreasing subsetsum the
evaluation of gj is simulated by the three numbers t3j , t3j−1 , and t3j−2 . At the point where
the algorithm checks whether t3j can be subtracted from A, the base-4 digits at positions
2j + n, . . . , 2p + n − 1 in the counter value A have been already set to zero. If the digits at
the next two high-order positions 2j + n − 1 and 2j + n − 2 are still 1 (i.e., the input edges
e2j+n−2 and e2j+n−1 for gate gj carry the truth value 1), then we can subtract t3j from A.
Thereby we subtract all powers 42j+n−1 , 42j+n−2 and 4h , where eh is an outgoing edge for
gate gj . Since gate gj evaluates to zero (both input edges carry 1), this subtraction correctly
simulates the evaluation of gate gj : all outgoing edges eh of gj (that were initially set to the
truth value 1) are set to the truth value 0. On the other hand, if one of the two digits at
positions 2j + n − 1 and 2j + n − 2 in A is 0 (which means that gate gj evaluates to 1), then
we cannot subtract t3j from A. If both digits at positions 2j + n − 1 and 2j + n − 2 in A are
0, then also t3j−1 and t3j−2 cannot be subtracted. On the other hand, if exactly one of the
two digits at positions 2j + n − 1 and 2j + n − 2 is 1, then with t3j−1 and t3j−2 we can set
these two digits to 0 (thereby digits at positions < 2j + n − 2 are not modiﬁed).
Assume now that yj (j ∈ [0..n − 1]) is the unique output gate that evaluates to 1, i.e., all
output gates yj 0 with j 0 6= j evaluate to zero. Then after processing all weights s1 , . . . , sk
we have A = 4j (we will never subtract 4j ). We have shown that there exists δ ∈ {0, 1}k
such that δ · s + 4j = N . Hence, if i = j (i.e., C (α)i = 1) then δ · s = N − 4i . Now assume
that i 6= j . In order to get a contradiction assume that there is δ 0 ∈ {0, 1}k such that
δ 0 · s + 4i = N . We have δ 6= δ 0 and δ · s + 4j = δ 0 · s + 4i , i.e, δ · s − δ 0 · s = 4i − 4j . Since
i, j ∈ [0..n − 1] we get |δ · s − δ 0 · s| < 4n−1 . But si − (si+1 + · · · sk ) ≥ 4n−1 for all i ∈ [1..k ]
implies that |δ · s − δ 0 · s| ≥ 4n−1 .

9.3 From super-decreasing subsetsum to straight-line programs

string S (t) ∈ {0, 1}∗ of length P t + 1 such that for all 0 ≤ p ≤ P t:
In [40] a super-decreasing sequence t = (t1 , . . . , tk ) of natural numbers is encoded by the
if p = α · t for some α ∈ {0, 1}k ,
S (t)[p] =
otherwise.

(10)

(1

0

Note that in the ﬁrst case, α is unique. Since t is a super-decreasing sequence, the number of
1’s in the string S (t) is 2k . Also note that S (t) starts and ends with 1. In [40] it was shown
that from a super-decreasing sequence t of binary encoded numbers one can construct in
LOGSPACE an SLP for the word S (t).

9.4 Proof of Theorem 46

Let us ﬁx a regular wreath product of the form G o Z for a ﬁnitely generated group G. Such
groups are also known as generalized lamplighter groups (the lamplighter group arises for
G = Z2 ). Throughout this section, we ﬁx a set of standard generators Σ for G and let τ = 1
be the generator for Z. Then Σ ∪ {τ , τ −1} is a standard generating set for the wreath product
G o Z. In G o Z the G-generator a ∈ Σ represents the mapping fa ∈ G(Z) with fa (0) = a and
fa (z ) = 1 for z 6= 0. For a word w ∈ (Σ ∪ {τ , τ −1})∗ we deﬁne η(w) := |w|τ − |w|τ −1 . Thus,

32

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

the element of G o Z represented by w is of the form f τ η(w) for some f ∈ G(Z) . Recall the
deﬁnition of the left action of Z on G(Z) from Section 3.1 (where we take H = Y = Z). For
better readability, we write c ◦ f for cf (c ∈ Z, f ∈ G(Z) ). Hence, we have (c ◦ f )(z ) = f (z + c).
If one thinks of f as a bi-inﬁnite word over the alphabet G, then c ◦ f is the same word but
shifted by −c.
The following intuition might be helpful: Consider a word w ∈ (Σ ∪ {τ , τ −1})∗ . In G o Z
we can simplify w to a word of the form τ z0 a1 τ z1 a2 · · · τ zk−1 ak τ zk (with zj ∈ Z, aj ∈ Σ),
which in G o Z can be rewritten as

τ z0+···+zj−1 aj τ −(z0+···+zj−1 ) (cid:1) τ z0+···+zk .

τ z0 a1 τ z1 a2 · · · τ zk−1 ak τ zk = (cid:0) kY
j=1
(cid:1) τ z0+···+zk .

(z0 + · · · + zj−1 ) ◦ faj

Hence, the word w represents the group element

(cid:0) kY

j=1

This gives the following intuition for evaluating τ z0 a1 τ z1 a2 · · · τ zk−1 ak τ zk : In the beginning,
every Z-position carries the G-value 1. First, go to the Z-position −z0 and multiply the
G-element at this position with a1 (on the right), then go to the Z-position −z0 − z1 and
multiply the G-element at this position with a2 , and so on.
Proof of Theorem 46. The easy part is to show that the compressed word problem for G o Z
belongs to ∀LEAF(WP(G)). In the following, we make use of the statements from Lemma 35.
Let G be an SLP over the alphabet Σ ∪ {τ , τ −1} and let f τ η(val(G )) ∈ G o Z be the group
element represented by val(G ). By Lemma 35 we can compute η(val(G )) in polynomial time.
If η(val(G )) 6= 0 then the Turing-machine rejects by printing a non-trivial generator of G
(here we need the assumption that G is non-trivial). So, let us assume that η(val(G )) = 0.
We can also compute in polynomial time two integers b, c ∈ Z such that supp(f ) ⊆ [b..c].
We can take for instance b = −|val(G )| and c = |val(G )|. It suﬃces to check whether for all
x ∈ [b..c] we have f (x) = 1. For this, the Turing-machine branches universally to all binary
coded integers x ∈ [b..c] (this yields the ∀-part in ∀LEAF(WP(G))). Consider a speciﬁc
branch that leads to the integer x ∈ [b..c]. From x and the input SLP G the Turing-machine
then produces a leaf string over the standard generating set Σ of G such that this leaf string
represents the group element f (x) ∈ G. For this, the machine branches to all positions
p ∈ [0..|val(G )| − 1] (if p < q < |val(G )| then the branch for p is to the left of the branch for q).
For a speciﬁc position p, the machine computes in polynomial time the symbol a = val(G )[p].
If a is τ or τ −1 then the machine prints 1 ∈ Σ. On the other hand, if a ∈ Σ then the machine
computes in polynomial time d = η(val(G )[: p]). This is possible by ﬁrst computing an SLP
for the preﬁx val(G )[: p]. If d = −x then the machine prints the symbol a, otherwise the
machine prints the trivial generator 1. It is easy to observe that the leaf string produced in
this way represents the group element f (x).
We now show the hardness statement from Theorem 46. By Lemma 8 it suﬃces to
show that CompressedWP(G o Z) is hard for ∀bLEAF(WP(G/Z (G))) with respect to
LOGSPACE-reductions. Let a0 , . . . , an−1 be an arbitrary enumeration of the standard gen-
erators in Σ. Fix a language L ∈ ∀bLEAF(WP(G/Z (G))). From the deﬁnition of the class
∀bLEAF(WP(G/Z (G))) it follows that there exist two polynomials p1 and p2 and a balanced
polynomial time NTM M running in time p1 + p2 that outputs a symbol from Σ after
termination and such that the following holds: Consider an input word z and let T (z ) be the

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

33

λ(β γ )

γ∈{0,1}m2

(11)

corresponding computation tree of M . Let m1 = p1 (|z |), m2 = p2 (|z |), and m = m1 + m2 .
Note that the nodes of T (z ) are the bit strings of length at most m. For every leaf α ∈ {0, 1}m
let us denote with λ(α) the symbol from Σ that M prints when reaching the leaf α. Then
z ∈ L if and only if for all β ∈ {0, 1}m1 the string
λβ := Y
represents a group element from the center Z (G). Here (and in the following), the product
in the right-hand side of (11) goes over all bit strings of length m2 in lexicographic order.
Our construction consists of ﬁve steps:
Step 1. Note that given a bit string α ∈ {0, 1}m , we can compute in polynomial time the
symbol λ(α) ∈ Σ by following the computation path speciﬁed by α. Using the classical
Cook-Levin construction (see e.g.
[3]), we can compute from the input z and a ∈ Σ in
LOGSPACE a boolean circuit Cz ,a with m input gates x1 , . . . , xm and a single output gate
y0 such that for all α ∈ {0, 1}m : Cz ,a (α)0 = 1 if and only if λ(α) = a. By taking the disjoint
union of these circuits and merging the input gates, we can build a single circuit Cz with
m input gates x1 , . . . , xm and n = |Σ| output gates y0 , . . . , yn−1 . For every α ∈ {0, 1}m and
every 0 ≤ i ≤ n − 1 the following holds: Cz (α)i = 1 if and only if λ(α) = ai .
Step 2. Using the construction from Section 9.2 we can compute from the circuit Cz in
LOGSPACE numbers q0 , . . . , qn−1 ∈ N and two super-decreasing sequences r = (r1 , . . . , rm )
and s = (s1 , . . . , sk ) with the following properties:
The r1 , . . . , rm are pairwise distinct powers of 4.
For all 0 ≤ i ≤ n − 1 and all α ∈ {0, 1}m we have: λ(α) = ai if and only if Cz (α)i = 1 if
and only if there is δ ∈ {0, 1}k such that δ · s = qi + α · r .
Note that for all α ∈ {0, 1}m there is a unique i such that Cz (α)i = 1. Hence, for all
α ∈ {0, 1}m there is a unique i such that qi + α · r is of the form δ · s for some δ ∈ {0, 1}k .
For this unique i we have λ(α) = ai .
We split the super-decreasing sequence r = (r1 , . . . , rm ) into the two sequences r1 =
(r1 , . . . , rm1 ) and r2 = (rm1+1 , . . . , rm ). For the following consideration, we need the following
numbers:
‘ = max (cid:8) P r1 + max{q0 , . . . , qn−1} + 1, P s − P r2 − min{q0 , . . . , qn−1} + 1(cid:9) (12)
(13)
The binary codings of these numbers can be computed in LOGSPACE (since iterated addition,
max, and min can be computed in LOGSPACE). The precise value of ‘ will be only relevant
at the end of step 4.
Step 3. By the result from [40] (see Section 9.3) we can construct in LOGSPACE from the
three super-decreasing sequences r1 , r2 and s three SLPs G1 , G2 and H over the alphabet
{0, 1} such that val(G1 ) = S (r1 ), val(G2 ) = S (r2 ) and val(H) = S (s) (see (10)). For all
positions p ≥ 0 (in the suitable range) we have:
val(G1 )[p] = 1 ⇐⇒ ∃β ∈ {0, 1}m1 : p = β · r1
val(G2 )[p] = 1 ⇐⇒ ∃γ ∈ {0, 1}m2 : p = γ · r2
Note that |val(G1 )| = P r1 + 1, |val(G2 )| = P r2 + 1, and |val(H)| = P s + 1.
val(H)[p] = 1 ⇐⇒ ∃δ ∈ {0, 1}k : p = δ · s

π = ‘ + P r2

34

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

σ = τ q0 T0 τ h−q0 τ q1 T1 τ h−q1 · · · τ qn−1 Tn−1 τ h−qn−1

Step 4. We build in LOGSPACE for every i ∈ [0..n − 1] an SLP Hi from the SLP H by
replacing in every right-hand side of H every occurrence of 0 by τ −1 and every occurrence of 1
by ai τ −1 . Let Ti be the start variable of Hi , let S1 be the start variable of G1 , and let S2 be the
start variable of G2 . We can assume that the variable sets of the SLPs G1 , G2 , H0 , . . . , Hn−1
are pairwise disjoint. We next combine these SLPs into a single SLP I . The variables of I
are the variables of the SLPs G1 , G2 , H0 , . . . , Hn−1 plus a fresh variable S which is the start
variable of I . The right-hand sides for the variables are deﬁned below. In the right-hand
sides we write powers τ p for integers p whose binary codings can be computed in LOGSPACE.
Such powers can be produced by small subSLPs that can be constructed in LOGSPACE too.
In all right-hand sides of G1 and G2 we replace all occurrences of the terminal symbol 0
by the Z-generator τ .
We replace every occurrence of the terminal symbol 1 in a right-hand side of G1 by S2 τ ‘ ,
where ‘ is from (12).
We replace every occurrence of the terminal symbol 1 in a right-hand side of G2 by στ ,
where
and h = P s + 1 is the length of the word val(H) (which is −η(valI (Ti )) for every
(14)
Finally, the right-hand side of the start variable S is S1 τ −d where d := P r1 + 1 + 2m1 · π .
i ∈ [0..n − 1]). Note that η(valI (σ)) = 0.
(note that d = η(valI (S1 ))).
Before we explain this construction, let us ﬁrst introduce some notations.
Let u := valI (S2 ). We have η(u) = |val(G2 )|. Hence, the group element represented by u
can be written as fu τ |val(G2 )| for a mapping fu ∈ G(Z) .
position − max{q0 , . . . , qn−1} to position P s − min{q0 , . . . , qn−1}.
Let v := valI (σ) where σ is from (14). Note that η(v) = 0. Hence, the group element
represented by v is a mapping fv ∈ G(Z) . Its support is a subset of the interval from
For β ∈ {0, 1}m1 let bin(β ) be the number represented by β in binary notation (thus,
bin(0m1 ) = 0, bin(0m1−11) = 1, . . . , bin(1m1 ) = 2m1 − 1). Moreover, let
pβ := −bin(β ) · π .
First, note that η(val(I )) = 0. This is due to the factor τ −d in the right-hand side of the
start variable S of I . Hence, the group element represented by val(I ) is a mapping f ∈ G(Z) .
The crucial claim is the following:

(cid:66) Claim. For every β ∈ {0, 1}m1 , f (pβ ) is the group element represented by the leaf string
λβ from (11).

Proof of the claim. In the following, we compute in the restricted direct product G(Z) . Recall
that the multiplication in this group is deﬁned by the pointwise multiplication of mappings.
Since we replaced in G1 every 1 in a right-hand side by S2 τ ‘ , which produces uτ ‘ in I
(which evaluates to fu τ π+1 ) the mapping f is a product (in the restricted direct product
G(Z) ) of shifted copies of fu . More precisely, for every β 0 ∈ {0, 1}m1 we get the shifted copy
(cid:0)β 0 · r1 + bin(β 0 ) · π(cid:1) ◦ fu
(15)
of fu . The shift distance β 0 · r1 + bin(β 0 ) · π can be explained as follows: The 1 in val(G1 ) that
corresponds to β 0 ∈ {0, 1}m1 occurs at position β 0 · r1 (the ﬁrst position is 0) and to the left

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

35

β 0∈{0,1}m1

(cid:0)β 0 · r1 − pβ 0 (cid:1) ◦ fu .

of this position we ﬁnd bin(β 0 ) many 1’s and β 0 · r1 − bin(β 0 ) many 0’s in val(G1 ). Moreover,
every 0 in val(G1 ) was replaced by τ (shift by 1) and every 1 in val(G1 ) was replaced by uτ ‘
(shift by ‘ + |val(G2 )| = π + 1). Hence, the total shift distance is indeed (15). Also note that
if β 0 ∈ {0, 1}m1 is lexicographically smaller than β 00 ∈ {0, 1}m1 then β 0 · r1 < β 00 · r1 . This
implies that
f = Y
(cid:0)β 0 · r1 + bin(β 0 ) · π(cid:1) ◦ fu = Y
Let us now compute the mapping fu . Recall that we replaced in G2 every occurrence of 1 by
στ , where σ is from (14) and derives to v . The 1’s in val(G2 ) occur at positions of the form
γ · r2 for γ ∈ {0, 1}m2 and if γ ∈ {0, 1}m2 is lexicographically smaller than γ 0 ∈ {0, 1}m2 then
fu = Y
γ · r2 < γ 0 · r2 . We therefore get
We obtain
f = Y

β 0∈{0,1}m1

γ∈{0,1}m2

(γ · r2 ) ◦ fv .
(cid:0)β 0 · r1 − pβ 0 (cid:1) ◦ fu
(γ · r2 ◦ fv )
(cid:0)β 0 · r1 + γ · r2 − pβ 0 (cid:1) ◦ fv
γ∈{0,1}m2

(cid:0)β 0 · r1 − pβ 0 (cid:1) ◦ Y

Y

β 0∈{0,1}m1

= Y
= Y

β 0∈{0,1}m1

β 0∈{0,1}m1

γ∈{0,1}m2

f (pβ ) = Y
and hence
We claim that for all β 6= β 0 and all γ ∈ {0, 1}m2 we have

β 0∈{0,1}m1

Y

γ∈{0,1}m2

fv (pβ − pβ 0 + β 0 · r1 + γ · r2 ).

fv (pβ − pβ 0 + β 0 · r1 + γ · r2 ) = 1.

(16)

γ∈{0,1}m2

fv (β · r1 + γ · r2 ).

Let us postpone the proof of this for a moment. From (16) we get
f (pβ ) = Y
Consider a speciﬁc γ ∈ {0, 1}m2 and let α = β γ and p = β · r1 + γ · r2 = α · r. From the
deﬁnition of v = valI (σ) it follows that for all x ∈ Z, fv (x) is a product of those group
generators ai such that x = −qi + δ · s for some δ ∈ {0, 1}k . For the position p this means
that qi + α · r = δ · s. By our previous remarks, there is a unique such i ∈ [0..n − 1] and for
f (pβ ) = Y
this i we have λ(α) = ai . Hence, we obtain fv (p) = λ(α) = λ(β γ ) and thus
It remains to show (16). To get this identity, we need the precise value of ‘ from (12) (so far,
the value of ‘ was not relevant). Assume now that β 6= β 0 , which implies
|pβ − pβ 0 | ≥ π = ‘ + X

λ(β γ ) = λβ .

γ∈{0,1}m2

r2 .

36

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

Hence, we either have

≥ ‘ + X

X

pβ − pβ 0 + β 0 · r1 + γ · r2 ≥ ‘ + X
r2 + β 0 · r1 + γ · r2
r2
s − min{q0 , . . . , qn−1 }
pβ − pβ 0 + β 0 · r1 + γ · r2 ≤ −‘ − X
>
r2 + β 0 · r1 + γ · r2
r1
< − max{q0 , . . . , qn−1},

≤ −‘ + X

or

mapping fv is contained in [− max{q0 , . . . , qn−1}..P s − min{q0 , . . . , qn−1}]. This shows (16)
where the strict inequalities follow from our choice of ‘. Recall that the support of the
and hence the claim.
Step 5. By the above claim, we have f (pβ ) ∈ Z (G) for all β ∈ {0, 1}m1 if and only if
λβ ∈ Z (G) for all β ∈ {0, 1}m1 , which is equivalent to z ∈ L. The only remaining problem is
that the word val(I ) produces some “garbage” group elements f (x) on positions x that are
not of the form pβ . Note that for every g ∈ G \ Z (G), there is a generator ai ∈ Σ such that
the commutator [g , ai ] is non-trivial. We now produce from I an SLP I −1 such that val(I −1 )
represents the inverse element of f ∈ G(Z) , which is the mapping g with g(x) = f (x)−1 for
all x ∈ Z. To construct I −1 , we have to reverse every right-hand side of I and replace every
occurrence of a symbol a0 , . . . , an−1 , τ , τ −1 by its inverse.
It is easy to compute in LOGSPACE for every i ∈ [0..n − 1] an SLP for the word

wi := (cid:0)ai τ π (cid:1)2m1

τ −2m1 ·π .

i

gi (pβ ) = f (pβ )−1a−1
i f (pβ )ai = [f (pβ ), ai ].

Then the group element represented by wi is the mapping fi ∈ G(Z) whose support is
the set of positions pβ for β ∈ {0, 1}m1 and fi (pβ ) = ai for all β ∈ {0, 1}m1 . We can
also compute in LOGSPACE an SLP for the word w−1
. We then built in LOGSPACE SLPs
J0 , . . . , Jn−1 such that val(Ji ) = val(I −1 )w−1
i val(I )wi . Hence, the word val(Ji ) represents
the group element gi ∈ G(Z) , where gi (x) = 1 for all x ∈ Z \ {pβ | β ∈ {0, 1}m1 } and
Finally, we construct in LOGSPACE an SLP J such that
We can assume that n ≤ ‘ + P r2 = π (n is a constant and we can always make ‘ bigger).
val(J ) = val(J0 ) τ val(J1 ) τ val(J2 ) · · · τ val(Jn−1 ) τ −n+1 .
Then val(J ) evaluates to the group element g ∈ G(Z) with g(x) = 1 for x ∈ Z \ {pβ − i | β ∈
{0, 1}m1 , 0 ≤ i ≤ n − 1} and g(pβ − i) = gi (pβ ) = [f (pβ ), ai ] for 0 ≤ i ≤ n − 1. Hence, if
f (pβ ) ∈ Z (G) for all β ∈ {0, 1}m1 then val(J ) = 1 in G o Z. On the other hand, if there is a
β ∈ {0, 1}m1 such that f (pβ ) ∈ G \ Z (G) then there is an ai such that [f (pβ ), ai ] 6= 1. Hence
g(pβ − i) 6= 1 and val(J ) 6= 1 in G o Z. This proves the theorem.
(cid:74)
The following remark will be needed in the next section.
(cid:73) Remark 48. Consider the SLP val(J ) computed in the previous proof from the machine
input z . We showed that z ∈ L if and only if val(J ) = 1 in G o Z. Let s = |val(J )|; it is
a number that grows exponentially with |z |. The binary expansion of s can be computed
from z in LOGSPACE using simple arithmetics. Let t be any positive integer with t ≥ 2s + 1.

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

37

Then val(J ) = 1 in G o Z if and only if val(J ) = 1 in G o (Z/t) where in the latter equality τ
is taken for the generator of Z/t. To see this, note that during the evaluation of val(J ) in
G o Z only the G-elements at positions in the interval [−s..s] (whose size is at most t) can be
multiplied with a generator of G. Intuitively, val(J ) evaluates in G o Z in the same way as in
G o (Z/t).

10

PSPACE-complete compressed word problems

In this section, we will use Theorem 46 (and Remark 48) to show PSPACE-completeness of
the compressed word problem for several groups. For upper upper bounds, we will make use
of the following simple lemma:
(cid:73) Lemma 49. If WP(G) belongs to polyL, then CompressedWP(G o Z) belongs to PSPACE.
Proof. We use a result of Waack [57] according to which the word problem for a wreath
product G1 o G2 is NC1 -reducible (and hence LOGSPACE-reducible) to the word problems for
G1 and G2 . Since WP(G) belongs to polyL and WP(Z) belongs to LOGSPACE, it follows
that WP(G o Z) belongs to polyL (polyL is closed under LOGSPACE-reductions). Hence, by
Lemma 37 the compressed word problem for G o Z belongs to PSPACE.
(cid:74)
The following lemma generalizes the inclusion PSPACE ⊆ LEAF(WP(G)) for G ﬁnite non-
solvable (where in fact equality holds) from [28]. It can be proved directly using the same
idea based on commutators as Theorem 32. Here we follow a diﬀerent approach and derive
it by a padding argument from Theorem 32.
(cid:73) Lemma 50. If the ﬁnitely generated group G is uniformly SENS, then PSPACE ⊆
LEAF(WP(G/Z (G))).
Proof. Let L ⊆ Γ∗ belong to PSPACE. Recall that PSPACE = APTIME. Hence, there is an
ATM for L with running time bounded by a polynomial p(n). We can assume that p(n) ≥ n
for all n. Now, consider the language
Pad2p(n) (L) = n
where $ is some fresh letter. Then Pad2p(n) (L) is in ALOGTIME: Let w be the input word
and let n = |w| be the input length. First, we check whether w ∈ Γ∗$∗ (the latter regular
language even belongs to uniform AC0 ). If not, we reject, otherwise we can write w = v$k for
some k ∈ N and v ∈ Γ∗ . Let m = n − k = |v |. We next have to verify that n = 2p(m) . Using
binary search, we compute in DLOGTIME the binary representation of the input length n. If
n is not a power of two (which is easy to check from the binary representation of n), then we
reject. Otherwise, let l = log2 n. The unary representations of l can be obtained from the
binary representation of n. It remains to check l = p(m). Using 1l we can check whether
|v | = m ≤ l. If not, we reject. Otherwise, we can produce 1m . Since polynomials are time
constructible we can simply run a clock for p(m) steps, and stop if the number of steps
exceeds l. Finally, we check whether v ∈ L (by assumption this can be done in ATIME(p(|v |)),
which is contained in ALOGTIME because of the increased input length). Thus, Pad2p(n) (L)
is in ALOGTIME.
Since we aim for applying Theorem 32, we have to encode every symbol c ∈ Γ ∪ {$} by
a bit string γ (c) of length 2µ for some ﬁxed constant µ. Hence, we consider the language
γ (Pad2p(n) (L)), which belongs to ALOGTIME as well. Observe that by Lemma 22, also
G/Z (G) is uniformly SENS. Thus, we can apply Theorem 32, which states that there

v$2p(|w|)−|v | (cid:12)(cid:12)(cid:12) v ∈ L

o

,

38

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

is a uniform family (Pn )n∈N of (G/Z (G), Σ)-programs of polynomial length recognizing
γ (Pad2p(n) (L)). Be aware, however, that “polynomial” here means polynomial in the input
length for γ (Pad2p(n) (L)). Let Qn = P2p(n)+µ , which has length 2d(n) for some function
d(n) ∈ O(p(n)). By the uniformity of (Pn )n∈N we can compute 1d(n) from 12p(n)+µ in
DTIME(O(log(2p(n)+µ ))) = DTIME(O(p(n))). Here we do not have to construct the unary
representation of 2p(n)+µ : recall that we have a random access Turing machine for the
computation. One can easily check whether the content of the address tape (a binary coded
number) is at most 2p(n)+µ .
Now, we construct an adequate NTM M with L = LEAF(M , WP(G/Z (G))): on input
z ∈ Γ∗ of length n the machine M produces a full binary tree of depth d(n). In the i-
th leaf (i ∈ [0..2d(n) − 1]) it computes the i-th instruction of Qn . By the uniformity of
(Pn )n∈N this can be done in DTIME(O(p(n))), so M respects a polynomial time bound. Let
hj, a, bi be the computed instruction. Here j ∈ [1..2p(n)+µ ] is a position in γ (z$2p(n)−n ).
Depending on the input bit at position j in γ (z$2p(n)−n ) (which can be easily computed
from z and j in polynomial time), the machine then outputs either a or b. We then
have leaf (M , z ) = Qn [γ (z$2p(n)−n )]. Thus, z ∈ L iﬀ γ (z$2p(n)−n ) ∈ γ (Pad2p(n) (L)) iﬀ
Qn [γ (z$2p(n)−n )] ∈ WP(G/Z (G)) iﬀ leaf (M , z ) ∈ WP(G/Z (G)).
(cid:74)
From Theorem 46 and Lemma 50 we get:
(cid:73) Corollary 51. If G is uniformly SENS, then CompressedWP(G o Z) is PSPACE-hard.
Since ﬁnite non-solvable groups and ﬁnitely generated free group of rank at least two are
uniformly SENS and their word problems can be solved in LOGSPACE (see [41] for the free
group case), we obtain the following from Lemma 49 and Corollary 51:
(cid:73) Corollary 52. If G is a ﬁnite non-solvable group or a ﬁnitely generated free group of rank
at least two, then CompressedWP(G o Z) is PSPACE-complete.
For Thompson’s group F we have F o Z ≤ F (Lemma 1). Moreover, F is uniformly SENS
(Corollary 28). Finally, Lehnert and Schweitzer have shown that F is co-context-free, i.e., the
complement of the word problem of F (with respect to any ﬁnite generating set) is a context-
free language [38]. This implies that the word problem for F belongs to the complexity class
LogCFL (the closure of the context-free languages under LOGSPACE-reductions). It is known
that LogCFL ⊆ DSPACE(log2 n) [47]. If we put all this into Theorem 51, we get:
(cid:73) Corollary 53. The compressed word problem for Thompson’s group F is PSPACE-complete.
In rest of the section we prove that the compressed word problem for some weakly branched
groups (including the Grigorchuk group and the Gupta-Sidki groups) is PSPACE-complete
as well. We need the following lemma.
(cid:73) Lemma 54. Let G be a ﬁnitely generated group with the standard generating set Σ such
that G o (Z/p) ≤ G for some p ≥ 2. Let τn be a generator for the cyclic group Z/pn for n ≥ 1.
Then G o (Z/pn ) ≤ G for every n ≥ 1, and given n in unary encoding and a ∈ Σ ∪ {τn , τ −1
one can compute in LOGSPACE an SLP Gn,a over the terminal alphabet Σ such that the
mapping a 7→ val(Gn,a ) (a ∈ Σ ∪ {τn , τ −1
n }) induces an embedding of G o (Z/pn ) into G.
Proof. We ﬁx an embedding ϕ1 : G o (Z/p) → G. We prove the lemma by induction on
n. The case n = 1 is clear. Consider n ≥ 2 and assume that we have the embedding
ϕn−1 : G o (Z/pn−1 ) → G. We show that
G o (Z/pn ) = G o hτn i ≤ (G o hτn−1 i) o hτ1 i = (G o (Z/pn−1 )) o (Z/p)

n }

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

39

via an embedding ψn . For this we deﬁne ψn (g) = g ∈ G ≤ G o (Z/pn−1 ) for g ∈ G and
ψn (τn ) = τn−1 τ1 . It is easy to see that this deﬁnes indeed an embedding. The element τn−1 τ1
generates a copy of Z/pn by cycling through p copies of Z/pn−1 and incrementing mod pn−1
the current Z/pn−1 -value.
We extend the embedding ϕn−1 : G o (Z/pn−1 ) → G to an embedding

ϕn−1 : (G o (Z/pn−1 )) o (Z/p) → G o (Z/p)

by letting ϕn−1 operate as the identity mapping on the right factor Z/p. Finally, we can
deﬁne ϕn : G o (Z/pn ) → G by ϕn = ψn ◦ ϕn−1 ◦ ϕ1 , where composition is executed from left
to right. We get

ϕn (τn ) = ϕ1 (ϕn−1 (ψn (τn ))) = ϕ1 (ϕn−1 (τn−1 τ1 )) = ϕ1 (ϕn−1 (τn−1 ))ϕ1 (τ1 ).

1 (τ1 )ϕ1 (τ1 ).

ϕn (τn ) = ϕn
1 (τ1 )ϕn−1
1

and ϕn (g) = ϕ1 (ϕn−1 (ψn (g))) = ϕ1 (ϕn−1 (g)). By induction on n we get
(τ1 ) · · · ϕ2
and ϕn (g) = ϕn1 (g) for g ∈ G. Lemma 36 implies that given n in unary encoding we can
compute in LOGSPACE SLPs for ϕn (τn ) and all ϕn (g) (g ∈ G).
(cid:74)
Using Lemma 54 we can show the following variant of Theorem 46.
(cid:73) Theorem 55. Let G be a ﬁnitely generated group such that G o (Z/p) ≤ G for some p ≥ 2.
Then CompressedWP(G) is hard for the complexity class ∀LEAF(WP(G/Z (G))).
Proof. Consider a language L ∈ ∀LEAF(WP(G/Z (G))) and an input word z of length n.
Let J be the SLP that we computed in the proof of Theorem 46 in LOGSPACE from z . We
showed that z ∈ L if and only if val(J ) = 1 in G o Z. Let s = |val(J )|; it is a number in 2nO(1) .
Hence, we can choose a ﬁxed polynomial q such that pq(n) ≥ 2s + 1 for all input lengths n.
Let m = q(n). By Remark 48 we have z ∈ L if and only if val(J ) = 1 in G o (Z/pm ).
From 1m = 1q(n) (which can be constructed in LOGSPACE) we can compute by Lemma 54
for every a ∈ Σ ∪ {τm , τ −1
m } an SLP Gm,a over the terminal alphabet Σ such that the mapping
a 7→ val(Gm,a ) (a ∈ Σ ∪ {τm , τ −1
m }) induces an embedding of the wreath product G o (Z/pm )
into G. Note that log m ∈ O(log n). Hence, the space needed for the construction of the
Gm,a is also logarithmic in the input length n. We can assume that the variable sets of the
SLPs Gm,a (a ∈ Σ ∪ {τm , τ −1
m }) and J are pairwise disjoint. Let Sm,a be the start variable
of Gm,a . We construct an SLP G by taking the union of the SLPs Gm,a (a ∈ Σ ∪ {τm , τ −1
m })
and J and replacing in every right-hand side of J every occurrence of a terminal symbol
a by Sm,a . We have val(G ) = 1 in G if and only if val(J ) = 1 in G o (Z/pm ) if and only if
z ∈ L.
(cid:74)

Lemma 50 and Theorem 55 yield:
(cid:73) Theorem 56. Let G be a uniformly SENS group such that G o (Z/p) ≤ G for some p ≥ 2.
Then CompressedWP(G) is PSPACE-hard.
Let us now come to weakly branched groups. We restrict ourselves to weakly branched
groups G whose branching subgroup K is not torsion-free.
(cid:73) Lemma 57. Let G be a weakly branched group whose branching subgroup K contains
elements of ﬁnite order. Then K contains K o (Z/p) for some p ≥ 2.

40

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

Proof. Let k ∈ K be an element of ﬁnite order. Up to replacing k by a power of itself, we
may assume k has prime order p. In particular, there exists a vertex v ∈ X ∗ whose orbit
under k has size p. Then hv ∗ K, ki ∼= K o (Z/p) is the desired subgroup.
(cid:74)
The following result applies in particular to the Grigorchuk group and the Gupta-Sidki
groups:
(cid:73) Corollary 58. Let G be a weakly branched torsion group whose branching subgroup is
ﬁnitely generated.
CompressedWP(G) is PSPACE-hard.
If G is also contracting then CompressedWP(G) is PSPACE-complete.
Proof. By Lemma 57 and Corollary 29 the branching subgroup K of G satisﬁes the hypotheses
of Theorem 56, so the compressed word problem for K (and hence G) is PSPACE-hard.
If G is also contracting, then the word problem of G is in LOGSPACE by Proposition 5,
so Lemma 37 implies that CompressedWP(G) belongs to PSPACE.
(cid:74)

11

The power word problem

Let us now consider the power word problem. In [46] the third and fourth author proved
that the power word problem for wreath products G o Z, where G is either ﬁnite non-solvable
or ﬁnitely generated free of rank at least two is coNP-complete. A closer examination of the
proof shows that the power word problem for G o Z is coNP-complete if
the power word problem for G belongs to coNP (by [46, Proposition 25] this implies that
the power word problem for G o Z belongs to coNP), and
G is uniformly SENS (the coNP-hardness proofs from [46] directly generalize to all
uniformly SENS groups).
In the rest of the section we show that the power word problem for Thompson’s group F is
coNP-complete. The upper bound can be shown for every co-context-free group. Recall that
a group G with a generating set Σ is co-context-free if Σ∗ \ WP(G, Σ) is context-free (the
choice of Σ is not relevant for this), see [31, Section 14.2] for more details.
(cid:73) Theorem 59. The power word problem for a co-context-free group G belongs to coNP.
Proof. Let Σ be a standard generating set for G and let (w1 , z1 , w2 , z2 , . . . , wn , zn ) be the
input power word, where wi ∈ Σ∗ . We can assume that all zi are positive. We have to check
whether wz1
n is trivial in G. Let L be the complement of WP(G, Σ), which is
context-free. Take the alphabet {a1 , . . . , an} and deﬁne the morphism h : {a1 , . . . , an}∗ → Σ∗
by h(ai ) = wi . Consider the language K = h−1 (L)

2 · · · wzn
1 wz2

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

41

problem for commutative context-free languages, which can be solved in NP according to
(cid:74)
[32]. This implies that the power word problem for G belongs to coNP.
Let us remark that the above context-free language K was also used in [37] in order to show
that the so-called knapsack problem for a co-context-free group is decidable.
(cid:73) Theorem 60. For Thompson’s group F , the power word problem is coNP-complete.
Proof. The upper bound follows from Theorem 59 and the fact that F is co-context-free
[38]. The lower bound follows from the remarks before Theorem 59 and the facts that F is
uniformly SENS and that F o Z ≤ F .
(cid:74)
In [46] it is shown that the power word problem for the Grigorchuk group belongs to
LOGSPACE and, therefore, is much simpler than for the other groups studied in this section
(assuming standard conjectures from complexity theory). The Grigorchuk group is also an
example for a group where the compressed word problem is provably more diﬃcult than the
power word problem (polyL is a proper subset of PSPACE).

12

Conclusion and open problems

We have added an algorithmic constraint (uniformly SENS) to the algebraic notion of being a
non-solvable group, which implies that the word problem is NC1 -hard (resp. ALOGTIME-hard).
Using this, we produced several new examples of non-solvable groups with an ALOGTIME-
hard word problem. However, the question remains open whether all non-solvable groups
have ALOGTIME-hard word problem, even if they are not ENS. We showed that for every
contracting self-similar group the word problem belongs LOGSPACE. Here, the question
remains whether there exists a contracting self-similar group with a LOGSPACE-complete
word problem. In particular, is the word problem for the Grigorchuk group LOGSPACE-
complete? (we proved that it is ALOGTIME-hard). Also the precise complexity of the word
problem for Thompson’s group F is open. It is ALOGTIME-hard and belongs to LOGCFL;
the latter follows from [38]. In fact, from the proof in [38] one can deduce that the word
problem for F belongs to LOGDCFL (the closure of the deterministic context-free languages
with respect to LOGSPACE-reductions).

References

1 Miklós Abért. Group laws and free subgroups in topological groups. Bul l. London Math. Soc.,

37(4):525–534, 2005. URL: https://doi.org/10.1112/S002460930500425X, doi:10.1112/
S002460930500425X.

2

3

Ian Agol. The virtual Haken conjecture. Documenta Mathematica, 18:1045–1087, 2013. With
an appendix by Ian Agol, Daniel Groves, and Jason Manning.
Sanjeev Arora and Boaz Barak. Computational Complexity - A Modern Approach. Cambridge
University Press, 2009.
4 David A. Mix Barrington. Bounded-width polynomial-size branching programs recognize
exactly those languages in N C 1 . J. Comput. Syst. Sci., 38(1):150–164, 1989. URL: http:

//dx.doi.org/10.1016/0022- 0000(89)90037- 8, doi:10.1016/0022- 0000(89)90037- 8.

5 David A. Mix Barrington and Denis Thérien. Finite monoids and the ﬁne structure of N C 1 .
Journal of the ACM, 35:941–952, 1988.
Laurent Bartholdi, Rostislav I. Grigorchuk, and Zoran Šuni´k. Branch groups. In Handbook
of algebra, Vol. 3, volume 3 of Handb. Algebr., pages 989–1112. Elsevier/North-Holland,

6

Amsterdam, 2003. URL: https://doi.org/10.1016/S1570- 7954(03)80078- 5, doi:10.1016/
S1570- 7954(03)80078- 5.

42

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

7

Laurent Bartholdi and Volodymyr V. Nekrashevych. Iterated monodromy groups of quadratic
polynomials. I. Groups Geom. Dyn., 2(3):309–336, 2008. URL: https://doi.org/10.4171/

GGD/42, doi:10.4171/GGD/42.

8 Martin Beaudry, Pierre McKenzie, Pierre Péladeau, and Denis Thérien. Finite monoids: From
word to circuit evaluation. SIAM Journal on Computing, 26(1):138–152, 1997.
9 Richard Beigel and John Gill. Counting classes: Thresholds, parity, mods, and fewness. Theor.

Comput. Sci., 103(1):3–23, 1992. URL: https://doi.org/10.1016/0304- 3975(92)90084- S,
doi:10.1016/0304- 3975(92)90084- S.

10 William W. Boone. The Word Problem. Ann. of Math., 70(2):207–265, 1959.
11 Daniel P. Bovet, Pierluigi Crescenzi, and Riccardo Silvestri. A uniform approach to deﬁne
complexity classes. Theoretical Computer Science, 104(2):263–283, 1992.
John W. Cannon, William J. Floyd, and Walter R. Parry. Introductory notes on Richard
Thompson’s groups. L’Enseignement Mathématique, 42(3):215–256, 1996.
13 Hervé Caussinus, Pierre McKenzie, Denis Thérien, and Heribert Vollmer. Nondeterministic
NC 1 computation. J. Comput. Syst. Sci., 57(2):200–212, 1998. URL: http://dx.doi.org/10.

12

1006/jcss.1998.1588, doi:10.1006/jcss.1998.1588.

14 Moses Charikar, Eric Lehman, Ding Liu, Rina Panigrahy, Manoj Prabhakaran, Amit Sahai,
and Abhi Shelat. The smallest grammar problem. IEEE Transactions on Information Theory,
51(7):2554–2576, 2005.
15 Max Dehn. Über unendliche diskontinuierliche Gruppen. Math. Ann., 71(1):116–144, 1911.

doi:10.1007/BF01456932.

16 Michael R. Garey and David S. Johnson. Computers and Intractability: A Guide to the Theory
of NP–completeness. Freeman, 1979.
17 Max Garzon and Yechezkel Zalcstein. The complexity of Grigorchuk groups with application
to cryptography. Theoretical Computer Science, 88(1):83–98, 1991.
18 Raymond Greenlaw, H. James Hoover, and Walter L. Ruzzo. Limits to paral lel computation:
P-completeness theory. The Clarendon Press, Oxford University Press, New York, 1995.
19 Rostislav I. Grigorchuk. On Burnside’s problem on periodic groups. Funktsional. Anal. i
Prilozhen., 14(1):53–54, 1980.
20 Rostislav I. Grigorchuk and Zoran Šuni´k. Asymptotic aspects of Schreier graphs and Hanoi
Towers groups. C. R. Math. Acad. Sci. Paris, 342(8):545–550, 2006. URL: https://doi.org/

10.1016/j.crma.2006.02.001, doi:10.1016/j.crma.2006.02.001.

21 Victor S. Guba and Mark V. Sapir. On subgroups of the R. Thompson group F and
other diagram groups. Mat. Sb., 190(8):3–60, 1999. URL: https://doi.org/10.1070/

SM1999v190n08ABEH000419, doi:10.1070/SM1999v190n08ABEH000419.

22 Narain Gupta and Saïd Sidki. On the Burnside problem for periodic groups. Math.

Z., 182(3):385–388, 1983. URL: https://doi.org/10.1007/BF01179757, doi:10.1007/
BF01179757.

23

Frédéric Haglund and Daniel T. Wise. Coxeter groups are virtually special. Advances in
Mathematics, 224(5):1890–1903, 2010.
24 Ulrich Hertrampf. Relations among mod-classes. Theoretical Computer Science, 74(3):325–328,

1990. doi:10.1016/0304- 3975(90)90081- R.

25 Ulrich Hertrampf. Über Komplexitätsklassen, die mit Hilfe von k-wertigen Funktionen deﬁniert
werden. Habilitationsschrift, Universität Würzburg, 1994.
26 Ulrich Hertrampf. The shapes of trees.
In Proceedings of the 3rd Annual International
Conference on Computing and combinatorics (COCOON 1997), Shanghai (China), volume
1276 of Lecture Notes in Computer Science, pages 412–421. Springer, 1997.
27 Ulrich Hertrampf. Algebraic acceptance mechanisms for polynomial time machines. SIGACT

News, 31(2):22–33, 2000. doi:10.1145/348210.348215.

28 Ulrich Hertrampf, Clemens Lautemann, Thomas Schwentick, Heribert Vollmer, and Klaus W.
Wagner. On the power of polynomial time bit-reductions. In Proceedings of the Eighth Annual

L. Bartholdi, M. Figelius, M. Lohrey and A. Wei\377

43

Structure in Complexity Theory Conference (San Diego, CA, 1993), pages 200–207. IEEE
Computer Society Press, 1993.
29 Ulrich Hertrampf, Heribert Vollmer, and Klaus Wagner. On balanced versus unbalanced
computation trees. Mathematical Systems Theory, 29(4):411–421, 1996.
30 Derek F. Holt, Markus Lohrey, and Saul Schleimer. Compressed decision problems in hyperbolic
groups. In Proceedings of the 36th International Symposium on Theoretical Aspects of Computer
Science, STACS 2019, volume 126 of LIPIcs, pages 37:1–37:16. Schloss Dagstuhl - Leibniz-

Zentrum fuer Informatik, 2019. URL: http://www.dagstuhl.de/dagpub/978- 3- 95977- 100- 9.

31 Derek F. Holt, Sarah Rees, and Claas E. Röver. Groups, Languages and Automata, volume 88
of London Mathematical Society Student Texts. Cambridge University Press, 2017. URL:

https://doi.org/10.1017/9781316588246, doi:10.1017/9781316588246.

32 Dung T. Huynh. Commutative grammars: The complexity of uniform word problems. Infor-
mation and Control, 57:21–39, 1983.
33 Birgit Jenner, Pierre McKenzie, and Denis Thérien. Logspace and logtime leaf languages.
Information and Computation, 129(1):21–33, 1996.
34 Howard J. Karloﬀ and Walter L. Ruzzo. The iterated mod problem.
Computation, 80(3):193–204, 1989.
35 Daniel König and Markus Lohrey. Evaluation of circuits over nilpotent and polycyclic groups.
Algorithmica, 80(5):1459–1492, 2018.
36 Daniel König and Markus Lohrey. Parallel identity testing for skew circuits with big powers
and applications. IJAC, 28(6):979–1004, 2018.
37 Daniel König, Markus Lohrey, and Georg Zetzsche. Knapsack and subset sum problems in
nilpotent, polycyclic, and co-context-free groups. In Algebra and Computer Science, volume
677 of Contemporary Mathematics, pages 138–153. American Mathematical Society, 2016.
Jörg Lehnert and Pascal Schweitzer. The co-word problem for the Higman-Thompson group
is context-free. Bul letin of the London Mathematical Society, 39(2):235–241, 02 2007. doi:

Information and

38

10.1112/blms/bdl043.

doi:10.4171/JEMS/220.

39 Martin W. Liebeck, Eamonn A. O’Brien, Aner Shalev, and Pham Huu Tiep. The Ore conjecture.
J. Eur. Math. Soc. (JEMS), 12(4):939–1008, 2010. URL: https://doi.org/10.4171/JEMS/220,

40 Yury Lifshits and Markus Lohrey. Querying and embedding compressed texts. In Proceedings
of the 31th International Symposium on Mathematical Foundations of Computer Science,
MFCS 2006, volume 4162 of Lecture Notes in Computer Science, pages 681–692. Springer,
2006.
41 Richard J. Lipton and Yechezkel Zalcstein. Word problems solvable in logspace. Journal of
the Association for Computing Machinery, 24(3):522–526, 1977.
42 Markus Lohrey. Word problems and membership problems on compressed words. SIAM
Journal on Computing, 35(5):1210 – 1240, 2006.
43 Markus Lohrey. Leaf languages and string compression.
209(6):951–965, 2011.
44 Markus Lohrey. The Compressed Word Problem for Groups. Springer Briefs in Mathemat-

Information and Computation,

ics. Springer, 2014. URL: https://doi.org/10.1007/978- 1- 4939- 0748- 9, doi:10.1007/
978- 1- 4939- 0748- 9.

45 Markus Lohrey and Christian Mathissen. Isomorphism of regular trees and words. Information
and Computation, 224:71–105, 2013.
46 Markus Lohrey and Armin Wei\377. The power word problem. InProceedings of MFCS 2019,
volume 138 of LIPIcs, pages 43:1–43:15. Schloss Dagstuhl - Leibniz-Zentrum für Informatik,
2019.
Philip M. Lewis II, Richard Edwin Stearns, and Juris Hartmanis. Memory bounds for
recognition of context-free and context-sensitive languages. In Proceedings of the 6th Annual
Symposium on Switching Circuit Theory and Logical Design, pages 191–202. IEEE Computer
Society, 1965.

47

44

ALOGTIME-hard word problems and PSPACE-complete compressed word problems

48 Volodymyr Nekrashevych. Self-similar groups, volume 117 of Mathematical Surveys and
Monographs. American Mathematical Society, Providence, RI, 2005. URL: https://doi.org/

10.1090/surv/117, doi:10.1090/surv/117.

49

Piotr S. Novikov. On the algorithmic unsolvability of the word problem in group theory. Trudy
Mat. Inst. Steklov, pages 1–143, 1955. In Russian.
50 David Robinson. Paral lel Algorithms for Group Word Problems. PhD thesis, University of
California, San Diego, 1993.
51
Joseph J. Rotman. An Introduction to the Theory of Groups (fourth edition). Springer, 1995.
52 Amir Shpilka and Amir Yehudayoﬀ. Arithmetic circuits: A survey of recent results and open
questions. Foundations and Trends in Theoretical Computer Science, 5(3-4):207–388, 2010.

URL: https://doi.org/10.1561/0400000039, doi:10.1561/0400000039.

53 Hans-Ulrich Simon. Word problems for groups and contextfree recognition. In Proceedings of
Fundamentals of Computation Theory, FCT 1979, pages 417–422. Akademie-Verlag, 1979.
54 Roman Smolensky. Algebraic methods in the theory of lower bounds for boolean circuit
complexity. In Proceedings of the 19th Annual ACM Symposium on Theory of Computing, 1987,
New York, New York, USA, pages 77–82, 1987. URL: https://doi.org/10.1145/28395.28404,

doi:10.1145/28395.28404.

55
Jacques Tits. Free subgroups in linear groups. Journal of Algebra, 20(2):250–270, 1972.
56 Heribert Vollmer. Introduction to Circuit Complexity. Springer, Berlin, 1999.
57
Stephan Waack. The parallel complexity of some constructions in combinatorial group theory.
Journal of Information Processing and Cybernetics EIK, 26:265–281, 1990.
Jan Philipp Wächter and Armin Wei\377. An automaton group with PSPACE-complete word
problem. CoRR, abs/1906.03424, 2019. URL: http://arxiv.org/abs/1906.03424.
John S. Wilson. Embedding theorems for residually ﬁnite groups. Math. Z., 174(2):149–157,

58

59

1980. URL: https://doi.org/10.1007/BF01293535, doi:10.1007/BF01293535.

60 Daniel T. Wise. Research announcement: the structure of groups with a quasiconvex hierarchy.
Electronic Research Announcements in Mathematical Sciences, 16:44–55, 2009.

